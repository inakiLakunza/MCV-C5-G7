1
The device we will be working on is: cuda
[02/29 23:05:02 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[02/29 23:05:06 d2.data.build]: Removed 0 images with no usable annotations. 5007 images left.
[02/29 23:05:06 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 18822        | pedestrian | 8065         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 4977         |            |              |
|   total    | 31864        |            |              |            |              |
[02/29 23:05:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/29 23:05:06 d2.data.build]: Using training sampler TrainingSampler
[02/29 23:05:06 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/29 23:05:06 d2.data.common]: Serializing 5007 elements to byte tensors and concatenating them all ...
[02/29 23:05:06 d2.data.common]: Serialized dataset takes 13.56 MiB
[02/29 23:05:06 d2.data.build]: Making batched data loader with batch_size=8
WARNING [02/29 23:05:06 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/29 23:05:06 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...
[02/29 23:05:06 d2.engine.train_loop]: Starting training from iteration 0
[02/29 23:05:23 d2.utils.events]:  eta: 0:13:29  iter: 19  total_loss: 4.014  loss_cls: 2.604  loss_box_reg: 0.4866  loss_mask: 0.6901  loss_rpn_cls: 0.1383  loss_rpn_loc: 0.06848    time: 0.6030  last_time: 0.5229  data_time: 0.1908  last_data_time: 0.0703   lr: 3.9962e-06  max_mem: 8141M
[02/29 23:05:40 d2.utils.events]:  eta: 0:13:07  iter: 39  total_loss: 3.912  loss_cls: 2.512  loss_box_reg: 0.4428  loss_mask: 0.685  loss_rpn_cls: 0.1933  loss_rpn_loc: 0.0902    time: 0.5704  last_time: 0.5423  data_time: 0.0684  last_data_time: 0.0781   lr: 7.9922e-06  max_mem: 8315M
[02/29 23:05:51 d2.utils.events]:  eta: 0:13:01  iter: 59  total_loss: 3.702  loss_cls: 2.286  loss_box_reg: 0.4944  loss_mask: 0.6736  loss_rpn_cls: 0.1261  loss_rpn_loc: 0.07908    time: 0.5653  last_time: 0.5772  data_time: 0.0710  last_data_time: 0.1167   lr: 1.1988e-05  max_mem: 8683M
[02/29 23:06:02 d2.utils.events]:  eta: 0:12:49  iter: 79  total_loss: 3.326  loss_cls: 2  loss_box_reg: 0.4851  loss_mask: 0.6614  loss_rpn_cls: 0.1256  loss_rpn_loc: 0.0692    time: 0.5619  last_time: 0.5356  data_time: 0.0630  last_data_time: 0.0502   lr: 1.5984e-05  max_mem: 8683M
[02/29 23:06:13 d2.utils.events]:  eta: 0:12:36  iter: 99  total_loss: 2.87  loss_cls: 1.633  loss_box_reg: 0.4809  loss_mask: 0.6361  loss_rpn_cls: 0.126  loss_rpn_loc: 0.07181    time: 0.5577  last_time: 0.5659  data_time: 0.0647  last_data_time: 0.0777   lr: 1.998e-05  max_mem: 8683M
[02/29 23:06:24 d2.utils.events]:  eta: 0:12:24  iter: 119  total_loss: 2.462  loss_cls: 1.183  loss_box_reg: 0.4392  loss_mask: 0.618  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.06927    time: 0.5541  last_time: 0.5054  data_time: 0.0603  last_data_time: 0.0408   lr: 2.3976e-05  max_mem: 8683M
[02/29 23:06:35 d2.utils.events]:  eta: 0:12:15  iter: 139  total_loss: 2.116  loss_cls: 0.8303  loss_box_reg: 0.5182  loss_mask: 0.5916  loss_rpn_cls: 0.111  loss_rpn_loc: 0.08741    time: 0.5532  last_time: 0.5564  data_time: 0.0616  last_data_time: 0.0823   lr: 2.7972e-05  max_mem: 8683M
[02/29 23:06:46 d2.utils.events]:  eta: 0:12:07  iter: 159  total_loss: 1.85  loss_cls: 0.6467  loss_box_reg: 0.4527  loss_mask: 0.564  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.0735    time: 0.5537  last_time: 0.5013  data_time: 0.0728  last_data_time: 0.0379   lr: 3.1968e-05  max_mem: 8683M
[02/29 23:06:57 d2.utils.events]:  eta: 0:11:56  iter: 179  total_loss: 1.72  loss_cls: 0.5269  loss_box_reg: 0.4562  loss_mask: 0.5446  loss_rpn_cls: 0.08564  loss_rpn_loc: 0.0691    time: 0.5522  last_time: 0.5225  data_time: 0.0626  last_data_time: 0.0635   lr: 3.5964e-05  max_mem: 8683M
[02/29 23:07:07 d2.utils.events]:  eta: 0:11:44  iter: 199  total_loss: 1.483  loss_cls: 0.4354  loss_box_reg: 0.3829  loss_mask: 0.5157  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.07555    time: 0.5499  last_time: 0.4864  data_time: 0.0570  last_data_time: 0.0422   lr: 3.996e-05  max_mem: 8714M
[02/29 23:07:18 d2.utils.events]:  eta: 0:11:35  iter: 219  total_loss: 1.6  loss_cls: 0.4834  loss_box_reg: 0.4766  loss_mask: 0.4874  loss_rpn_cls: 0.07535  loss_rpn_loc: 0.07445    time: 0.5496  last_time: 0.5552  data_time: 0.0642  last_data_time: 0.0534   lr: 4.3956e-05  max_mem: 8714M
[02/29 23:07:29 d2.utils.events]:  eta: 0:11:24  iter: 239  total_loss: 1.508  loss_cls: 0.421  loss_box_reg: 0.4295  loss_mask: 0.4752  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.08126    time: 0.5489  last_time: 0.5728  data_time: 0.0677  last_data_time: 0.1055   lr: 4.7952e-05  max_mem: 8714M
[02/29 23:07:40 d2.utils.events]:  eta: 0:11:12  iter: 259  total_loss: 1.433  loss_cls: 0.3946  loss_box_reg: 0.467  loss_mask: 0.4317  loss_rpn_cls: 0.06075  loss_rpn_loc: 0.07973    time: 0.5479  last_time: 0.5705  data_time: 0.0575  last_data_time: 0.0782   lr: 5.1948e-05  max_mem: 8718M
[02/29 23:07:51 d2.utils.events]:  eta: 0:11:01  iter: 279  total_loss: 1.466  loss_cls: 0.3929  loss_box_reg: 0.4355  loss_mask: 0.429  loss_rpn_cls: 0.06689  loss_rpn_loc: 0.07511    time: 0.5475  last_time: 0.5369  data_time: 0.0646  last_data_time: 0.0654   lr: 5.5944e-05  max_mem: 8718M
[02/29 23:08:02 d2.utils.events]:  eta: 0:10:51  iter: 299  total_loss: 1.328  loss_cls: 0.3556  loss_box_reg: 0.4095  loss_mask: 0.4068  loss_rpn_cls: 0.05718  loss_rpn_loc: 0.07021    time: 0.5472  last_time: 0.5450  data_time: 0.0666  last_data_time: 0.0483   lr: 5.994e-05  max_mem: 8718M
[02/29 23:08:13 d2.utils.events]:  eta: 0:10:40  iter: 319  total_loss: 1.355  loss_cls: 0.352  loss_box_reg: 0.4652  loss_mask: 0.4097  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.09256    time: 0.5474  last_time: 0.5792  data_time: 0.0613  last_data_time: 0.0677   lr: 6.3936e-05  max_mem: 8718M
[02/29 23:08:23 d2.utils.events]:  eta: 0:10:29  iter: 339  total_loss: 1.227  loss_cls: 0.3113  loss_box_reg: 0.3928  loss_mask: 0.3888  loss_rpn_cls: 0.05524  loss_rpn_loc: 0.07441    time: 0.5470  last_time: 0.5632  data_time: 0.0665  last_data_time: 0.0376   lr: 6.7932e-05  max_mem: 8718M
[02/29 23:08:34 d2.utils.events]:  eta: 0:10:19  iter: 359  total_loss: 1.227  loss_cls: 0.2927  loss_box_reg: 0.4209  loss_mask: 0.364  loss_rpn_cls: 0.05539  loss_rpn_loc: 0.08698    time: 0.5471  last_time: 0.5762  data_time: 0.0638  last_data_time: 0.0738   lr: 7.1928e-05  max_mem: 8718M
[02/29 23:08:45 d2.utils.events]:  eta: 0:10:08  iter: 379  total_loss: 1.214  loss_cls: 0.2795  loss_box_reg: 0.4212  loss_mask: 0.364  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.08174    time: 0.5472  last_time: 0.5329  data_time: 0.0646  last_data_time: 0.0517   lr: 7.5924e-05  max_mem: 8718M
[02/29 23:08:56 d2.utils.events]:  eta: 0:09:56  iter: 399  total_loss: 1.12  loss_cls: 0.2767  loss_box_reg: 0.3726  loss_mask: 0.3594  loss_rpn_cls: 0.05769  loss_rpn_loc: 0.07744    time: 0.5463  last_time: 0.5179  data_time: 0.0567  last_data_time: 0.0634   lr: 7.992e-05  max_mem: 8718M
[02/29 23:09:07 d2.utils.events]:  eta: 0:09:45  iter: 419  total_loss: 1.232  loss_cls: 0.2729  loss_box_reg: 0.4019  loss_mask: 0.3423  loss_rpn_cls: 0.05323  loss_rpn_loc: 0.0822    time: 0.5467  last_time: 0.5340  data_time: 0.0654  last_data_time: 0.0696   lr: 8.3916e-05  max_mem: 8718M
[02/29 23:09:18 d2.utils.events]:  eta: 0:09:34  iter: 439  total_loss: 1.082  loss_cls: 0.2621  loss_box_reg: 0.3529  loss_mask: 0.3432  loss_rpn_cls: 0.04924  loss_rpn_loc: 0.0656    time: 0.5463  last_time: 0.5473  data_time: 0.0560  last_data_time: 0.0827   lr: 8.7912e-05  max_mem: 8718M
[02/29 23:09:29 d2.utils.events]:  eta: 0:09:24  iter: 459  total_loss: 1.033  loss_cls: 0.2355  loss_box_reg: 0.3746  loss_mask: 0.3083  loss_rpn_cls: 0.05299  loss_rpn_loc: 0.07323    time: 0.5461  last_time: 0.5076  data_time: 0.0617  last_data_time: 0.0634   lr: 9.1908e-05  max_mem: 8718M
[02/29 23:09:39 d2.utils.events]:  eta: 0:09:12  iter: 479  total_loss: 1.042  loss_cls: 0.2503  loss_box_reg: 0.3346  loss_mask: 0.3201  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.07633    time: 0.5455  last_time: 0.5282  data_time: 0.0573  last_data_time: 0.0692   lr: 9.5904e-05  max_mem: 8718M
[02/29 23:09:51 d2.utils.events]:  eta: 0:09:02  iter: 499  total_loss: 0.9875  loss_cls: 0.2393  loss_box_reg: 0.3298  loss_mask: 0.3131  loss_rpn_cls: 0.0466  loss_rpn_loc: 0.07694    time: 0.5452  last_time: 0.5183  data_time: 0.0623  last_data_time: 0.0402   lr: 9.99e-05  max_mem: 8718M
[02/29 23:10:02 d2.utils.events]:  eta: 0:08:51  iter: 519  total_loss: 0.9742  loss_cls: 0.2284  loss_box_reg: 0.3189  loss_mask: 0.2944  loss_rpn_cls: 0.04425  loss_rpn_loc: 0.09124    time: 0.5455  last_time: 0.5169  data_time: 0.0610  last_data_time: 0.0418   lr: 0.0001039  max_mem: 8718M
[02/29 23:10:13 d2.utils.events]:  eta: 0:08:40  iter: 539  total_loss: 0.9442  loss_cls: 0.2186  loss_box_reg: 0.3223  loss_mask: 0.2844  loss_rpn_cls: 0.04078  loss_rpn_loc: 0.07521    time: 0.5457  last_time: 0.5279  data_time: 0.0648  last_data_time: 0.0687   lr: 0.00010789  max_mem: 8718M
[02/29 23:10:24 d2.utils.events]:  eta: 0:08:30  iter: 559  total_loss: 0.9289  loss_cls: 0.2128  loss_box_reg: 0.3048  loss_mask: 0.2794  loss_rpn_cls: 0.04725  loss_rpn_loc: 0.07834    time: 0.5462  last_time: 0.5653  data_time: 0.0654  last_data_time: 0.0721   lr: 0.00011189  max_mem: 8718M
[02/29 23:10:35 d2.utils.events]:  eta: 0:08:19  iter: 579  total_loss: 0.9371  loss_cls: 0.2208  loss_box_reg: 0.2841  loss_mask: 0.3021  loss_rpn_cls: 0.04608  loss_rpn_loc: 0.08209    time: 0.5462  last_time: 0.5711  data_time: 0.0613  last_data_time: 0.0816   lr: 0.00011588  max_mem: 8718M
[02/29 23:10:46 d2.utils.events]:  eta: 0:08:09  iter: 599  total_loss: 0.9192  loss_cls: 0.2083  loss_box_reg: 0.2857  loss_mask: 0.3025  loss_rpn_cls: 0.0412  loss_rpn_loc: 0.06946    time: 0.5466  last_time: 0.5213  data_time: 0.0691  last_data_time: 0.0677   lr: 0.00011988  max_mem: 8718M
[02/29 23:10:58 d2.utils.events]:  eta: 0:07:59  iter: 619  total_loss: 0.8731  loss_cls: 0.1882  loss_box_reg: 0.2494  loss_mask: 0.3103  loss_rpn_cls: 0.0381  loss_rpn_loc: 0.07875    time: 0.5469  last_time: 0.5482  data_time: 0.0696  last_data_time: 0.0726   lr: 0.00012388  max_mem: 8718M
[02/29 23:11:08 d2.utils.events]:  eta: 0:07:48  iter: 639  total_loss: 0.8522  loss_cls: 0.185  loss_box_reg: 0.2435  loss_mask: 0.2749  loss_rpn_cls: 0.04253  loss_rpn_loc: 0.06869    time: 0.5467  last_time: 0.5065  data_time: 0.0621  last_data_time: 0.0592   lr: 0.00012787  max_mem: 8718M
[02/29 23:11:20 d2.utils.events]:  eta: 0:07:37  iter: 659  total_loss: 0.8523  loss_cls: 0.1948  loss_box_reg: 0.2753  loss_mask: 0.2706  loss_rpn_cls: 0.03822  loss_rpn_loc: 0.07277    time: 0.5471  last_time: 0.5495  data_time: 0.0675  last_data_time: 0.0437   lr: 0.00013187  max_mem: 8846M
[02/29 23:11:31 d2.utils.events]:  eta: 0:07:27  iter: 679  total_loss: 0.7984  loss_cls: 0.1797  loss_box_reg: 0.2585  loss_mask: 0.2592  loss_rpn_cls: 0.04017  loss_rpn_loc: 0.07139    time: 0.5471  last_time: 0.5509  data_time: 0.0596  last_data_time: 0.0442   lr: 0.00013586  max_mem: 8846M
[02/29 23:11:42 d2.utils.events]:  eta: 0:07:16  iter: 699  total_loss: 0.791  loss_cls: 0.1868  loss_box_reg: 0.2452  loss_mask: 0.2736  loss_rpn_cls: 0.03659  loss_rpn_loc: 0.07083    time: 0.5473  last_time: 0.5394  data_time: 0.0614  last_data_time: 0.0566   lr: 0.00013986  max_mem: 8846M
[02/29 23:11:53 d2.utils.events]:  eta: 0:07:06  iter: 719  total_loss: 0.8575  loss_cls: 0.1851  loss_box_reg: 0.2762  loss_mask: 0.2772  loss_rpn_cls: 0.03549  loss_rpn_loc: 0.06288    time: 0.5476  last_time: 0.5508  data_time: 0.0675  last_data_time: 0.0859   lr: 0.00014386  max_mem: 8846M
[02/29 23:12:04 d2.utils.events]:  eta: 0:06:55  iter: 739  total_loss: 0.801  loss_cls: 0.1788  loss_box_reg: 0.2546  loss_mask: 0.2621  loss_rpn_cls: 0.03709  loss_rpn_loc: 0.06494    time: 0.5476  last_time: 0.5568  data_time: 0.0584  last_data_time: 0.0540   lr: 0.00014785  max_mem: 8846M
[02/29 23:12:15 d2.utils.events]:  eta: 0:06:44  iter: 759  total_loss: 0.8117  loss_cls: 0.1782  loss_box_reg: 0.2502  loss_mask: 0.256  loss_rpn_cls: 0.03523  loss_rpn_loc: 0.07482    time: 0.5477  last_time: 0.5117  data_time: 0.0618  last_data_time: 0.0357   lr: 0.00015185  max_mem: 8846M
[02/29 23:12:26 d2.utils.events]:  eta: 0:06:33  iter: 779  total_loss: 0.8327  loss_cls: 0.1772  loss_box_reg: 0.2587  loss_mask: 0.2642  loss_rpn_cls: 0.03827  loss_rpn_loc: 0.07282    time: 0.5480  last_time: 0.5562  data_time: 0.0626  last_data_time: 0.0644   lr: 0.00015584  max_mem: 8846M
[02/29 23:12:37 d2.utils.events]:  eta: 0:06:22  iter: 799  total_loss: 0.7768  loss_cls: 0.1598  loss_box_reg: 0.2216  loss_mask: 0.2596  loss_rpn_cls: 0.03198  loss_rpn_loc: 0.06304    time: 0.5478  last_time: 0.5199  data_time: 0.0566  last_data_time: 0.0594   lr: 0.00015984  max_mem: 8846M
[02/29 23:12:48 d2.utils.events]:  eta: 0:06:11  iter: 819  total_loss: 0.7441  loss_cls: 0.1622  loss_box_reg: 0.2271  loss_mask: 0.2529  loss_rpn_cls: 0.0373  loss_rpn_loc: 0.07814    time: 0.5476  last_time: 0.5173  data_time: 0.0588  last_data_time: 0.0576   lr: 0.00016384  max_mem: 8846M
[02/29 23:12:59 d2.utils.events]:  eta: 0:06:00  iter: 839  total_loss: 0.7772  loss_cls: 0.1648  loss_box_reg: 0.2266  loss_mask: 0.2848  loss_rpn_cls: 0.03864  loss_rpn_loc: 0.06953    time: 0.5476  last_time: 0.5425  data_time: 0.0616  last_data_time: 0.0655   lr: 0.00016783  max_mem: 8846M
[02/29 23:13:09 d2.utils.events]:  eta: 0:05:49  iter: 859  total_loss: 0.7819  loss_cls: 0.1651  loss_box_reg: 0.2531  loss_mask: 0.271  loss_rpn_cls: 0.03555  loss_rpn_loc: 0.07313    time: 0.5475  last_time: 0.5725  data_time: 0.0627  last_data_time: 0.0802   lr: 0.00017183  max_mem: 8846M
[02/29 23:13:20 d2.utils.events]:  eta: 0:05:38  iter: 879  total_loss: 0.8025  loss_cls: 0.1596  loss_box_reg: 0.2334  loss_mask: 0.2682  loss_rpn_cls: 0.03769  loss_rpn_loc: 0.07138    time: 0.5473  last_time: 0.5304  data_time: 0.0567  last_data_time: 0.0412   lr: 0.00017582  max_mem: 8846M
[02/29 23:13:31 d2.utils.events]:  eta: 0:05:27  iter: 899  total_loss: 0.7554  loss_cls: 0.1517  loss_box_reg: 0.2206  loss_mask: 0.2466  loss_rpn_cls: 0.03953  loss_rpn_loc: 0.06155    time: 0.5472  last_time: 0.5222  data_time: 0.0595  last_data_time: 0.0572   lr: 0.00017982  max_mem: 8846M
[02/29 23:13:42 d2.utils.events]:  eta: 0:05:16  iter: 919  total_loss: 0.7403  loss_cls: 0.1478  loss_box_reg: 0.2163  loss_mask: 0.2571  loss_rpn_cls: 0.03526  loss_rpn_loc: 0.07284    time: 0.5471  last_time: 0.5617  data_time: 0.0590  last_data_time: 0.0718   lr: 0.00018382  max_mem: 8846M
[02/29 23:13:53 d2.utils.events]:  eta: 0:05:05  iter: 939  total_loss: 0.7233  loss_cls: 0.1596  loss_box_reg: 0.2161  loss_mask: 0.2629  loss_rpn_cls: 0.03331  loss_rpn_loc: 0.06481    time: 0.5472  last_time: 0.5614  data_time: 0.0674  last_data_time: 0.0915   lr: 0.00018781  max_mem: 8846M
[02/29 23:14:04 d2.utils.events]:  eta: 0:04:54  iter: 959  total_loss: 0.7637  loss_cls: 0.1537  loss_box_reg: 0.2325  loss_mask: 0.2484  loss_rpn_cls: 0.03186  loss_rpn_loc: 0.07309    time: 0.5474  last_time: 0.5148  data_time: 0.0686  last_data_time: 0.0533   lr: 0.00019181  max_mem: 8846M
[02/29 23:14:15 d2.utils.events]:  eta: 0:04:43  iter: 979  total_loss: 0.7479  loss_cls: 0.1483  loss_box_reg: 0.1984  loss_mask: 0.2466  loss_rpn_cls: 0.03347  loss_rpn_loc: 0.07264    time: 0.5474  last_time: 0.5511  data_time: 0.0651  last_data_time: 0.0762   lr: 0.0001958  max_mem: 8846M
[02/29 23:14:27 d2.utils.events]:  eta: 0:04:32  iter: 999  total_loss: 0.7122  loss_cls: 0.1508  loss_box_reg: 0.2142  loss_mask: 0.2539  loss_rpn_cls: 0.03477  loss_rpn_loc: 0.06501    time: 0.5474  last_time: 0.5568  data_time: 0.0656  last_data_time: 0.0719   lr: 0.0001998  max_mem: 8846M
[02/29 23:14:38 d2.utils.events]:  eta: 0:04:21  iter: 1019  total_loss: 0.7117  loss_cls: 0.1516  loss_box_reg: 0.2256  loss_mask: 0.2557  loss_rpn_cls: 0.03025  loss_rpn_loc: 0.06968    time: 0.5476  last_time: 0.5781  data_time: 0.0650  last_data_time: 0.0752   lr: 0.0002  max_mem: 8846M
[02/29 23:14:49 d2.utils.events]:  eta: 0:04:11  iter: 1039  total_loss: 0.7692  loss_cls: 0.1563  loss_box_reg: 0.2479  loss_mask: 0.2543  loss_rpn_cls: 0.03015  loss_rpn_loc: 0.07315    time: 0.5479  last_time: 0.5883  data_time: 0.0691  last_data_time: 0.0958   lr: 0.0002  max_mem: 8846M
[02/29 23:15:00 d2.utils.events]:  eta: 0:04:00  iter: 1059  total_loss: 0.7015  loss_cls: 0.1443  loss_box_reg: 0.2147  loss_mask: 0.2515  loss_rpn_cls: 0.03277  loss_rpn_loc: 0.06767    time: 0.5479  last_time: 0.5853  data_time: 0.0635  last_data_time: 0.0842   lr: 0.0002  max_mem: 8846M
[02/29 23:15:12 d2.utils.events]:  eta: 0:03:49  iter: 1079  total_loss: 0.7387  loss_cls: 0.1569  loss_box_reg: 0.2316  loss_mask: 0.2593  loss_rpn_cls: 0.03047  loss_rpn_loc: 0.06429    time: 0.5481  last_time: 0.5158  data_time: 0.0661  last_data_time: 0.0383   lr: 0.0002  max_mem: 8846M
[02/29 23:15:22 d2.utils.events]:  eta: 0:03:38  iter: 1099  total_loss: 0.6979  loss_cls: 0.1329  loss_box_reg: 0.1927  loss_mask: 0.2558  loss_rpn_cls: 0.03637  loss_rpn_loc: 0.06736    time: 0.5478  last_time: 0.5012  data_time: 0.0572  last_data_time: 0.0465   lr: 0.0002  max_mem: 8846M
[02/29 23:15:33 d2.utils.events]:  eta: 0:03:27  iter: 1119  total_loss: 0.7118  loss_cls: 0.1419  loss_box_reg: 0.1972  loss_mask: 0.2458  loss_rpn_cls: 0.03435  loss_rpn_loc: 0.07527    time: 0.5478  last_time: 0.5544  data_time: 0.0653  last_data_time: 0.0686   lr: 0.0002  max_mem: 8846M
[02/29 23:15:44 d2.utils.events]:  eta: 0:03:16  iter: 1139  total_loss: 0.6778  loss_cls: 0.1376  loss_box_reg: 0.1868  loss_mask: 0.2506  loss_rpn_cls: 0.02894  loss_rpn_loc: 0.06328    time: 0.5475  last_time: 0.5268  data_time: 0.0616  last_data_time: 0.0495   lr: 0.0002  max_mem: 8846M
[02/29 23:15:55 d2.utils.events]:  eta: 0:03:05  iter: 1159  total_loss: 0.7012  loss_cls: 0.1447  loss_box_reg: 0.1919  loss_mask: 0.2464  loss_rpn_cls: 0.03539  loss_rpn_loc: 0.06555    time: 0.5474  last_time: 0.5149  data_time: 0.0676  last_data_time: 0.0455   lr: 0.0002  max_mem: 8846M
[02/29 23:16:06 d2.utils.events]:  eta: 0:02:54  iter: 1179  total_loss: 0.7018  loss_cls: 0.1418  loss_box_reg: 0.2053  loss_mask: 0.2552  loss_rpn_cls: 0.03301  loss_rpn_loc: 0.06329    time: 0.5474  last_time: 0.5335  data_time: 0.0682  last_data_time: 0.0548   lr: 0.0002  max_mem: 8846M
[02/29 23:16:16 d2.utils.events]:  eta: 0:02:43  iter: 1199  total_loss: 0.7329  loss_cls: 0.1456  loss_box_reg: 0.2119  loss_mask: 0.2569  loss_rpn_cls: 0.0364  loss_rpn_loc: 0.07496    time: 0.5474  last_time: 0.5009  data_time: 0.0630  last_data_time: 0.0512   lr: 0.0002  max_mem: 8846M
[02/29 23:16:27 d2.utils.events]:  eta: 0:02:32  iter: 1219  total_loss: 0.6726  loss_cls: 0.1369  loss_box_reg: 0.2052  loss_mask: 0.2464  loss_rpn_cls: 0.03493  loss_rpn_loc: 0.0639    time: 0.5473  last_time: 0.5652  data_time: 0.0607  last_data_time: 0.0460   lr: 0.0002  max_mem: 8846M
[02/29 23:16:38 d2.utils.events]:  eta: 0:02:21  iter: 1239  total_loss: 0.648  loss_cls: 0.1309  loss_box_reg: 0.1635  loss_mask: 0.2335  loss_rpn_cls: 0.03413  loss_rpn_loc: 0.05142    time: 0.5470  last_time: 0.5464  data_time: 0.0603  last_data_time: 0.0794   lr: 0.0002  max_mem: 8846M
[02/29 23:16:49 d2.utils.events]:  eta: 0:02:10  iter: 1259  total_loss: 0.7124  loss_cls: 0.1409  loss_box_reg: 0.2041  loss_mask: 0.2421  loss_rpn_cls: 0.02937  loss_rpn_loc: 0.05802    time: 0.5469  last_time: 0.5441  data_time: 0.0575  last_data_time: 0.0415   lr: 0.0002  max_mem: 8846M
[02/29 23:17:00 d2.utils.events]:  eta: 0:02:00  iter: 1279  total_loss: 0.7039  loss_cls: 0.1469  loss_box_reg: 0.1995  loss_mask: 0.2464  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.06482    time: 0.5469  last_time: 0.4939  data_time: 0.0636  last_data_time: 0.0497   lr: 0.0002  max_mem: 8846M
[02/29 23:17:10 d2.utils.events]:  eta: 0:01:49  iter: 1299  total_loss: 0.6835  loss_cls: 0.1364  loss_box_reg: 0.1914  loss_mask: 0.2469  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.06114    time: 0.5467  last_time: 0.5317  data_time: 0.0613  last_data_time: 0.0692   lr: 0.0002  max_mem: 8846M
[02/29 23:17:21 d2.utils.events]:  eta: 0:01:38  iter: 1319  total_loss: 0.6429  loss_cls: 0.1412  loss_box_reg: 0.1949  loss_mask: 0.2523  loss_rpn_cls: 0.02492  loss_rpn_loc: 0.05637    time: 0.5465  last_time: 0.5130  data_time: 0.0525  last_data_time: 0.0337   lr: 0.0002  max_mem: 8846M
[02/29 23:17:32 d2.utils.events]:  eta: 0:01:27  iter: 1339  total_loss: 0.6829  loss_cls: 0.1385  loss_box_reg: 0.1988  loss_mask: 0.2532  loss_rpn_cls: 0.02734  loss_rpn_loc: 0.06478    time: 0.5464  last_time: 0.5162  data_time: 0.0619  last_data_time: 0.0468   lr: 0.0002  max_mem: 8846M
[02/29 23:17:43 d2.utils.events]:  eta: 0:01:16  iter: 1359  total_loss: 0.6668  loss_cls: 0.1406  loss_box_reg: 0.2031  loss_mask: 0.2343  loss_rpn_cls: 0.02775  loss_rpn_loc: 0.06482    time: 0.5463  last_time: 0.5420  data_time: 0.0602  last_data_time: 0.0573   lr: 0.0002  max_mem: 8846M
[02/29 23:17:54 d2.utils.events]:  eta: 0:01:05  iter: 1379  total_loss: 0.6783  loss_cls: 0.1442  loss_box_reg: 0.2121  loss_mask: 0.2349  loss_rpn_cls: 0.03057  loss_rpn_loc: 0.06351    time: 0.5465  last_time: 0.5391  data_time: 0.0701  last_data_time: 0.0787   lr: 0.0002  max_mem: 8846M
[02/29 23:18:05 d2.utils.events]:  eta: 0:00:54  iter: 1399  total_loss: 0.7213  loss_cls: 0.1382  loss_box_reg: 0.1857  loss_mask: 0.2486  loss_rpn_cls: 0.02796  loss_rpn_loc: 0.07024    time: 0.5464  last_time: 0.5422  data_time: 0.0663  last_data_time: 0.0603   lr: 0.0002  max_mem: 8846M
[02/29 23:18:16 d2.utils.events]:  eta: 0:00:43  iter: 1419  total_loss: 0.7075  loss_cls: 0.1474  loss_box_reg: 0.2138  loss_mask: 0.2501  loss_rpn_cls: 0.03135  loss_rpn_loc: 0.06883    time: 0.5466  last_time: 0.5678  data_time: 0.0589  last_data_time: 0.0818   lr: 0.0002  max_mem: 8846M
[02/29 23:18:27 d2.utils.events]:  eta: 0:00:32  iter: 1439  total_loss: 0.7071  loss_cls: 0.1417  loss_box_reg: 0.2082  loss_mask: 0.2571  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.05833    time: 0.5465  last_time: 0.5421  data_time: 0.0596  last_data_time: 0.0676   lr: 0.0002  max_mem: 8846M
[02/29 23:18:37 d2.utils.events]:  eta: 0:00:21  iter: 1459  total_loss: 0.6507  loss_cls: 0.13  loss_box_reg: 0.1874  loss_mask: 0.2422  loss_rpn_cls: 0.02595  loss_rpn_loc: 0.05572    time: 0.5463  last_time: 0.5375  data_time: 0.0586  last_data_time: 0.0916   lr: 0.0002  max_mem: 8846M
[02/29 23:18:48 d2.utils.events]:  eta: 0:00:10  iter: 1479  total_loss: 0.6533  loss_cls: 0.1355  loss_box_reg: 0.1833  loss_mask: 0.2378  loss_rpn_cls: 0.03023  loss_rpn_loc: 0.06398    time: 0.5460  last_time: 0.5178  data_time: 0.0504  last_data_time: 0.0483   lr: 0.0002  max_mem: 8846M
[02/29 23:19:00 d2.utils.events]:  eta: 0:00:00  iter: 1499  total_loss: 0.6573  loss_cls: 0.1272  loss_box_reg: 0.186  loss_mask: 0.2412  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.06753    time: 0.5459  last_time: 0.5273  data_time: 0.0612  last_data_time: 0.0566   lr: 0.0002  max_mem: 8846M
[02/29 23:19:00 d2.engine.hooks]: Overall training speed: 1498 iterations in 0:13:37 (0.5459 s / it)
[02/29 23:19:00 d2.engine.hooks]: Total training time: 0:13:48 (0:00:11 on hooks)
[02/29 23:19:06 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 8021         | pedestrian | 3347         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 2765         |            |              |
|   total    | 14133        |            |              |            |              |
[02/29 23:19:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/29 23:19:06 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/29 23:19:06 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[02/29 23:19:06 d2.data.common]: Serialized dataset takes 5.86 MiB
WARNING [02/29 23:19:06 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[02/29 23:19:06 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /ghome/group07/C5-W2/outputs_task_e/model_final.pth ...
[02/29 23:19:08 d2.evaluation.coco_evaluation]: Trying to convert 'KITTI-MOTS_val' to COCO format ...
WARNING [02/29 23:19:08 d2.data.datasets.coco]: Using previously cached COCO format annotations at '/ghome/group07/C5-W2/outputs_task_e/KITTI-MOTS_val_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[02/29 23:19:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[02/29 23:19:11 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/29 23:19:11 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[02/29 23:19:11 d2.data.common]: Serialized dataset takes 5.86 MiB
[02/29 23:19:11 d2.evaluation.evaluator]: Start inference on 2919 batches
[02/29 23:19:13 d2.evaluation.evaluator]: Inference done 11/2919. Dataloading: 0.0018 s/iter. Inference: 0.0408 s/iter. Eval: 0.0011 s/iter. Total: 0.0437 s/iter. ETA=0:02:07
[02/29 23:19:18 d2.evaluation.evaluator]: Inference done 116/2919. Dataloading: 0.0026 s/iter. Inference: 0.0434 s/iter. Eval: 0.0017 s/iter. Total: 0.0477 s/iter. ETA=0:02:13
[02/29 23:19:23 d2.evaluation.evaluator]: Inference done 214/2919. Dataloading: 0.0027 s/iter. Inference: 0.0451 s/iter. Eval: 0.0016 s/iter. Total: 0.0495 s/iter. ETA=0:02:13
[02/29 23:19:28 d2.evaluation.evaluator]: Inference done 316/2919. Dataloading: 0.0027 s/iter. Inference: 0.0451 s/iter. Eval: 0.0016 s/iter. Total: 0.0495 s/iter. ETA=0:02:08
[02/29 23:19:33 d2.evaluation.evaluator]: Inference done 408/2919. Dataloading: 0.0027 s/iter. Inference: 0.0463 s/iter. Eval: 0.0016 s/iter. Total: 0.0507 s/iter. ETA=0:02:07
[02/29 23:19:38 d2.evaluation.evaluator]: Inference done 503/2919. Dataloading: 0.0027 s/iter. Inference: 0.0467 s/iter. Eval: 0.0016 s/iter. Total: 0.0511 s/iter. ETA=0:02:03
[02/29 23:19:43 d2.evaluation.evaluator]: Inference done 605/2919. Dataloading: 0.0027 s/iter. Inference: 0.0464 s/iter. Eval: 0.0016 s/iter. Total: 0.0507 s/iter. ETA=0:01:57
[02/29 23:19:48 d2.evaluation.evaluator]: Inference done 699/2919. Dataloading: 0.0027 s/iter. Inference: 0.0466 s/iter. Eval: 0.0017 s/iter. Total: 0.0511 s/iter. ETA=0:01:53
[02/29 23:19:53 d2.evaluation.evaluator]: Inference done 794/2919. Dataloading: 0.0027 s/iter. Inference: 0.0468 s/iter. Eval: 0.0018 s/iter. Total: 0.0514 s/iter. ETA=0:01:49
[02/29 23:19:58 d2.evaluation.evaluator]: Inference done 890/2919. Dataloading: 0.0027 s/iter. Inference: 0.0468 s/iter. Eval: 0.0019 s/iter. Total: 0.0515 s/iter. ETA=0:01:44
[02/29 23:20:03 d2.evaluation.evaluator]: Inference done 984/2919. Dataloading: 0.0027 s/iter. Inference: 0.0470 s/iter. Eval: 0.0019 s/iter. Total: 0.0517 s/iter. ETA=0:01:39
[02/29 23:20:08 d2.evaluation.evaluator]: Inference done 1078/2919. Dataloading: 0.0027 s/iter. Inference: 0.0471 s/iter. Eval: 0.0020 s/iter. Total: 0.0518 s/iter. ETA=0:01:35
[02/29 23:20:13 d2.evaluation.evaluator]: Inference done 1174/2919. Dataloading: 0.0027 s/iter. Inference: 0.0470 s/iter. Eval: 0.0021 s/iter. Total: 0.0519 s/iter. ETA=0:01:30
[02/29 23:20:18 d2.evaluation.evaluator]: Inference done 1268/2919. Dataloading: 0.0027 s/iter. Inference: 0.0471 s/iter. Eval: 0.0021 s/iter. Total: 0.0520 s/iter. ETA=0:01:25
[02/29 23:20:23 d2.evaluation.evaluator]: Inference done 1362/2919. Dataloading: 0.0027 s/iter. Inference: 0.0472 s/iter. Eval: 0.0021 s/iter. Total: 0.0521 s/iter. ETA=0:01:21
[02/29 23:20:28 d2.evaluation.evaluator]: Inference done 1456/2919. Dataloading: 0.0028 s/iter. Inference: 0.0473 s/iter. Eval: 0.0021 s/iter. Total: 0.0522 s/iter. ETA=0:01:16
[02/29 23:20:33 d2.evaluation.evaluator]: Inference done 1551/2919. Dataloading: 0.0028 s/iter. Inference: 0.0473 s/iter. Eval: 0.0021 s/iter. Total: 0.0522 s/iter. ETA=0:01:11
[02/29 23:20:38 d2.evaluation.evaluator]: Inference done 1648/2919. Dataloading: 0.0028 s/iter. Inference: 0.0473 s/iter. Eval: 0.0021 s/iter. Total: 0.0522 s/iter. ETA=0:01:06
[02/29 23:20:43 d2.evaluation.evaluator]: Inference done 1743/2919. Dataloading: 0.0028 s/iter. Inference: 0.0472 s/iter. Eval: 0.0021 s/iter. Total: 0.0522 s/iter. ETA=0:01:01
[02/29 23:20:48 d2.evaluation.evaluator]: Inference done 1839/2919. Dataloading: 0.0028 s/iter. Inference: 0.0472 s/iter. Eval: 0.0021 s/iter. Total: 0.0522 s/iter. ETA=0:00:56
[02/29 23:20:53 d2.evaluation.evaluator]: Inference done 1939/2919. Dataloading: 0.0028 s/iter. Inference: 0.0471 s/iter. Eval: 0.0022 s/iter. Total: 0.0521 s/iter. ETA=0:00:51
[02/29 23:20:58 d2.evaluation.evaluator]: Inference done 2031/2919. Dataloading: 0.0028 s/iter. Inference: 0.0472 s/iter. Eval: 0.0022 s/iter. Total: 0.0522 s/iter. ETA=0:00:46
[02/29 23:21:03 d2.evaluation.evaluator]: Inference done 2122/2919. Dataloading: 0.0028 s/iter. Inference: 0.0472 s/iter. Eval: 0.0022 s/iter. Total: 0.0524 s/iter. ETA=0:00:41
[02/29 23:21:08 d2.evaluation.evaluator]: Inference done 2220/2919. Dataloading: 0.0028 s/iter. Inference: 0.0472 s/iter. Eval: 0.0023 s/iter. Total: 0.0523 s/iter. ETA=0:00:36
[02/29 23:21:13 d2.evaluation.evaluator]: Inference done 2319/2919. Dataloading: 0.0028 s/iter. Inference: 0.0471 s/iter. Eval: 0.0023 s/iter. Total: 0.0523 s/iter. ETA=0:00:31
[02/29 23:21:19 d2.evaluation.evaluator]: Inference done 2409/2919. Dataloading: 0.0028 s/iter. Inference: 0.0472 s/iter. Eval: 0.0023 s/iter. Total: 0.0524 s/iter. ETA=0:00:26
[02/29 23:21:24 d2.evaluation.evaluator]: Inference done 2500/2919. Dataloading: 0.0028 s/iter. Inference: 0.0471 s/iter. Eval: 0.0025 s/iter. Total: 0.0525 s/iter. ETA=0:00:21
[02/29 23:21:29 d2.evaluation.evaluator]: Inference done 2593/2919. Dataloading: 0.0028 s/iter. Inference: 0.0471 s/iter. Eval: 0.0026 s/iter. Total: 0.0525 s/iter. ETA=0:00:17
[02/29 23:21:34 d2.evaluation.evaluator]: Inference done 2689/2919. Dataloading: 0.0028 s/iter. Inference: 0.0471 s/iter. Eval: 0.0026 s/iter. Total: 0.0525 s/iter. ETA=0:00:12
[02/29 23:21:39 d2.evaluation.evaluator]: Inference done 2786/2919. Dataloading: 0.0028 s/iter. Inference: 0.0470 s/iter. Eval: 0.0026 s/iter. Total: 0.0525 s/iter. ETA=0:00:06
[02/29 23:21:44 d2.evaluation.evaluator]: Inference done 2881/2919. Dataloading: 0.0028 s/iter. Inference: 0.0470 s/iter. Eval: 0.0027 s/iter. Total: 0.0525 s/iter. ETA=0:00:01
[02/29 23:21:46 d2.evaluation.evaluator]: Total inference time: 0:02:33.057873 (0.052525 s / iter per device, on 1 devices)
[02/29 23:21:46 d2.evaluation.evaluator]: Total inference pure compute time: 0:02:16 (0.046986 s / iter per device, on 1 devices)
[02/29 23:21:46 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[02/29 23:21:46 d2.evaluation.coco_evaluation]: Saving results to /ghome/group07/C5-W2/outputs_task_e/coco_instances_results.json
[02/29 23:21:46 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[02/29 23:21:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[02/29 23:21:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.70 seconds.
[02/29 23:21:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[02/29 23:21:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.532
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590
[02/29 23:21:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.592 | 53.229 | 46.104 | 26.403 | 46.677 | 49.585 |
[02/29 23:21:47 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 67.384 | pedestrian | 50.473 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 0.919  |            |        |
Loading and preparing results...
DONE (t=0.11s)
creating index...
index created!
[02/29 23:21:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[02/29 23:21:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.86 seconds.
[02/29 23:21:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[02/29 23:21:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.388
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540
[02/29 23:21:48 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 34.941 | 52.272 | 39.341 | 21.057 | 42.225 | 50.991 |
[02/29 23:21:48 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 65.911 | pedestrian | 38.376 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 0.535  |            |        |
OrderedDict([('bbox', {'AP': 39.59192207619823, 'AP50': 53.22902948856857, 'AP75': 46.10434937808691, 'APs': 26.402824526362345, 'APm': 46.676558896359694, 'APl': 49.58535404334373, 'AP-background': nan, 'AP-car': 67.38355246452792, 'AP-pedestrian': 50.47283611201584, 'AP-': nan, 'AP-ignore': 0.9193776520509191}), ('segm', {'AP': 34.9407418633101, 'AP50': 52.2718133173667, 'AP75': 39.341201760324836, 'APs': 21.056883043132327, 'APm': 42.22485124398365, 'APl': 50.99073428927072, 'AP-background': nan, 'AP-car': 65.91130871965906, 'AP-pedestrian': 38.37626340492471, 'AP-': nan, 'AP-ignore': 0.5346534653465347})])
