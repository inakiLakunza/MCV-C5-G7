1
The device we will be working on is: cuda
[03/02 11:25:01 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=44, bias=True)
    )
  )
)
[03/02 11:25:05 d2.data.build]: Removed 0 images with no usable annotations. 5007 images left.
[03/02 11:25:06 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 18822        | pedestrian | 8065         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 4977         |            |              |
|   total    | 31864        |            |              |            |              |
[03/02 11:25:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[03/02 11:25:06 d2.data.build]: Using training sampler TrainingSampler
[03/02 11:25:06 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/02 11:25:06 d2.data.common]: Serializing 5007 elements to byte tensors and concatenating them all ...
[03/02 11:25:06 d2.data.common]: Serialized dataset takes 13.56 MiB
[03/02 11:25:06 d2.data.build]: Making batched data loader with batch_size=10
WARNING [03/02 11:25:06 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/02 11:25:06 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_C4_1x/137257644/model_final_721ade.pkl ...
[03/02 11:25:06 d2.engine.train_loop]: Starting training from iteration 0
[03/02 11:25:46 d2.utils.events]:  eta: 0:41:25  iter: 19  total_loss: 3.094  loss_cls: 1.989  loss_box_reg: 0.4454  loss_rpn_cls: 0.399  loss_rpn_loc: 0.1859    time: 1.7297  last_time: 1.7064  data_time: 0.1790  last_data_time: 0.1223   lr: 0.00039962  max_mem: 20096M
[03/02 11:26:29 d2.utils.events]:  eta: 0:41:37  iter: 39  total_loss: 1.227  loss_cls: 0.456  loss_box_reg: 0.4456  loss_rpn_cls: 0.1742  loss_rpn_loc: 0.1597    time: 1.7548  last_time: 1.7422  data_time: 0.1393  last_data_time: 0.1261   lr: 0.00079922  max_mem: 20096M
[03/02 11:27:03 d2.utils.events]:  eta: 0:40:56  iter: 59  total_loss: 0.9472  loss_cls: 0.2596  loss_box_reg: 0.4048  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.1504    time: 1.7373  last_time: 1.7028  data_time: 0.1118  last_data_time: 0.1033   lr: 0.0011988  max_mem: 20096M
[03/02 11:27:38 d2.utils.events]:  eta: 0:40:25  iter: 79  total_loss: 0.8211  loss_cls: 0.183  loss_box_reg: 0.3392  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.1461    time: 1.7356  last_time: 1.7906  data_time: 0.1105  last_data_time: 0.1273   lr: 0.0015984  max_mem: 20096M
[03/02 11:28:12 d2.utils.events]:  eta: 0:39:56  iter: 99  total_loss: 0.6452  loss_cls: 0.1456  loss_box_reg: 0.2605  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.124    time: 1.7334  last_time: 1.6998  data_time: 0.1045  last_data_time: 0.1005   lr: 0.001998  max_mem: 20096M
[03/02 11:28:46 d2.utils.events]:  eta: 0:39:22  iter: 119  total_loss: 0.6022  loss_cls: 0.1139  loss_box_reg: 0.24  loss_rpn_cls: 0.09643  loss_rpn_loc: 0.1401    time: 1.7300  last_time: 1.7089  data_time: 0.0978  last_data_time: 0.0736   lr: 0.0023976  max_mem: 20096M
[03/02 11:29:21 d2.utils.events]:  eta: 0:38:52  iter: 139  total_loss: 0.5755  loss_cls: 0.1147  loss_box_reg: 0.2372  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.1263    time: 1.7300  last_time: 1.7383  data_time: 0.1045  last_data_time: 0.0808   lr: 0.0027972  max_mem: 20096M
[03/02 11:29:55 d2.utils.events]:  eta: 0:38:18  iter: 159  total_loss: 0.5722  loss_cls: 0.1094  loss_box_reg: 0.2066  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1337    time: 1.7290  last_time: 1.7425  data_time: 0.1045  last_data_time: 0.1315   lr: 0.0031968  max_mem: 20096M
[03/02 11:30:30 d2.utils.events]:  eta: 0:37:50  iter: 179  total_loss: 0.4929  loss_cls: 0.09739  loss_box_reg: 0.1902  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.1257    time: 1.7291  last_time: 1.7316  data_time: 0.1085  last_data_time: 0.0962   lr: 0.0035964  max_mem: 20096M
[03/02 11:31:05 d2.utils.events]:  eta: 0:37:19  iter: 199  total_loss: 0.5357  loss_cls: 0.1086  loss_box_reg: 0.2026  loss_rpn_cls: 0.0947  loss_rpn_loc: 0.1182    time: 1.7299  last_time: 1.7755  data_time: 0.1103  last_data_time: 0.0959   lr: 0.003996  max_mem: 20096M
[03/02 11:31:39 d2.utils.events]:  eta: 0:36:46  iter: 219  total_loss: 0.5315  loss_cls: 0.09736  loss_box_reg: 0.2008  loss_rpn_cls: 0.08859  loss_rpn_loc: 0.1324    time: 1.7298  last_time: 1.7176  data_time: 0.1023  last_data_time: 0.1084   lr: 0.0043956  max_mem: 20096M
[03/02 11:32:14 d2.utils.events]:  eta: 0:36:11  iter: 239  total_loss: 0.4988  loss_cls: 0.09401  loss_box_reg: 0.19  loss_rpn_cls: 0.09242  loss_rpn_loc: 0.1234    time: 1.7299  last_time: 1.7819  data_time: 0.1020  last_data_time: 0.1553   lr: 0.0047952  max_mem: 20096M
[03/02 11:32:48 d2.utils.events]:  eta: 0:35:37  iter: 259  total_loss: 0.5143  loss_cls: 0.1011  loss_box_reg: 0.1946  loss_rpn_cls: 0.07984  loss_rpn_loc: 0.1352    time: 1.7300  last_time: 1.7491  data_time: 0.1134  last_data_time: 0.0892   lr: 0.0051948  max_mem: 20096M
[03/02 11:33:22 d2.utils.events]:  eta: 0:35:00  iter: 279  total_loss: 0.5006  loss_cls: 0.09177  loss_box_reg: 0.1679  loss_rpn_cls: 0.08663  loss_rpn_loc: 0.1381    time: 1.7281  last_time: 1.7137  data_time: 0.1061  last_data_time: 0.0930   lr: 0.0055944  max_mem: 20096M
[03/02 11:33:57 d2.utils.events]:  eta: 0:34:24  iter: 299  total_loss: 0.4719  loss_cls: 0.08533  loss_box_reg: 0.1647  loss_rpn_cls: 0.0796  loss_rpn_loc: 0.147    time: 1.7269  last_time: 1.6695  data_time: 0.1043  last_data_time: 0.1017   lr: 0.005994  max_mem: 20096M
[03/02 11:34:31 d2.utils.events]:  eta: 0:33:49  iter: 319  total_loss: 0.4929  loss_cls: 0.09237  loss_box_reg: 0.182  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1395    time: 1.7259  last_time: 1.6719  data_time: 0.1055  last_data_time: 0.0893   lr: 0.0063936  max_mem: 20096M
[03/02 11:35:05 d2.utils.events]:  eta: 0:33:16  iter: 339  total_loss: 0.5232  loss_cls: 0.08708  loss_box_reg: 0.1807  loss_rpn_cls: 0.08166  loss_rpn_loc: 0.1301    time: 1.7260  last_time: 1.6884  data_time: 0.1002  last_data_time: 0.0835   lr: 0.0067932  max_mem: 20096M
[03/02 11:35:40 d2.utils.events]:  eta: 0:32:41  iter: 359  total_loss: 0.4831  loss_cls: 0.08798  loss_box_reg: 0.1829  loss_rpn_cls: 0.077  loss_rpn_loc: 0.1301    time: 1.7252  last_time: 1.7367  data_time: 0.1008  last_data_time: 0.1087   lr: 0.0071928  max_mem: 20096M
[03/02 11:36:14 d2.utils.events]:  eta: 0:32:07  iter: 379  total_loss: 0.4904  loss_cls: 0.08666  loss_box_reg: 0.1814  loss_rpn_cls: 0.08185  loss_rpn_loc: 0.1407    time: 1.7250  last_time: 1.7622  data_time: 0.0982  last_data_time: 0.0870   lr: 0.0075924  max_mem: 20096M
[03/02 11:36:49 d2.utils.events]:  eta: 0:31:33  iter: 399  total_loss: 0.4777  loss_cls: 0.09084  loss_box_reg: 0.1775  loss_rpn_cls: 0.07966  loss_rpn_loc: 0.1379    time: 1.7249  last_time: 1.7642  data_time: 0.1008  last_data_time: 0.0860   lr: 0.007992  max_mem: 20096M
[03/02 11:37:23 d2.utils.events]:  eta: 0:30:59  iter: 419  total_loss: 0.4697  loss_cls: 0.08271  loss_box_reg: 0.1681  loss_rpn_cls: 0.07868  loss_rpn_loc: 0.135    time: 1.7250  last_time: 1.6980  data_time: 0.1120  last_data_time: 0.0939   lr: 0.0083916  max_mem: 20096M
[03/02 11:37:57 d2.utils.events]:  eta: 0:30:24  iter: 439  total_loss: 0.4937  loss_cls: 0.08871  loss_box_reg: 0.1803  loss_rpn_cls: 0.08563  loss_rpn_loc: 0.1417    time: 1.7246  last_time: 1.7332  data_time: 0.0947  last_data_time: 0.0955   lr: 0.0087912  max_mem: 20096M
[03/02 11:38:32 d2.utils.events]:  eta: 0:29:50  iter: 459  total_loss: 0.4594  loss_cls: 0.08699  loss_box_reg: 0.191  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.1197    time: 1.7244  last_time: 1.7112  data_time: 0.0986  last_data_time: 0.0850   lr: 0.0091908  max_mem: 20096M
[03/02 11:39:06 d2.utils.events]:  eta: 0:29:14  iter: 479  total_loss: 0.4433  loss_cls: 0.08482  loss_box_reg: 0.1684  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.1097    time: 1.7232  last_time: 1.7110  data_time: 0.0889  last_data_time: 0.1006   lr: 0.0095904  max_mem: 20096M
[03/02 11:39:40 d2.utils.events]:  eta: 0:28:38  iter: 499  total_loss: 0.4643  loss_cls: 0.08375  loss_box_reg: 0.1747  loss_rpn_cls: 0.08551  loss_rpn_loc: 0.1233    time: 1.7211  last_time: 1.6373  data_time: 0.0867  last_data_time: 0.0740   lr: 0.00999  max_mem: 20096M
[03/02 11:40:13 d2.utils.events]:  eta: 0:28:02  iter: 519  total_loss: 0.4572  loss_cls: 0.08098  loss_box_reg: 0.1674  loss_rpn_cls: 0.07668  loss_rpn_loc: 0.1357    time: 1.7191  last_time: 1.6977  data_time: 0.0923  last_data_time: 0.0818   lr: 0.01039  max_mem: 20096M
[03/02 11:40:47 d2.utils.events]:  eta: 0:27:25  iter: 539  total_loss: 0.4792  loss_cls: 0.08108  loss_box_reg: 0.1598  loss_rpn_cls: 0.08981  loss_rpn_loc: 0.1503    time: 1.7178  last_time: 1.6393  data_time: 0.0916  last_data_time: 0.0842   lr: 0.010789  max_mem: 20096M
[03/02 11:41:20 d2.utils.events]:  eta: 0:26:50  iter: 559  total_loss: 0.4494  loss_cls: 0.07985  loss_box_reg: 0.1661  loss_rpn_cls: 0.07839  loss_rpn_loc: 0.1254    time: 1.7165  last_time: 1.6800  data_time: 0.0922  last_data_time: 0.1100   lr: 0.011189  max_mem: 20096M
[03/02 11:41:54 d2.utils.events]:  eta: 0:26:15  iter: 579  total_loss: 0.4599  loss_cls: 0.07639  loss_box_reg: 0.1553  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.139    time: 1.7152  last_time: 1.6706  data_time: 0.0902  last_data_time: 0.0854   lr: 0.011588  max_mem: 20096M
[03/02 11:42:27 d2.utils.events]:  eta: 0:25:39  iter: 599  total_loss: 0.4283  loss_cls: 0.07516  loss_box_reg: 0.158  loss_rpn_cls: 0.06683  loss_rpn_loc: 0.1165    time: 1.7132  last_time: 1.6447  data_time: 0.0882  last_data_time: 0.0803   lr: 0.011988  max_mem: 20096M
[03/02 11:43:01 d2.utils.events]:  eta: 0:25:04  iter: 619  total_loss: 0.4595  loss_cls: 0.07644  loss_box_reg: 0.1655  loss_rpn_cls: 0.07655  loss_rpn_loc: 0.1208    time: 1.7124  last_time: 1.6839  data_time: 0.0943  last_data_time: 0.0883   lr: 0.012388  max_mem: 20096M
[03/02 11:43:35 d2.utils.events]:  eta: 0:24:29  iter: 639  total_loss: 0.4321  loss_cls: 0.07429  loss_box_reg: 0.1692  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.1137    time: 1.7116  last_time: 1.6977  data_time: 0.0868  last_data_time: 0.0860   lr: 0.012787  max_mem: 20096M
[03/02 11:44:08 d2.utils.events]:  eta: 0:23:54  iter: 659  total_loss: 0.4287  loss_cls: 0.07182  loss_box_reg: 0.1666  loss_rpn_cls: 0.07036  loss_rpn_loc: 0.1206    time: 1.7106  last_time: 1.7019  data_time: 0.0909  last_data_time: 0.0968   lr: 0.013187  max_mem: 20096M
[03/02 11:44:42 d2.utils.events]:  eta: 0:23:19  iter: 679  total_loss: 0.4772  loss_cls: 0.07736  loss_box_reg: 0.1757  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.1413    time: 1.7100  last_time: 1.6579  data_time: 0.0882  last_data_time: 0.0771   lr: 0.013586  max_mem: 20096M
[03/02 11:45:16 d2.utils.events]:  eta: 0:22:44  iter: 699  total_loss: 0.4346  loss_cls: 0.07325  loss_box_reg: 0.1634  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1115    time: 1.7093  last_time: 1.6901  data_time: 0.0944  last_data_time: 0.0958   lr: 0.013986  max_mem: 20096M
[03/02 11:45:49 d2.utils.events]:  eta: 0:22:09  iter: 719  total_loss: 0.4242  loss_cls: 0.07538  loss_box_reg: 0.1639  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1204    time: 1.7086  last_time: 1.6442  data_time: 0.0918  last_data_time: 0.0756   lr: 0.014386  max_mem: 20096M
[03/02 11:46:22 d2.utils.events]:  eta: 0:21:33  iter: 739  total_loss: 0.4487  loss_cls: 0.07558  loss_box_reg: 0.1723  loss_rpn_cls: 0.06993  loss_rpn_loc: 0.1294    time: 1.7069  last_time: 1.6574  data_time: 0.0864  last_data_time: 0.0932   lr: 0.014785  max_mem: 20096M
[03/02 11:46:56 d2.utils.events]:  eta: 0:20:59  iter: 759  total_loss: 0.5087  loss_cls: 0.08534  loss_box_reg: 0.1897  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.1284    time: 1.7056  last_time: 1.6384  data_time: 0.0955  last_data_time: 0.0838   lr: 0.015185  max_mem: 20096M
[03/02 11:47:29 d2.utils.events]:  eta: 0:20:24  iter: 779  total_loss: 0.4698  loss_cls: 0.07534  loss_box_reg: 0.169  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.1389    time: 1.7049  last_time: 1.6871  data_time: 0.0981  last_data_time: 0.0817   lr: 0.015584  max_mem: 20096M
[03/02 11:48:03 d2.utils.events]:  eta: 0:19:50  iter: 799  total_loss: 0.4422  loss_cls: 0.08331  loss_box_reg: 0.1751  loss_rpn_cls: 0.07382  loss_rpn_loc: 0.1325    time: 1.7044  last_time: 1.7127  data_time: 0.0967  last_data_time: 0.0975   lr: 0.015984  max_mem: 20096M
[03/02 11:48:36 d2.utils.events]:  eta: 0:19:15  iter: 819  total_loss: 0.4243  loss_cls: 0.07539  loss_box_reg: 0.1581  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.1247    time: 1.7034  last_time: 1.7027  data_time: 0.0897  last_data_time: 0.0936   lr: 0.016384  max_mem: 20096M
[03/02 11:49:09 d2.utils.events]:  eta: 0:18:41  iter: 839  total_loss: 0.438  loss_cls: 0.07453  loss_box_reg: 0.1609  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.1282    time: 1.7024  last_time: 1.6473  data_time: 0.0892  last_data_time: 0.0775   lr: 0.016783  max_mem: 20096M
[03/02 11:49:42 d2.utils.events]:  eta: 0:18:06  iter: 859  total_loss: 0.4039  loss_cls: 0.06257  loss_box_reg: 0.1419  loss_rpn_cls: 0.06242  loss_rpn_loc: 0.1372    time: 1.7012  last_time: 1.6458  data_time: 0.0879  last_data_time: 0.0783   lr: 0.017183  max_mem: 20096M
[03/02 11:50:16 d2.utils.events]:  eta: 0:17:32  iter: 879  total_loss: 0.4192  loss_cls: 0.06684  loss_box_reg: 0.1468  loss_rpn_cls: 0.06357  loss_rpn_loc: 0.14    time: 1.7004  last_time: 1.6595  data_time: 0.0858  last_data_time: 0.0854   lr: 0.017582  max_mem: 20096M
[03/02 11:50:49 d2.utils.events]:  eta: 0:16:58  iter: 899  total_loss: 0.4086  loss_cls: 0.06615  loss_box_reg: 0.1463  loss_rpn_cls: 0.06358  loss_rpn_loc: 0.1433    time: 1.7000  last_time: 1.7558  data_time: 0.0891  last_data_time: 0.1245   lr: 0.017982  max_mem: 20096M
[03/02 11:51:23 d2.utils.events]:  eta: 0:16:24  iter: 919  total_loss: 0.4214  loss_cls: 0.07002  loss_box_reg: 0.162  loss_rpn_cls: 0.06218  loss_rpn_loc: 0.1268    time: 1.6999  last_time: 1.7003  data_time: 0.0890  last_data_time: 0.0948   lr: 0.018382  max_mem: 20096M
[03/02 11:51:56 d2.utils.events]:  eta: 0:15:49  iter: 939  total_loss: 0.4471  loss_cls: 0.08007  loss_box_reg: 0.1624  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.1137    time: 1.6989  last_time: 1.6267  data_time: 0.0822  last_data_time: 0.0808   lr: 0.018781  max_mem: 20096M
[03/02 11:52:30 d2.utils.events]:  eta: 0:15:15  iter: 959  total_loss: 0.4202  loss_cls: 0.0703  loss_box_reg: 0.1564  loss_rpn_cls: 0.05674  loss_rpn_loc: 0.1326    time: 1.6982  last_time: 1.6854  data_time: 0.0872  last_data_time: 0.0736   lr: 0.019181  max_mem: 20096M
[03/02 11:53:03 d2.utils.events]:  eta: 0:14:41  iter: 979  total_loss: 0.4096  loss_cls: 0.07042  loss_box_reg: 0.1636  loss_rpn_cls: 0.06369  loss_rpn_loc: 0.123    time: 1.6976  last_time: 1.6711  data_time: 0.0884  last_data_time: 0.1122   lr: 0.01958  max_mem: 20096M
[03/02 11:53:36 d2.utils.events]:  eta: 0:14:07  iter: 999  total_loss: 0.4189  loss_cls: 0.07122  loss_box_reg: 0.152  loss_rpn_cls: 0.06471  loss_rpn_loc: 0.1132    time: 1.6967  last_time: 1.6687  data_time: 0.0879  last_data_time: 0.0889   lr: 0.01998  max_mem: 20096M
[03/02 11:54:10 d2.utils.events]:  eta: 0:13:32  iter: 1019  total_loss: 0.4099  loss_cls: 0.07577  loss_box_reg: 0.1691  loss_rpn_cls: 0.06986  loss_rpn_loc: 0.122    time: 1.6963  last_time: 1.6794  data_time: 0.0931  last_data_time: 0.1163   lr: 0.02  max_mem: 20096M
[03/02 11:54:43 d2.utils.events]:  eta: 0:12:58  iter: 1039  total_loss: 0.4279  loss_cls: 0.06906  loss_box_reg: 0.1453  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.1387    time: 1.6956  last_time: 1.6669  data_time: 0.0889  last_data_time: 0.0722   lr: 0.02  max_mem: 20096M
[03/02 11:55:16 d2.utils.events]:  eta: 0:12:24  iter: 1059  total_loss: 0.4161  loss_cls: 0.06488  loss_box_reg: 0.1637  loss_rpn_cls: 0.0668  loss_rpn_loc: 0.1194    time: 1.6950  last_time: 1.6087  data_time: 0.0902  last_data_time: 0.0785   lr: 0.02  max_mem: 20096M
[03/02 11:55:50 d2.utils.events]:  eta: 0:11:49  iter: 1079  total_loss: 0.3942  loss_cls: 0.0671  loss_box_reg: 0.1397  loss_rpn_cls: 0.06796  loss_rpn_loc: 0.1272    time: 1.6944  last_time: 1.6426  data_time: 0.0873  last_data_time: 0.0837   lr: 0.02  max_mem: 20096M
[03/02 11:56:23 d2.utils.events]:  eta: 0:11:15  iter: 1099  total_loss: 0.3699  loss_cls: 0.0588  loss_box_reg: 0.1351  loss_rpn_cls: 0.05227  loss_rpn_loc: 0.1245    time: 1.6938  last_time: 1.6607  data_time: 0.0872  last_data_time: 0.0826   lr: 0.02  max_mem: 20096M
[03/02 11:56:57 d2.utils.events]:  eta: 0:10:41  iter: 1119  total_loss: 0.3998  loss_cls: 0.06522  loss_box_reg: 0.1397  loss_rpn_cls: 0.05388  loss_rpn_loc: 0.1209    time: 1.6936  last_time: 1.7081  data_time: 0.0922  last_data_time: 0.1106   lr: 0.02  max_mem: 20096M
[03/02 11:57:30 d2.utils.events]:  eta: 0:10:06  iter: 1139  total_loss: 0.386  loss_cls: 0.06421  loss_box_reg: 0.1482  loss_rpn_cls: 0.05811  loss_rpn_loc: 0.109    time: 1.6929  last_time: 1.6550  data_time: 0.0905  last_data_time: 0.0804   lr: 0.02  max_mem: 20096M
[03/02 11:58:03 d2.utils.events]:  eta: 0:09:32  iter: 1159  total_loss: 0.3783  loss_cls: 0.06286  loss_box_reg: 0.1476  loss_rpn_cls: 0.06046  loss_rpn_loc: 0.1144    time: 1.6926  last_time: 1.6560  data_time: 0.0880  last_data_time: 0.0798   lr: 0.02  max_mem: 20096M
[03/02 11:58:37 d2.utils.events]:  eta: 0:08:58  iter: 1179  total_loss: 0.4131  loss_cls: 0.05981  loss_box_reg: 0.1483  loss_rpn_cls: 0.06792  loss_rpn_loc: 0.1366    time: 1.6920  last_time: 1.6321  data_time: 0.0898  last_data_time: 0.0826   lr: 0.02  max_mem: 20096M
[03/02 11:59:11 d2.utils.events]:  eta: 0:08:24  iter: 1199  total_loss: 0.4039  loss_cls: 0.07019  loss_box_reg: 0.1581  loss_rpn_cls: 0.05659  loss_rpn_loc: 0.1227    time: 1.6923  last_time: 1.7206  data_time: 0.1055  last_data_time: 0.1084   lr: 0.02  max_mem: 20096M
[03/02 11:59:45 d2.utils.events]:  eta: 0:07:50  iter: 1219  total_loss: 0.4115  loss_cls: 0.06471  loss_box_reg: 0.1613  loss_rpn_cls: 0.05504  loss_rpn_loc: 0.147    time: 1.6927  last_time: 1.7219  data_time: 0.1013  last_data_time: 0.0899   lr: 0.02  max_mem: 20096M
[03/02 12:00:19 d2.utils.events]:  eta: 0:07:17  iter: 1239  total_loss: 0.3971  loss_cls: 0.07037  loss_box_reg: 0.1577  loss_rpn_cls: 0.05727  loss_rpn_loc: 0.1104    time: 1.6931  last_time: 1.7593  data_time: 0.1003  last_data_time: 0.0926   lr: 0.02  max_mem: 20096M
[03/02 12:00:53 d2.utils.events]:  eta: 0:06:43  iter: 1259  total_loss: 0.368  loss_cls: 0.06718  loss_box_reg: 0.154  loss_rpn_cls: 0.05001  loss_rpn_loc: 0.09204    time: 1.6931  last_time: 1.6857  data_time: 0.0967  last_data_time: 0.0936   lr: 0.02  max_mem: 20096M
[03/02 12:01:27 d2.utils.events]:  eta: 0:06:09  iter: 1279  total_loss: 0.3662  loss_cls: 0.0566  loss_box_reg: 0.1443  loss_rpn_cls: 0.05364  loss_rpn_loc: 0.1013    time: 1.6934  last_time: 1.7126  data_time: 0.1019  last_data_time: 0.0888   lr: 0.02  max_mem: 20096M
[03/02 12:02:02 d2.utils.events]:  eta: 0:05:36  iter: 1299  total_loss: 0.376  loss_cls: 0.06628  loss_box_reg: 0.1573  loss_rpn_cls: 0.05398  loss_rpn_loc: 0.1059    time: 1.6937  last_time: 1.7086  data_time: 0.1009  last_data_time: 0.0901   lr: 0.02  max_mem: 20096M
[03/02 12:02:36 d2.utils.events]:  eta: 0:05:02  iter: 1319  total_loss: 0.3998  loss_cls: 0.06357  loss_box_reg: 0.1636  loss_rpn_cls: 0.05736  loss_rpn_loc: 0.1075    time: 1.6937  last_time: 1.7109  data_time: 0.0904  last_data_time: 0.0939   lr: 0.02  max_mem: 20096M
[03/02 12:03:10 d2.utils.events]:  eta: 0:04:28  iter: 1339  total_loss: 0.3856  loss_cls: 0.06163  loss_box_reg: 0.1425  loss_rpn_cls: 0.05304  loss_rpn_loc: 0.1142    time: 1.6940  last_time: 1.7582  data_time: 0.0992  last_data_time: 0.1274   lr: 0.02  max_mem: 20096M
[03/02 12:03:44 d2.utils.events]:  eta: 0:03:55  iter: 1359  total_loss: 0.3917  loss_cls: 0.06099  loss_box_reg: 0.1446  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.1249    time: 1.6940  last_time: 1.6947  data_time: 0.0912  last_data_time: 0.0799   lr: 0.02  max_mem: 20096M
[03/02 12:04:18 d2.utils.events]:  eta: 0:03:21  iter: 1379  total_loss: 0.3898  loss_cls: 0.06244  loss_box_reg: 0.1445  loss_rpn_cls: 0.06145  loss_rpn_loc: 0.1187    time: 1.6941  last_time: 1.6574  data_time: 0.0955  last_data_time: 0.0923   lr: 0.02  max_mem: 20096M
[03/02 12:04:52 d2.utils.events]:  eta: 0:02:48  iter: 1399  total_loss: 0.3821  loss_cls: 0.06137  loss_box_reg: 0.146  loss_rpn_cls: 0.05162  loss_rpn_loc: 0.1117    time: 1.6943  last_time: 1.6720  data_time: 0.0985  last_data_time: 0.0909   lr: 0.02  max_mem: 20096M
[03/02 12:05:25 d2.utils.events]:  eta: 0:02:14  iter: 1419  total_loss: 0.3608  loss_cls: 0.0586  loss_box_reg: 0.1474  loss_rpn_cls: 0.05354  loss_rpn_loc: 0.1091    time: 1.6940  last_time: 1.6540  data_time: 0.0986  last_data_time: 0.0902   lr: 0.02  max_mem: 20096M
[03/02 12:05:59 d2.utils.events]:  eta: 0:01:40  iter: 1439  total_loss: 0.3986  loss_cls: 0.06131  loss_box_reg: 0.1462  loss_rpn_cls: 0.06133  loss_rpn_loc: 0.1348    time: 1.6936  last_time: 1.6593  data_time: 0.0994  last_data_time: 0.1134   lr: 0.02  max_mem: 20096M
[03/02 12:06:32 d2.utils.events]:  eta: 0:01:07  iter: 1459  total_loss: 0.386  loss_cls: 0.06268  loss_box_reg: 0.142  loss_rpn_cls: 0.05571  loss_rpn_loc: 0.1312    time: 1.6931  last_time: 1.6786  data_time: 0.0939  last_data_time: 0.0933   lr: 0.02  max_mem: 20096M
[03/02 12:07:05 d2.utils.events]:  eta: 0:00:33  iter: 1479  total_loss: 0.3701  loss_cls: 0.05295  loss_box_reg: 0.1421  loss_rpn_cls: 0.05063  loss_rpn_loc: 0.08898    time: 1.6928  last_time: 1.7011  data_time: 0.0972  last_data_time: 0.1081   lr: 0.02  max_mem: 20096M
[03/02 12:07:40 d2.utils.events]:  eta: 0:00:00  iter: 1499  total_loss: 0.3698  loss_cls: 0.05731  loss_box_reg: 0.1448  loss_rpn_cls: 0.05191  loss_rpn_loc: 0.1042    time: 1.6925  last_time: 1.6564  data_time: 0.1021  last_data_time: 0.1058   lr: 0.02  max_mem: 20096M
[03/02 12:07:40 d2.engine.hooks]: Overall training speed: 1498 iterations in 0:42:15 (1.6925 s / it)
[03/02 12:07:40 d2.engine.hooks]: Total training time: 0:42:25 (0:00:10 on hooks)
[03/02 12:07:42 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 8021         | pedestrian | 3347         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 2765         |            |              |
|   total    | 14133        |            |              |            |              |
[03/02 12:07:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/02 12:07:42 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/02 12:07:42 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/02 12:07:42 d2.data.common]: Serialized dataset takes 5.86 MiB
WARNING [03/02 12:07:42 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[03/02 12:07:43 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /ghome/group07/C5-W2/fastr_lr_0_02_bs_128_is_16/model_0001499.pth ...
[03/02 12:07:45 d2.evaluation.coco_evaluation]: Trying to convert 'KITTI-MOTS_val' to COCO format ...
[03/02 12:07:45 d2.data.datasets.coco]: Converting annotations of dataset 'KITTI-MOTS_val' to COCO format ...)
[03/02 12:07:47 d2.data.datasets.coco]: Converting dataset dicts into COCO format
[03/02 12:07:47 d2.data.datasets.coco]: Conversion finished, #images: 2919, #annotations: 14133
[03/02 12:07:47 d2.data.datasets.coco]: Caching COCO format annotations at '/ghome/group07/C5-W2/fastr_lr_0_02_bs_128_is_16/KITTI-MOTS_val_coco_format.json' ...
[03/02 12:07:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/02 12:07:50 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/02 12:07:50 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/02 12:07:50 d2.data.common]: Serialized dataset takes 5.86 MiB
[03/02 12:07:50 d2.evaluation.evaluator]: Start inference on 2919 batches
[03/02 12:07:52 d2.evaluation.evaluator]: Inference done 11/2919. Dataloading: 0.0023 s/iter. Inference: 0.1066 s/iter. Eval: 0.0002 s/iter. Total: 0.1091 s/iter. ETA=0:05:17
[03/02 12:07:57 d2.evaluation.evaluator]: Inference done 57/2919. Dataloading: 0.0029 s/iter. Inference: 0.1059 s/iter. Eval: 0.0002 s/iter. Total: 0.1092 s/iter. ETA=0:05:12
[03/02 12:08:03 d2.evaluation.evaluator]: Inference done 105/2919. Dataloading: 0.0030 s/iter. Inference: 0.1037 s/iter. Eval: 0.0002 s/iter. Total: 0.1071 s/iter. ETA=0:05:01
[03/02 12:08:08 d2.evaluation.evaluator]: Inference done 149/2919. Dataloading: 0.0030 s/iter. Inference: 0.1066 s/iter. Eval: 0.0002 s/iter. Total: 0.1099 s/iter. ETA=0:05:04
[03/02 12:08:13 d2.evaluation.evaluator]: Inference done 194/2919. Dataloading: 0.0030 s/iter. Inference: 0.1069 s/iter. Eval: 0.0002 s/iter. Total: 0.1102 s/iter. ETA=0:05:00
[03/02 12:08:18 d2.evaluation.evaluator]: Inference done 243/2919. Dataloading: 0.0030 s/iter. Inference: 0.1053 s/iter. Eval: 0.0002 s/iter. Total: 0.1087 s/iter. ETA=0:04:50
[03/02 12:08:23 d2.evaluation.evaluator]: Inference done 292/2919. Dataloading: 0.0030 s/iter. Inference: 0.1043 s/iter. Eval: 0.0002 s/iter. Total: 0.1076 s/iter. ETA=0:04:42
[03/02 12:08:28 d2.evaluation.evaluator]: Inference done 341/2919. Dataloading: 0.0030 s/iter. Inference: 0.1038 s/iter. Eval: 0.0002 s/iter. Total: 0.1071 s/iter. ETA=0:04:36
[03/02 12:08:33 d2.evaluation.evaluator]: Inference done 390/2919. Dataloading: 0.0030 s/iter. Inference: 0.1033 s/iter. Eval: 0.0002 s/iter. Total: 0.1066 s/iter. ETA=0:04:29
[03/02 12:08:38 d2.evaluation.evaluator]: Inference done 438/2919. Dataloading: 0.0030 s/iter. Inference: 0.1031 s/iter. Eval: 0.0002 s/iter. Total: 0.1064 s/iter. ETA=0:04:23
[03/02 12:08:43 d2.evaluation.evaluator]: Inference done 487/2919. Dataloading: 0.0030 s/iter. Inference: 0.1028 s/iter. Eval: 0.0002 s/iter. Total: 0.1061 s/iter. ETA=0:04:18
[03/02 12:08:48 d2.evaluation.evaluator]: Inference done 536/2919. Dataloading: 0.0030 s/iter. Inference: 0.1025 s/iter. Eval: 0.0002 s/iter. Total: 0.1058 s/iter. ETA=0:04:12
[03/02 12:08:53 d2.evaluation.evaluator]: Inference done 585/2919. Dataloading: 0.0030 s/iter. Inference: 0.1024 s/iter. Eval: 0.0002 s/iter. Total: 0.1057 s/iter. ETA=0:04:06
[03/02 12:08:58 d2.evaluation.evaluator]: Inference done 632/2919. Dataloading: 0.0030 s/iter. Inference: 0.1026 s/iter. Eval: 0.0002 s/iter. Total: 0.1059 s/iter. ETA=0:04:02
[03/02 12:09:03 d2.evaluation.evaluator]: Inference done 680/2919. Dataloading: 0.0030 s/iter. Inference: 0.1025 s/iter. Eval: 0.0002 s/iter. Total: 0.1058 s/iter. ETA=0:03:56
[03/02 12:09:08 d2.evaluation.evaluator]: Inference done 727/2919. Dataloading: 0.0030 s/iter. Inference: 0.1025 s/iter. Eval: 0.0002 s/iter. Total: 0.1058 s/iter. ETA=0:03:51
[03/02 12:09:13 d2.evaluation.evaluator]: Inference done 775/2919. Dataloading: 0.0030 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1058 s/iter. ETA=0:03:46
[03/02 12:09:18 d2.evaluation.evaluator]: Inference done 824/2919. Dataloading: 0.0030 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1056 s/iter. ETA=0:03:41
[03/02 12:09:23 d2.evaluation.evaluator]: Inference done 871/2919. Dataloading: 0.0030 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1057 s/iter. ETA=0:03:36
[03/02 12:09:28 d2.evaluation.evaluator]: Inference done 920/2919. Dataloading: 0.0030 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1055 s/iter. ETA=0:03:30
[03/02 12:09:33 d2.evaluation.evaluator]: Inference done 968/2919. Dataloading: 0.0030 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1055 s/iter. ETA=0:03:25
[03/02 12:09:38 d2.evaluation.evaluator]: Inference done 1016/2919. Dataloading: 0.0030 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1055 s/iter. ETA=0:03:20
[03/02 12:09:44 d2.evaluation.evaluator]: Inference done 1064/2919. Dataloading: 0.0031 s/iter. Inference: 0.1021 s/iter. Eval: 0.0002 s/iter. Total: 0.1055 s/iter. ETA=0:03:15
[03/02 12:09:49 d2.evaluation.evaluator]: Inference done 1113/2919. Dataloading: 0.0030 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1054 s/iter. ETA=0:03:10
[03/02 12:09:54 d2.evaluation.evaluator]: Inference done 1162/2919. Dataloading: 0.0030 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1054 s/iter. ETA=0:03:05
[03/02 12:09:59 d2.evaluation.evaluator]: Inference done 1210/2919. Dataloading: 0.0030 s/iter. Inference: 0.1020 s/iter. Eval: 0.0002 s/iter. Total: 0.1054 s/iter. ETA=0:03:00
[03/02 12:10:04 d2.evaluation.evaluator]: Inference done 1259/2919. Dataloading: 0.0030 s/iter. Inference: 0.1020 s/iter. Eval: 0.0002 s/iter. Total: 0.1053 s/iter. ETA=0:02:54
[03/02 12:10:09 d2.evaluation.evaluator]: Inference done 1310/2919. Dataloading: 0.0030 s/iter. Inference: 0.1018 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:02:49
[03/02 12:10:14 d2.evaluation.evaluator]: Inference done 1360/2919. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.0002 s/iter. Total: 0.1050 s/iter. ETA=0:02:43
[03/02 12:10:19 d2.evaluation.evaluator]: Inference done 1409/2919. Dataloading: 0.0030 s/iter. Inference: 0.1016 s/iter. Eval: 0.0002 s/iter. Total: 0.1049 s/iter. ETA=0:02:38
[03/02 12:10:24 d2.evaluation.evaluator]: Inference done 1458/2919. Dataloading: 0.0030 s/iter. Inference: 0.1015 s/iter. Eval: 0.0002 s/iter. Total: 0.1048 s/iter. ETA=0:02:33
[03/02 12:10:29 d2.evaluation.evaluator]: Inference done 1507/2919. Dataloading: 0.0030 s/iter. Inference: 0.1014 s/iter. Eval: 0.0002 s/iter. Total: 0.1048 s/iter. ETA=0:02:27
[03/02 12:10:34 d2.evaluation.evaluator]: Inference done 1554/2919. Dataloading: 0.0030 s/iter. Inference: 0.1015 s/iter. Eval: 0.0002 s/iter. Total: 0.1049 s/iter. ETA=0:02:23
[03/02 12:10:39 d2.evaluation.evaluator]: Inference done 1602/2919. Dataloading: 0.0030 s/iter. Inference: 0.1015 s/iter. Eval: 0.0002 s/iter. Total: 0.1049 s/iter. ETA=0:02:18
[03/02 12:10:44 d2.evaluation.evaluator]: Inference done 1651/2919. Dataloading: 0.0030 s/iter. Inference: 0.1015 s/iter. Eval: 0.0002 s/iter. Total: 0.1048 s/iter. ETA=0:02:12
[03/02 12:10:49 d2.evaluation.evaluator]: Inference done 1700/2919. Dataloading: 0.0030 s/iter. Inference: 0.1014 s/iter. Eval: 0.0002 s/iter. Total: 0.1048 s/iter. ETA=0:02:07
[03/02 12:10:54 d2.evaluation.evaluator]: Inference done 1744/2919. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.0002 s/iter. Total: 0.1050 s/iter. ETA=0:02:03
[03/02 12:10:59 d2.evaluation.evaluator]: Inference done 1791/2919. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:58
[03/02 12:11:05 d2.evaluation.evaluator]: Inference done 1839/2919. Dataloading: 0.0030 s/iter. Inference: 0.1018 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:53
[03/02 12:11:10 d2.evaluation.evaluator]: Inference done 1887/2919. Dataloading: 0.0030 s/iter. Inference: 0.1018 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:48
[03/02 12:11:15 d2.evaluation.evaluator]: Inference done 1936/2919. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.0002 s/iter. Total: 0.1050 s/iter. ETA=0:01:43
[03/02 12:11:20 d2.evaluation.evaluator]: Inference done 1983/2919. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:38
[03/02 12:11:25 d2.evaluation.evaluator]: Inference done 2031/2919. Dataloading: 0.0030 s/iter. Inference: 0.1018 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:33
[03/02 12:11:30 d2.evaluation.evaluator]: Inference done 2079/2919. Dataloading: 0.0030 s/iter. Inference: 0.1018 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:28
[03/02 12:11:35 d2.evaluation.evaluator]: Inference done 2128/2919. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:23
[03/02 12:11:40 d2.evaluation.evaluator]: Inference done 2176/2919. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:18
[03/02 12:11:45 d2.evaluation.evaluator]: Inference done 2223/2919. Dataloading: 0.0030 s/iter. Inference: 0.1018 s/iter. Eval: 0.0002 s/iter. Total: 0.1051 s/iter. ETA=0:01:13
[03/02 12:11:50 d2.evaluation.evaluator]: Inference done 2269/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0002 s/iter. Total: 0.1052 s/iter. ETA=0:01:08
[03/02 12:11:55 d2.evaluation.evaluator]: Inference done 2317/2919. Dataloading: 0.0030 s/iter. Inference: 0.1018 s/iter. Eval: 0.0003 s/iter. Total: 0.1052 s/iter. ETA=0:01:03
[03/02 12:12:00 d2.evaluation.evaluator]: Inference done 2365/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1052 s/iter. ETA=0:00:58
[03/02 12:12:05 d2.evaluation.evaluator]: Inference done 2412/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:53
[03/02 12:12:10 d2.evaluation.evaluator]: Inference done 2459/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:48
[03/02 12:12:15 d2.evaluation.evaluator]: Inference done 2507/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:43
[03/02 12:12:20 d2.evaluation.evaluator]: Inference done 2555/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:38
[03/02 12:12:25 d2.evaluation.evaluator]: Inference done 2604/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:33
[03/02 12:12:30 d2.evaluation.evaluator]: Inference done 2652/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:28
[03/02 12:12:35 d2.evaluation.evaluator]: Inference done 2699/2919. Dataloading: 0.0030 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:23
[03/02 12:12:41 d2.evaluation.evaluator]: Inference done 2746/2919. Dataloading: 0.0030 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:00:18
[03/02 12:12:46 d2.evaluation.evaluator]: Inference done 2792/2919. Dataloading: 0.0030 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1054 s/iter. ETA=0:00:13
[03/02 12:12:51 d2.evaluation.evaluator]: Inference done 2839/2919. Dataloading: 0.0030 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1054 s/iter. ETA=0:00:08
[03/02 12:12:56 d2.evaluation.evaluator]: Inference done 2887/2919. Dataloading: 0.0030 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1054 s/iter. ETA=0:00:03
[03/02 12:12:59 d2.evaluation.evaluator]: Total inference time: 0:05:07.211937 (0.105426 s / iter per device, on 1 devices)
[03/02 12:12:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:57 (0.102023 s / iter per device, on 1 devices)
[03/02 12:12:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[03/02 12:12:59 d2.evaluation.coco_evaluation]: Saving results to /ghome/group07/C5-W2/fastr_lr_0_02_bs_128_is_16/coco_instances_results.json
[03/02 12:12:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.11s)
creating index...
index created!
[03/02 12:12:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[03/02 12:13:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 1.71 seconds.
[03/02 12:13:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[03/02 12:13:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.17 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
[03/02 12:13:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.343 | 57.371 | 42.979 | 21.896 | 47.267 | 51.242 |
[03/02 12:13:01 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 62.275 | pedestrian | 48.960 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 3.793  |            |        |
OrderedDict([('bbox', {'AP': 38.34264566925623, 'AP50': 57.37112989183609, 'AP75': 42.97943981860413, 'APs': 21.89593305268116, 'APm': 47.26688230297953, 'APl': 51.242419474204304, 'AP-background': nan, 'AP-car': 62.27490335429334, 'AP-pedestrian': 48.95975100827318, 'AP-': nan, 'AP-ignore': 3.793282645202143})])
