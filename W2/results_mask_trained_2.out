1
The device we will be working on is: cuda
[02/29 23:49:10 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[02/29 23:49:13 d2.data.build]: Removed 0 images with no usable annotations. 5007 images left.
[02/29 23:49:14 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 18822        | pedestrian | 8065         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 4977         |            |              |
|   total    | 31864        |            |              |            |              |
[02/29 23:49:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[02/29 23:49:14 d2.data.build]: Using training sampler TrainingSampler
[02/29 23:49:14 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[02/29 23:49:14 d2.data.common]: Serializing 5007 elements to byte tensors and concatenating them all ...
[02/29 23:49:14 d2.data.common]: Serialized dataset takes 13.56 MiB
[02/29 23:49:14 d2.data.build]: Making batched data loader with batch_size=8
WARNING [02/29 23:49:14 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[02/29 23:49:14 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...
[02/29 23:49:14 d2.engine.train_loop]: Starting training from iteration 0
[02/29 23:49:30 d2.utils.events]:  eta: 0:13:22  iter: 19  total_loss: 3.982  loss_cls: 2.576  loss_box_reg: 0.4513  loss_mask: 0.6941  loss_rpn_cls: 0.1671  loss_rpn_loc: 0.08493    time: 0.5558  last_time: 0.5288  data_time: 0.1352  last_data_time: 0.0669   lr: 3.9962e-06  max_mem: 8179M
[02/29 23:49:49 d2.utils.events]:  eta: 0:13:25  iter: 39  total_loss: 3.962  loss_cls: 2.482  loss_box_reg: 0.5233  loss_mask: 0.6884  loss_rpn_cls: 0.18  loss_rpn_loc: 0.09137    time: 0.5604  last_time: 0.5603  data_time: 0.0702  last_data_time: 0.0808   lr: 7.9922e-06  max_mem: 8496M
[02/29 23:50:00 d2.utils.events]:  eta: 0:13:18  iter: 59  total_loss: 3.704  loss_cls: 2.289  loss_box_reg: 0.5167  loss_mask: 0.6768  loss_rpn_cls: 0.1524  loss_rpn_loc: 0.09165    time: 0.5620  last_time: 0.5362  data_time: 0.0760  last_data_time: 0.0634   lr: 1.1988e-05  max_mem: 8580M
[02/29 23:50:12 d2.utils.events]:  eta: 0:13:07  iter: 79  total_loss: 3.373  loss_cls: 1.962  loss_box_reg: 0.4587  loss_mask: 0.6609  loss_rpn_cls: 0.1396  loss_rpn_loc: 0.0722    time: 0.5639  last_time: 0.5745  data_time: 0.0711  last_data_time: 0.0827   lr: 1.5984e-05  max_mem: 8580M
[02/29 23:50:23 d2.utils.events]:  eta: 0:12:55  iter: 99  total_loss: 2.939  loss_cls: 1.567  loss_box_reg: 0.4119  loss_mask: 0.6437  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.068    time: 0.5606  last_time: 0.5792  data_time: 0.0651  last_data_time: 0.0738   lr: 1.998e-05  max_mem: 8580M
[02/29 23:50:34 d2.utils.events]:  eta: 0:12:46  iter: 119  total_loss: 2.459  loss_cls: 1.168  loss_box_reg: 0.4446  loss_mask: 0.6189  loss_rpn_cls: 0.1224  loss_rpn_loc: 0.0826    time: 0.5615  last_time: 0.5746  data_time: 0.0726  last_data_time: 0.0610   lr: 2.3976e-05  max_mem: 8580M
[02/29 23:50:45 d2.utils.events]:  eta: 0:12:37  iter: 139  total_loss: 2.065  loss_cls: 0.817  loss_box_reg: 0.441  loss_mask: 0.5888  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.07721    time: 0.5624  last_time: 0.5579  data_time: 0.0697  last_data_time: 0.0856   lr: 2.7972e-05  max_mem: 8696M
[02/29 23:50:56 d2.utils.events]:  eta: 0:12:24  iter: 159  total_loss: 1.753  loss_cls: 0.5613  loss_box_reg: 0.3844  loss_mask: 0.5625  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.07851    time: 0.5594  last_time: 0.5776  data_time: 0.0681  last_data_time: 0.0747   lr: 3.1968e-05  max_mem: 8696M
[02/29 23:51:07 d2.utils.events]:  eta: 0:12:13  iter: 179  total_loss: 1.751  loss_cls: 0.5605  loss_box_reg: 0.4445  loss_mask: 0.5496  loss_rpn_cls: 0.102  loss_rpn_loc: 0.08263    time: 0.5596  last_time: 0.5404  data_time: 0.0684  last_data_time: 0.0812   lr: 3.5964e-05  max_mem: 8696M
[02/29 23:51:18 d2.utils.events]:  eta: 0:12:03  iter: 199  total_loss: 1.605  loss_cls: 0.485  loss_box_reg: 0.4463  loss_mask: 0.5078  loss_rpn_cls: 0.0849  loss_rpn_loc: 0.06616    time: 0.5593  last_time: 0.5652  data_time: 0.0737  last_data_time: 0.0665   lr: 3.996e-05  max_mem: 8696M
[02/29 23:51:30 d2.utils.events]:  eta: 0:11:53  iter: 219  total_loss: 1.604  loss_cls: 0.4996  loss_box_reg: 0.4759  loss_mask: 0.4763  loss_rpn_cls: 0.08128  loss_rpn_loc: 0.08195    time: 0.5601  last_time: 0.5616  data_time: 0.0735  last_data_time: 0.0807   lr: 4.3956e-05  max_mem: 8696M
[02/29 23:51:41 d2.utils.events]:  eta: 0:11:42  iter: 239  total_loss: 1.583  loss_cls: 0.4569  loss_box_reg: 0.4418  loss_mask: 0.4591  loss_rpn_cls: 0.07675  loss_rpn_loc: 0.06998    time: 0.5606  last_time: 0.5687  data_time: 0.0721  last_data_time: 0.0874   lr: 4.7952e-05  max_mem: 8696M
[02/29 23:51:52 d2.utils.events]:  eta: 0:11:31  iter: 259  total_loss: 1.515  loss_cls: 0.4341  loss_box_reg: 0.4584  loss_mask: 0.4601  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.07337    time: 0.5604  last_time: 0.5426  data_time: 0.0672  last_data_time: 0.0730   lr: 5.1948e-05  max_mem: 8696M
[02/29 23:52:03 d2.utils.events]:  eta: 0:11:20  iter: 279  total_loss: 1.474  loss_cls: 0.3823  loss_box_reg: 0.4322  loss_mask: 0.436  loss_rpn_cls: 0.06299  loss_rpn_loc: 0.07614    time: 0.5604  last_time: 0.5882  data_time: 0.0677  last_data_time: 0.0557   lr: 5.5944e-05  max_mem: 8696M
[02/29 23:52:15 d2.utils.events]:  eta: 0:11:08  iter: 299  total_loss: 1.408  loss_cls: 0.3769  loss_box_reg: 0.4091  loss_mask: 0.4354  loss_rpn_cls: 0.06611  loss_rpn_loc: 0.08308    time: 0.5598  last_time: 0.5990  data_time: 0.0647  last_data_time: 0.0499   lr: 5.994e-05  max_mem: 8696M
[02/29 23:52:26 d2.utils.events]:  eta: 0:10:57  iter: 319  total_loss: 1.285  loss_cls: 0.3347  loss_box_reg: 0.4165  loss_mask: 0.3925  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.07935    time: 0.5601  last_time: 0.5405  data_time: 0.0688  last_data_time: 0.0750   lr: 6.3936e-05  max_mem: 8696M
[02/29 23:52:37 d2.utils.events]:  eta: 0:10:46  iter: 339  total_loss: 1.24  loss_cls: 0.3155  loss_box_reg: 0.3949  loss_mask: 0.397  loss_rpn_cls: 0.05826  loss_rpn_loc: 0.07777    time: 0.5595  last_time: 0.5219  data_time: 0.0627  last_data_time: 0.0541   lr: 6.7932e-05  max_mem: 8696M
[02/29 23:52:49 d2.utils.events]:  eta: 0:10:35  iter: 359  total_loss: 1.212  loss_cls: 0.3191  loss_box_reg: 0.3946  loss_mask: 0.3531  loss_rpn_cls: 0.05827  loss_rpn_loc: 0.07383    time: 0.5595  last_time: 0.6281  data_time: 0.0672  last_data_time: 0.0703   lr: 7.1928e-05  max_mem: 8696M
[02/29 23:53:00 d2.utils.events]:  eta: 0:10:24  iter: 379  total_loss: 1.245  loss_cls: 0.3136  loss_box_reg: 0.4186  loss_mask: 0.3795  loss_rpn_cls: 0.05887  loss_rpn_loc: 0.08426    time: 0.5596  last_time: 0.5678  data_time: 0.0652  last_data_time: 0.0694   lr: 7.5924e-05  max_mem: 8696M
[02/29 23:53:11 d2.utils.events]:  eta: 0:10:13  iter: 399  total_loss: 1.134  loss_cls: 0.2819  loss_box_reg: 0.3795  loss_mask: 0.3532  loss_rpn_cls: 0.04665  loss_rpn_loc: 0.07295    time: 0.5600  last_time: 0.5711  data_time: 0.0673  last_data_time: 0.0577   lr: 7.992e-05  max_mem: 8696M
[02/29 23:53:23 d2.utils.events]:  eta: 0:10:03  iter: 419  total_loss: 1.193  loss_cls: 0.2952  loss_box_reg: 0.4316  loss_mask: 0.3458  loss_rpn_cls: 0.04828  loss_rpn_loc: 0.07091    time: 0.5607  last_time: 0.5312  data_time: 0.0683  last_data_time: 0.0348   lr: 8.3916e-05  max_mem: 8696M
[02/29 23:53:34 d2.utils.events]:  eta: 0:09:53  iter: 439  total_loss: 1.117  loss_cls: 0.2621  loss_box_reg: 0.3827  loss_mask: 0.331  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.08154    time: 0.5612  last_time: 0.5330  data_time: 0.0697  last_data_time: 0.0515   lr: 8.7912e-05  max_mem: 8696M
[02/29 23:53:45 d2.utils.events]:  eta: 0:09:41  iter: 459  total_loss: 1.052  loss_cls: 0.2564  loss_box_reg: 0.3402  loss_mask: 0.3224  loss_rpn_cls: 0.05336  loss_rpn_loc: 0.06717    time: 0.5614  last_time: 0.5501  data_time: 0.0685  last_data_time: 0.0614   lr: 9.1908e-05  max_mem: 8696M
[02/29 23:53:57 d2.utils.events]:  eta: 0:09:32  iter: 479  total_loss: 1.037  loss_cls: 0.2468  loss_box_reg: 0.3542  loss_mask: 0.3148  loss_rpn_cls: 0.04901  loss_rpn_loc: 0.06648    time: 0.5622  last_time: 0.6228  data_time: 0.0725  last_data_time: 0.0863   lr: 9.5904e-05  max_mem: 8696M
[02/29 23:54:09 d2.utils.events]:  eta: 0:09:20  iter: 499  total_loss: 1.024  loss_cls: 0.2395  loss_box_reg: 0.3255  loss_mask: 0.307  loss_rpn_cls: 0.04235  loss_rpn_loc: 0.06882    time: 0.5621  last_time: 0.5447  data_time: 0.0699  last_data_time: 0.0692   lr: 9.99e-05  max_mem: 8696M
[02/29 23:54:21 d2.utils.events]:  eta: 0:09:09  iter: 519  total_loss: 0.9362  loss_cls: 0.216  loss_box_reg: 0.3091  loss_mask: 0.2899  loss_rpn_cls: 0.04459  loss_rpn_loc: 0.0706    time: 0.5621  last_time: 0.5187  data_time: 0.0672  last_data_time: 0.0484   lr: 0.0001039  max_mem: 8696M
[02/29 23:54:32 d2.utils.events]:  eta: 0:08:57  iter: 539  total_loss: 0.9779  loss_cls: 0.2289  loss_box_reg: 0.3018  loss_mask: 0.3113  loss_rpn_cls: 0.04613  loss_rpn_loc: 0.0748    time: 0.5618  last_time: 0.5424  data_time: 0.0671  last_data_time: 0.0819   lr: 0.00010789  max_mem: 8696M
[02/29 23:54:43 d2.utils.events]:  eta: 0:08:47  iter: 559  total_loss: 0.9562  loss_cls: 0.2339  loss_box_reg: 0.3386  loss_mask: 0.2819  loss_rpn_cls: 0.04802  loss_rpn_loc: 0.07002    time: 0.5620  last_time: 0.5639  data_time: 0.0728  last_data_time: 0.0780   lr: 0.00011189  max_mem: 8696M
[02/29 23:54:54 d2.utils.events]:  eta: 0:08:35  iter: 579  total_loss: 0.8785  loss_cls: 0.1985  loss_box_reg: 0.2659  loss_mask: 0.2667  loss_rpn_cls: 0.04073  loss_rpn_loc: 0.07001    time: 0.5618  last_time: 0.5176  data_time: 0.0636  last_data_time: 0.0363   lr: 0.00011588  max_mem: 8696M
[02/29 23:55:05 d2.utils.events]:  eta: 0:08:24  iter: 599  total_loss: 0.9257  loss_cls: 0.2103  loss_box_reg: 0.2974  loss_mask: 0.2981  loss_rpn_cls: 0.038  loss_rpn_loc: 0.06602    time: 0.5615  last_time: 0.5072  data_time: 0.0688  last_data_time: 0.0474   lr: 0.00011988  max_mem: 8696M
[02/29 23:55:16 d2.utils.events]:  eta: 0:08:13  iter: 619  total_loss: 0.8385  loss_cls: 0.1782  loss_box_reg: 0.2403  loss_mask: 0.2781  loss_rpn_cls: 0.04553  loss_rpn_loc: 0.07726    time: 0.5613  last_time: 0.5479  data_time: 0.0687  last_data_time: 0.0768   lr: 0.00012388  max_mem: 8696M
[02/29 23:55:27 d2.utils.events]:  eta: 0:08:01  iter: 639  total_loss: 0.8319  loss_cls: 0.1859  loss_box_reg: 0.2598  loss_mask: 0.291  loss_rpn_cls: 0.03709  loss_rpn_loc: 0.06535    time: 0.5611  last_time: 0.5435  data_time: 0.0718  last_data_time: 0.0620   lr: 0.00012787  max_mem: 8696M
[02/29 23:55:39 d2.utils.events]:  eta: 0:07:50  iter: 659  total_loss: 0.842  loss_cls: 0.1954  loss_box_reg: 0.2794  loss_mask: 0.2639  loss_rpn_cls: 0.04273  loss_rpn_loc: 0.06736    time: 0.5613  last_time: 0.5907  data_time: 0.0721  last_data_time: 0.0878   lr: 0.00013187  max_mem: 8696M
[02/29 23:55:50 d2.utils.events]:  eta: 0:07:39  iter: 679  total_loss: 0.8739  loss_cls: 0.1947  loss_box_reg: 0.2738  loss_mask: 0.278  loss_rpn_cls: 0.04172  loss_rpn_loc: 0.06917    time: 0.5615  last_time: 0.5890  data_time: 0.0683  last_data_time: 0.0534   lr: 0.00013586  max_mem: 8696M
[02/29 23:56:01 d2.utils.events]:  eta: 0:07:28  iter: 699  total_loss: 0.8351  loss_cls: 0.17  loss_box_reg: 0.25  loss_mask: 0.2644  loss_rpn_cls: 0.04103  loss_rpn_loc: 0.07955    time: 0.5615  last_time: 0.5214  data_time: 0.0660  last_data_time: 0.0396   lr: 0.00013986  max_mem: 8696M
[02/29 23:56:12 d2.utils.events]:  eta: 0:07:17  iter: 719  total_loss: 0.8231  loss_cls: 0.1869  loss_box_reg: 0.2642  loss_mask: 0.2708  loss_rpn_cls: 0.03251  loss_rpn_loc: 0.06625    time: 0.5613  last_time: 0.5325  data_time: 0.0667  last_data_time: 0.0501   lr: 0.00014386  max_mem: 8696M
[02/29 23:56:24 d2.utils.events]:  eta: 0:07:06  iter: 739  total_loss: 0.8051  loss_cls: 0.171  loss_box_reg: 0.2589  loss_mask: 0.2655  loss_rpn_cls: 0.03799  loss_rpn_loc: 0.07259    time: 0.5620  last_time: 0.5725  data_time: 0.0787  last_data_time: 0.0720   lr: 0.00014785  max_mem: 8696M
[02/29 23:56:35 d2.utils.events]:  eta: 0:06:55  iter: 759  total_loss: 0.8434  loss_cls: 0.1728  loss_box_reg: 0.2546  loss_mask: 0.264  loss_rpn_cls: 0.03863  loss_rpn_loc: 0.06407    time: 0.5621  last_time: 0.5671  data_time: 0.0629  last_data_time: 0.0779   lr: 0.00015185  max_mem: 8696M
[02/29 23:56:47 d2.utils.events]:  eta: 0:06:44  iter: 779  total_loss: 0.8421  loss_cls: 0.1805  loss_box_reg: 0.262  loss_mask: 0.2776  loss_rpn_cls: 0.0409  loss_rpn_loc: 0.08524    time: 0.5624  last_time: 0.5638  data_time: 0.0734  last_data_time: 0.0608   lr: 0.00015584  max_mem: 8696M
[02/29 23:56:59 d2.utils.events]:  eta: 0:06:33  iter: 799  total_loss: 0.773  loss_cls: 0.1545  loss_box_reg: 0.231  loss_mask: 0.2561  loss_rpn_cls: 0.03791  loss_rpn_loc: 0.07433    time: 0.5628  last_time: 0.5599  data_time: 0.0720  last_data_time: 0.0755   lr: 0.00015984  max_mem: 8696M
[02/29 23:57:10 d2.utils.events]:  eta: 0:06:21  iter: 819  total_loss: 0.7414  loss_cls: 0.1432  loss_box_reg: 0.2083  loss_mask: 0.2531  loss_rpn_cls: 0.037  loss_rpn_loc: 0.08505    time: 0.5627  last_time: 0.5360  data_time: 0.0695  last_data_time: 0.0809   lr: 0.00016384  max_mem: 8696M
[02/29 23:57:21 d2.utils.events]:  eta: 0:06:10  iter: 839  total_loss: 0.7268  loss_cls: 0.1555  loss_box_reg: 0.216  loss_mask: 0.2535  loss_rpn_cls: 0.03569  loss_rpn_loc: 0.07433    time: 0.5626  last_time: 0.5650  data_time: 0.0711  last_data_time: 0.0785   lr: 0.00016783  max_mem: 8696M
[02/29 23:57:32 d2.utils.events]:  eta: 0:05:59  iter: 859  total_loss: 0.8349  loss_cls: 0.1612  loss_box_reg: 0.2523  loss_mask: 0.2726  loss_rpn_cls: 0.04205  loss_rpn_loc: 0.07678    time: 0.5627  last_time: 0.6202  data_time: 0.0700  last_data_time: 0.0727   lr: 0.00017183  max_mem: 8696M
[02/29 23:57:43 d2.utils.events]:  eta: 0:05:48  iter: 879  total_loss: 0.7238  loss_cls: 0.1426  loss_box_reg: 0.2101  loss_mask: 0.2548  loss_rpn_cls: 0.03757  loss_rpn_loc: 0.06264    time: 0.5622  last_time: 0.5747  data_time: 0.0628  last_data_time: 0.0769   lr: 0.00017582  max_mem: 8696M
[02/29 23:57:55 d2.utils.events]:  eta: 0:05:36  iter: 899  total_loss: 0.812  loss_cls: 0.1534  loss_box_reg: 0.2481  loss_mask: 0.2618  loss_rpn_cls: 0.03814  loss_rpn_loc: 0.08439    time: 0.5624  last_time: 0.6006  data_time: 0.0697  last_data_time: 0.0767   lr: 0.00017982  max_mem: 8696M
[02/29 23:58:06 d2.utils.events]:  eta: 0:05:25  iter: 919  total_loss: 0.7425  loss_cls: 0.1505  loss_box_reg: 0.2197  loss_mask: 0.2616  loss_rpn_cls: 0.03523  loss_rpn_loc: 0.06615    time: 0.5623  last_time: 0.5373  data_time: 0.0730  last_data_time: 0.0555   lr: 0.00018382  max_mem: 8696M
[02/29 23:58:17 d2.utils.events]:  eta: 0:05:14  iter: 939  total_loss: 0.7768  loss_cls: 0.1661  loss_box_reg: 0.2467  loss_mask: 0.254  loss_rpn_cls: 0.03426  loss_rpn_loc: 0.06994    time: 0.5625  last_time: 0.5979  data_time: 0.0661  last_data_time: 0.0892   lr: 0.00018781  max_mem: 8696M
[02/29 23:58:28 d2.utils.events]:  eta: 0:05:03  iter: 959  total_loss: 0.712  loss_cls: 0.1479  loss_box_reg: 0.2111  loss_mask: 0.2555  loss_rpn_cls: 0.03329  loss_rpn_loc: 0.06041    time: 0.5622  last_time: 0.5616  data_time: 0.0678  last_data_time: 0.0653   lr: 0.00019181  max_mem: 8696M
[02/29 23:58:39 d2.utils.events]:  eta: 0:04:51  iter: 979  total_loss: 0.7066  loss_cls: 0.147  loss_box_reg: 0.2039  loss_mask: 0.2455  loss_rpn_cls: 0.03313  loss_rpn_loc: 0.06281    time: 0.5621  last_time: 0.5323  data_time: 0.0725  last_data_time: 0.0802   lr: 0.0001958  max_mem: 8696M
[02/29 23:58:51 d2.utils.events]:  eta: 0:04:40  iter: 999  total_loss: 0.6909  loss_cls: 0.1529  loss_box_reg: 0.2047  loss_mask: 0.246  loss_rpn_cls: 0.03103  loss_rpn_loc: 0.06204    time: 0.5619  last_time: 0.5811  data_time: 0.0674  last_data_time: 0.0889   lr: 0.0001998  max_mem: 8696M
[02/29 23:59:03 d2.utils.events]:  eta: 0:04:29  iter: 1019  total_loss: 0.7185  loss_cls: 0.1407  loss_box_reg: 0.2116  loss_mask: 0.2375  loss_rpn_cls: 0.03313  loss_rpn_loc: 0.06951    time: 0.5619  last_time: 0.5895  data_time: 0.0674  last_data_time: 0.0823   lr: 0.0002  max_mem: 8696M
[02/29 23:59:13 d2.utils.events]:  eta: 0:04:17  iter: 1039  total_loss: 0.7154  loss_cls: 0.1441  loss_box_reg: 0.2067  loss_mask: 0.2658  loss_rpn_cls: 0.03436  loss_rpn_loc: 0.06932    time: 0.5614  last_time: 0.5464  data_time: 0.0571  last_data_time: 0.0726   lr: 0.0002  max_mem: 8696M
[02/29 23:59:24 d2.utils.events]:  eta: 0:04:06  iter: 1059  total_loss: 0.6939  loss_cls: 0.1414  loss_box_reg: 0.1961  loss_mask: 0.2507  loss_rpn_cls: 0.03521  loss_rpn_loc: 0.06571    time: 0.5612  last_time: 0.5604  data_time: 0.0653  last_data_time: 0.0835   lr: 0.0002  max_mem: 8696M
[02/29 23:59:36 d2.utils.events]:  eta: 0:03:55  iter: 1079  total_loss: 0.7328  loss_cls: 0.1453  loss_box_reg: 0.2139  loss_mask: 0.2531  loss_rpn_cls: 0.03642  loss_rpn_loc: 0.07204    time: 0.5611  last_time: 0.5590  data_time: 0.0639  last_data_time: 0.0846   lr: 0.0002  max_mem: 8696M
[02/29 23:59:47 d2.utils.events]:  eta: 0:03:43  iter: 1099  total_loss: 0.73  loss_cls: 0.1523  loss_box_reg: 0.1961  loss_mask: 0.256  loss_rpn_cls: 0.02927  loss_rpn_loc: 0.0681    time: 0.5609  last_time: 0.5177  data_time: 0.0682  last_data_time: 0.0364   lr: 0.0002  max_mem: 8696M
[02/29 23:59:58 d2.utils.events]:  eta: 0:03:32  iter: 1119  total_loss: 0.6874  loss_cls: 0.1455  loss_box_reg: 0.215  loss_mask: 0.2478  loss_rpn_cls: 0.03252  loss_rpn_loc: 0.06669    time: 0.5611  last_time: 0.5530  data_time: 0.0699  last_data_time: 0.0429   lr: 0.0002  max_mem: 8696M
[03/01 00:00:09 d2.utils.events]:  eta: 0:03:21  iter: 1139  total_loss: 0.7092  loss_cls: 0.1458  loss_box_reg: 0.2041  loss_mask: 0.2332  loss_rpn_cls: 0.03227  loss_rpn_loc: 0.08298    time: 0.5612  last_time: 0.5774  data_time: 0.0675  last_data_time: 0.0658   lr: 0.0002  max_mem: 8696M
[03/01 00:00:21 d2.utils.events]:  eta: 0:03:10  iter: 1159  total_loss: 0.7276  loss_cls: 0.1527  loss_box_reg: 0.2209  loss_mask: 0.2437  loss_rpn_cls: 0.03375  loss_rpn_loc: 0.0677    time: 0.5613  last_time: 0.6142  data_time: 0.0694  last_data_time: 0.0929   lr: 0.0002  max_mem: 8696M
[03/01 00:00:32 d2.utils.events]:  eta: 0:02:59  iter: 1179  total_loss: 0.7226  loss_cls: 0.1463  loss_box_reg: 0.2051  loss_mask: 0.2544  loss_rpn_cls: 0.03231  loss_rpn_loc: 0.07449    time: 0.5613  last_time: 0.4839  data_time: 0.0742  last_data_time: 0.0424   lr: 0.0002  max_mem: 8696M
[03/01 00:00:43 d2.utils.events]:  eta: 0:02:48  iter: 1199  total_loss: 0.707  loss_cls: 0.1352  loss_box_reg: 0.195  loss_mask: 0.2542  loss_rpn_cls: 0.02972  loss_rpn_loc: 0.05944    time: 0.5612  last_time: 0.5433  data_time: 0.0685  last_data_time: 0.0377   lr: 0.0002  max_mem: 8696M
[03/01 00:00:54 d2.utils.events]:  eta: 0:02:36  iter: 1219  total_loss: 0.7058  loss_cls: 0.138  loss_box_reg: 0.2031  loss_mask: 0.2484  loss_rpn_cls: 0.03076  loss_rpn_loc: 0.07062    time: 0.5612  last_time: 0.5848  data_time: 0.0736  last_data_time: 0.0893   lr: 0.0002  max_mem: 8696M
[03/01 00:01:05 d2.utils.events]:  eta: 0:02:25  iter: 1239  total_loss: 0.6651  loss_cls: 0.1348  loss_box_reg: 0.1902  loss_mask: 0.2385  loss_rpn_cls: 0.02982  loss_rpn_loc: 0.06188    time: 0.5611  last_time: 0.5504  data_time: 0.0617  last_data_time: 0.0383   lr: 0.0002  max_mem: 8696M
[03/01 00:01:17 d2.utils.events]:  eta: 0:02:14  iter: 1259  total_loss: 0.6754  loss_cls: 0.1323  loss_box_reg: 0.1814  loss_mask: 0.2454  loss_rpn_cls: 0.02881  loss_rpn_loc: 0.0629    time: 0.5611  last_time: 0.5598  data_time: 0.0719  last_data_time: 0.0566   lr: 0.0002  max_mem: 8696M
[03/01 00:01:28 d2.utils.events]:  eta: 0:02:03  iter: 1279  total_loss: 0.7429  loss_cls: 0.1445  loss_box_reg: 0.2035  loss_mask: 0.2487  loss_rpn_cls: 0.04254  loss_rpn_loc: 0.07541    time: 0.5612  last_time: 0.5035  data_time: 0.0692  last_data_time: 0.0392   lr: 0.0002  max_mem: 8848M
[03/01 00:01:39 d2.utils.events]:  eta: 0:01:52  iter: 1299  total_loss: 0.6802  loss_cls: 0.1362  loss_box_reg: 0.1987  loss_mask: 0.2416  loss_rpn_cls: 0.0266  loss_rpn_loc: 0.06315    time: 0.5613  last_time: 0.5521  data_time: 0.0659  last_data_time: 0.0771   lr: 0.0002  max_mem: 8848M
[03/01 00:01:50 d2.utils.events]:  eta: 0:01:40  iter: 1319  total_loss: 0.6839  loss_cls: 0.1388  loss_box_reg: 0.1911  loss_mask: 0.2323  loss_rpn_cls: 0.03148  loss_rpn_loc: 0.07643    time: 0.5612  last_time: 0.5213  data_time: 0.0678  last_data_time: 0.0708   lr: 0.0002  max_mem: 8848M
[03/01 00:02:01 d2.utils.events]:  eta: 0:01:29  iter: 1339  total_loss: 0.6566  loss_cls: 0.1351  loss_box_reg: 0.192  loss_mask: 0.2468  loss_rpn_cls: 0.02796  loss_rpn_loc: 0.05119    time: 0.5611  last_time: 0.6195  data_time: 0.0627  last_data_time: 0.0717   lr: 0.0002  max_mem: 8848M
[03/01 00:02:13 d2.utils.events]:  eta: 0:01:18  iter: 1359  total_loss: 0.7155  loss_cls: 0.1523  loss_box_reg: 0.2136  loss_mask: 0.2413  loss_rpn_cls: 0.02898  loss_rpn_loc: 0.07291    time: 0.5613  last_time: 0.5879  data_time: 0.0668  last_data_time: 0.0948   lr: 0.0002  max_mem: 8848M
[03/01 00:02:24 d2.utils.events]:  eta: 0:01:07  iter: 1379  total_loss: 0.6742  loss_cls: 0.134  loss_box_reg: 0.192  loss_mask: 0.2304  loss_rpn_cls: 0.02754  loss_rpn_loc: 0.06697    time: 0.5611  last_time: 0.5261  data_time: 0.0641  last_data_time: 0.0658   lr: 0.0002  max_mem: 8848M
[03/01 00:02:35 d2.utils.events]:  eta: 0:00:55  iter: 1399  total_loss: 0.705  loss_cls: 0.1426  loss_box_reg: 0.1996  loss_mask: 0.2492  loss_rpn_cls: 0.02858  loss_rpn_loc: 0.06325    time: 0.5609  last_time: 0.5022  data_time: 0.0641  last_data_time: 0.0453   lr: 0.0002  max_mem: 8848M
[03/01 00:02:46 d2.utils.events]:  eta: 0:00:44  iter: 1419  total_loss: 0.6709  loss_cls: 0.1378  loss_box_reg: 0.1981  loss_mask: 0.2343  loss_rpn_cls: 0.02535  loss_rpn_loc: 0.06639    time: 0.5611  last_time: 0.6287  data_time: 0.0708  last_data_time: 0.0846   lr: 0.0002  max_mem: 8848M
[03/01 00:02:57 d2.utils.events]:  eta: 0:00:33  iter: 1439  total_loss: 0.6366  loss_cls: 0.1351  loss_box_reg: 0.1922  loss_mask: 0.2369  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.05859    time: 0.5610  last_time: 0.5667  data_time: 0.0679  last_data_time: 0.0785   lr: 0.0002  max_mem: 8848M
[03/01 00:03:09 d2.utils.events]:  eta: 0:00:22  iter: 1459  total_loss: 0.6298  loss_cls: 0.1258  loss_box_reg: 0.1935  loss_mask: 0.2326  loss_rpn_cls: 0.02816  loss_rpn_loc: 0.05881    time: 0.5610  last_time: 0.5988  data_time: 0.0688  last_data_time: 0.0761   lr: 0.0002  max_mem: 8848M
[03/01 00:03:20 d2.utils.events]:  eta: 0:00:11  iter: 1479  total_loss: 0.7066  loss_cls: 0.1402  loss_box_reg: 0.2165  loss_mask: 0.2452  loss_rpn_cls: 0.03173  loss_rpn_loc: 0.08131    time: 0.5611  last_time: 0.5885  data_time: 0.0721  last_data_time: 0.0765   lr: 0.0002  max_mem: 8848M
[03/01 00:03:33 d2.utils.events]:  eta: 0:00:00  iter: 1499  total_loss: 0.7096  loss_cls: 0.1423  loss_box_reg: 0.209  loss_mask: 0.2377  loss_rpn_cls: 0.0327  loss_rpn_loc: 0.07729    time: 0.5611  last_time: 0.5838  data_time: 0.0663  last_data_time: 0.0864   lr: 0.0002  max_mem: 8848M
[03/01 00:03:33 d2.engine.hooks]: Overall training speed: 1498 iterations in 0:14:00 (0.5611 s / it)
[03/01 00:03:33 d2.engine.hooks]: Total training time: 0:14:13 (0:00:12 on hooks)
[03/01 00:03:40 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 8021         | pedestrian | 3347         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 2765         |            |              |
|   total    | 14133        |            |              |            |              |
[03/01 00:03:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/01 00:03:40 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 00:03:40 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/01 00:03:40 d2.data.common]: Serialized dataset takes 5.86 MiB
WARNING [03/01 00:03:40 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[03/01 00:03:41 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /ghome/group07/C5-W2/outputs_task_e/model_final.pth ...
[03/01 00:03:43 d2.evaluation.coco_evaluation]: Trying to convert 'KITTI-MOTS_val' to COCO format ...
WARNING [03/01 00:03:43 d2.data.datasets.coco]: Using previously cached COCO format annotations at '/ghome/group07/C5-W2/outputs_task_e/KITTI-MOTS_val_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[03/01 00:03:46 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/01 00:03:46 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 00:03:46 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/01 00:03:46 d2.data.common]: Serialized dataset takes 5.86 MiB
[03/01 00:03:46 d2.evaluation.evaluator]: Start inference on 2919 batches
[03/01 00:03:48 d2.evaluation.evaluator]: Inference done 11/2919. Dataloading: 0.0032 s/iter. Inference: 0.0503 s/iter. Eval: 0.0021 s/iter. Total: 0.0557 s/iter. ETA=0:02:41
[03/01 00:03:54 d2.evaluation.evaluator]: Inference done 105/2919. Dataloading: 0.0028 s/iter. Inference: 0.0485 s/iter. Eval: 0.0020 s/iter. Total: 0.0534 s/iter. ETA=0:02:30
[03/01 00:03:59 d2.evaluation.evaluator]: Inference done 205/2919. Dataloading: 0.0027 s/iter. Inference: 0.0471 s/iter. Eval: 0.0019 s/iter. Total: 0.0518 s/iter. ETA=0:02:20
[03/01 00:04:04 d2.evaluation.evaluator]: Inference done 301/2919. Dataloading: 0.0027 s/iter. Inference: 0.0473 s/iter. Eval: 0.0019 s/iter. Total: 0.0520 s/iter. ETA=0:02:16
[03/01 00:04:09 d2.evaluation.evaluator]: Inference done 396/2919. Dataloading: 0.0027 s/iter. Inference: 0.0476 s/iter. Eval: 0.0019 s/iter. Total: 0.0522 s/iter. ETA=0:02:11
[03/01 00:04:14 d2.evaluation.evaluator]: Inference done 491/2919. Dataloading: 0.0027 s/iter. Inference: 0.0477 s/iter. Eval: 0.0019 s/iter. Total: 0.0523 s/iter. ETA=0:02:07
[03/01 00:04:19 d2.evaluation.evaluator]: Inference done 586/2919. Dataloading: 0.0027 s/iter. Inference: 0.0478 s/iter. Eval: 0.0019 s/iter. Total: 0.0524 s/iter. ETA=0:02:02
[03/01 00:04:24 d2.evaluation.evaluator]: Inference done 684/2919. Dataloading: 0.0027 s/iter. Inference: 0.0475 s/iter. Eval: 0.0020 s/iter. Total: 0.0522 s/iter. ETA=0:01:56
[03/01 00:04:29 d2.evaluation.evaluator]: Inference done 779/2919. Dataloading: 0.0027 s/iter. Inference: 0.0475 s/iter. Eval: 0.0021 s/iter. Total: 0.0524 s/iter. ETA=0:01:52
[03/01 00:04:34 d2.evaluation.evaluator]: Inference done 873/2919. Dataloading: 0.0027 s/iter. Inference: 0.0475 s/iter. Eval: 0.0022 s/iter. Total: 0.0525 s/iter. ETA=0:01:47
[03/01 00:04:39 d2.evaluation.evaluator]: Inference done 968/2919. Dataloading: 0.0027 s/iter. Inference: 0.0475 s/iter. Eval: 0.0023 s/iter. Total: 0.0525 s/iter. ETA=0:01:42
[03/01 00:04:44 d2.evaluation.evaluator]: Inference done 1069/2919. Dataloading: 0.0027 s/iter. Inference: 0.0471 s/iter. Eval: 0.0024 s/iter. Total: 0.0523 s/iter. ETA=0:01:36
[03/01 00:04:49 d2.evaluation.evaluator]: Inference done 1162/2919. Dataloading: 0.0027 s/iter. Inference: 0.0472 s/iter. Eval: 0.0024 s/iter. Total: 0.0524 s/iter. ETA=0:01:32
[03/01 00:04:54 d2.evaluation.evaluator]: Inference done 1254/2919. Dataloading: 0.0027 s/iter. Inference: 0.0474 s/iter. Eval: 0.0024 s/iter. Total: 0.0526 s/iter. ETA=0:01:27
[03/01 00:04:59 d2.evaluation.evaluator]: Inference done 1347/2919. Dataloading: 0.0027 s/iter. Inference: 0.0475 s/iter. Eval: 0.0024 s/iter. Total: 0.0527 s/iter. ETA=0:01:22
[03/01 00:05:04 d2.evaluation.evaluator]: Inference done 1440/2919. Dataloading: 0.0027 s/iter. Inference: 0.0476 s/iter. Eval: 0.0024 s/iter. Total: 0.0528 s/iter. ETA=0:01:18
[03/01 00:05:09 d2.evaluation.evaluator]: Inference done 1532/2919. Dataloading: 0.0027 s/iter. Inference: 0.0477 s/iter. Eval: 0.0024 s/iter. Total: 0.0529 s/iter. ETA=0:01:13
[03/01 00:05:14 d2.evaluation.evaluator]: Inference done 1623/2919. Dataloading: 0.0027 s/iter. Inference: 0.0478 s/iter. Eval: 0.0024 s/iter. Total: 0.0530 s/iter. ETA=0:01:08
[03/01 00:05:19 d2.evaluation.evaluator]: Inference done 1714/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0024 s/iter. Total: 0.0532 s/iter. ETA=0:01:04
[03/01 00:05:24 d2.evaluation.evaluator]: Inference done 1806/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0025 s/iter. Total: 0.0533 s/iter. ETA=0:00:59
[03/01 00:05:29 d2.evaluation.evaluator]: Inference done 1899/2919. Dataloading: 0.0028 s/iter. Inference: 0.0480 s/iter. Eval: 0.0025 s/iter. Total: 0.0533 s/iter. ETA=0:00:54
[03/01 00:05:34 d2.evaluation.evaluator]: Inference done 1991/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0025 s/iter. Total: 0.0534 s/iter. ETA=0:00:49
[03/01 00:05:39 d2.evaluation.evaluator]: Inference done 2084/2919. Dataloading: 0.0027 s/iter. Inference: 0.0481 s/iter. Eval: 0.0025 s/iter. Total: 0.0534 s/iter. ETA=0:00:44
[03/01 00:05:44 d2.evaluation.evaluator]: Inference done 2181/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0025 s/iter. Total: 0.0533 s/iter. ETA=0:00:39
[03/01 00:05:49 d2.evaluation.evaluator]: Inference done 2274/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0025 s/iter. Total: 0.0534 s/iter. ETA=0:00:34
[03/01 00:05:54 d2.evaluation.evaluator]: Inference done 2370/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0025 s/iter. Total: 0.0533 s/iter. ETA=0:00:29
[03/01 00:05:59 d2.evaluation.evaluator]: Inference done 2455/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0027 s/iter. Total: 0.0535 s/iter. ETA=0:00:24
[03/01 00:06:04 d2.evaluation.evaluator]: Inference done 2540/2919. Dataloading: 0.0027 s/iter. Inference: 0.0481 s/iter. Eval: 0.0029 s/iter. Total: 0.0537 s/iter. ETA=0:00:20
[03/01 00:06:09 d2.evaluation.evaluator]: Inference done 2633/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0029 s/iter. Total: 0.0537 s/iter. ETA=0:00:15
[03/01 00:06:14 d2.evaluation.evaluator]: Inference done 2726/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0029 s/iter. Total: 0.0537 s/iter. ETA=0:00:10
[03/01 00:06:19 d2.evaluation.evaluator]: Inference done 2819/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0029 s/iter. Total: 0.0537 s/iter. ETA=0:00:05
[03/01 00:06:24 d2.evaluation.evaluator]: Inference done 2913/2919. Dataloading: 0.0027 s/iter. Inference: 0.0480 s/iter. Eval: 0.0029 s/iter. Total: 0.0537 s/iter. ETA=0:00:00
[03/01 00:06:25 d2.evaluation.evaluator]: Total inference time: 0:02:36.537213 (0.053719 s / iter per device, on 1 devices)
[03/01 00:06:25 d2.evaluation.evaluator]: Total inference pure compute time: 0:02:19 (0.047976 s / iter per device, on 1 devices)
[03/01 00:06:25 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[03/01 00:06:25 d2.evaluation.coco_evaluation]: Saving results to /ghome/group07/C5-W2/outputs_task_e/coco_instances_results.json
[03/01 00:06:25 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[03/01 00:06:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[03/01 00:06:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 1.09 seconds.
[03/01 00:06:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[03/01 00:06:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.428
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583
[03/01 00:06:26 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.410 | 53.303 | 45.755 | 26.188 | 46.465 | 48.683 |
[03/01 00:06:26 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 66.883 | pedestrian | 50.521 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 0.827  |            |        |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[03/01 00:06:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[03/01 00:06:27 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.87 seconds.
[03/01 00:06:27 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[03/01 00:06:27 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.388
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.260
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539
[03/01 00:06:27 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 35.113 | 52.593 | 39.304 | 21.094 | 42.137 | 51.082 |
[03/01 00:06:27 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 66.506 | pedestrian | 38.359 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 0.475  |            |        |
OrderedDict([('bbox', {'AP': 39.410254846164236, 'AP50': 53.30316975080353, 'AP75': 45.75530317762917, 'APs': 26.187500187813384, 'APm': 46.46538876657628, 'APl': 48.682733543098436, 'AP-background': nan, 'AP-car': 66.88338982042139, 'AP-pedestrian': 50.52064204480402, 'AP-': nan, 'AP-ignore': 0.8267326732673268}), ('segm', {'AP': 35.11324418818794, 'AP50': 52.59261018451937, 'AP75': 39.3043726274049, 'APs': 21.09393944708103, 'APm': 42.1366213639644, 'APl': 51.082059863120044, 'AP-background': nan, 'AP-car': 66.50591137598076, 'AP-pedestrian': 38.358573663830576, 'AP-': nan, 'AP-ignore': 0.4752475247524752})])
