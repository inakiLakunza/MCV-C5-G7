1
The device we will be working on is: cuda
[03/01 21:47:00 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/01 21:47:04 d2.data.build]: Removed 0 images with no usable annotations. 5007 images left.
[03/01 21:47:04 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 18822        | pedestrian | 8065         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 4977         |            |              |
|   total    | 31864        |            |              |            |              |
[03/01 21:47:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[03/01 21:47:04 d2.data.build]: Using training sampler TrainingSampler
[03/01 21:47:04 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 21:47:04 d2.data.common]: Serializing 5007 elements to byte tensors and concatenating them all ...
[03/01 21:47:04 d2.data.common]: Serialized dataset takes 13.56 MiB
[03/01 21:47:04 d2.data.build]: Making batched data loader with batch_size=16
WARNING [03/01 21:47:04 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/01 21:47:04 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...
[03/01 21:47:04 d2.engine.train_loop]: Starting training from iteration 0
[03/01 21:47:39 d2.utils.events]:  eta: 0:29:49  iter: 19  total_loss: 2.37  loss_cls: 1.054  loss_box_reg: 0.4077  loss_mask: 0.6134  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.07889    time: 1.2912  last_time: 1.1127  data_time: 0.6193  last_data_time: 0.2583   lr: 0.00099905  max_mem: 15491M
[03/01 21:48:12 d2.utils.events]:  eta: 0:29:48  iter: 39  total_loss: 1.232  loss_cls: 0.332  loss_box_reg: 0.3849  loss_mask: 0.3626  loss_rpn_cls: 0.05526  loss_rpn_loc: 0.08117    time: 1.2899  last_time: 1.2526  data_time: 0.3752  last_data_time: 0.3205   lr: 0.001998  max_mem: 15759M
[03/01 21:48:44 d2.utils.events]:  eta: 0:29:18  iter: 59  total_loss: 0.9513  loss_cls: 0.2347  loss_box_reg: 0.3046  loss_mask: 0.2849  loss_rpn_cls: 0.04359  loss_rpn_loc: 0.07317    time: 1.3981  last_time: 1.2084  data_time: 0.4071  last_data_time: 0.3104   lr: 0.002997  max_mem: 15759M
[03/01 21:49:09 d2.utils.events]:  eta: 0:29:10  iter: 79  total_loss: 0.7962  loss_cls: 0.17  loss_box_reg: 0.2379  loss_mask: 0.2581  loss_rpn_cls: 0.03306  loss_rpn_loc: 0.06523    time: 1.3590  last_time: 1.4349  data_time: 0.3474  last_data_time: 0.5531   lr: 0.0039961  max_mem: 15854M
[03/01 21:49:34 d2.utils.events]:  eta: 0:28:36  iter: 99  total_loss: 0.6794  loss_cls: 0.1439  loss_box_reg: 0.2003  loss_mask: 0.2332  loss_rpn_cls: 0.03021  loss_rpn_loc: 0.06651    time: 1.3348  last_time: 1.2160  data_time: 0.3438  last_data_time: 0.3314   lr: 0.0049951  max_mem: 16194M
[03/01 21:49:58 d2.utils.events]:  eta: 0:28:12  iter: 119  total_loss: 0.6675  loss_cls: 0.1356  loss_box_reg: 0.2035  loss_mask: 0.2251  loss_rpn_cls: 0.02605  loss_rpn_loc: 0.08387    time: 1.3185  last_time: 1.2086  data_time: 0.3355  last_data_time: 0.3304   lr: 0.0059941  max_mem: 16194M
[03/01 21:50:23 d2.utils.events]:  eta: 0:27:44  iter: 139  total_loss: 0.6886  loss_cls: 0.1455  loss_box_reg: 0.2121  loss_mask: 0.2267  loss_rpn_cls: 0.02796  loss_rpn_loc: 0.06521    time: 1.3051  last_time: 1.2245  data_time: 0.3213  last_data_time: 0.3113   lr: 0.0069931  max_mem: 16194M
[03/01 21:50:47 d2.utils.events]:  eta: 0:27:19  iter: 159  total_loss: 0.6643  loss_cls: 0.1334  loss_box_reg: 0.2058  loss_mask: 0.2199  loss_rpn_cls: 0.02983  loss_rpn_loc: 0.07593    time: 1.2946  last_time: 1.2335  data_time: 0.3250  last_data_time: 0.3272   lr: 0.0079921  max_mem: 16194M
[03/01 21:51:12 d2.utils.events]:  eta: 0:26:53  iter: 179  total_loss: 0.6597  loss_cls: 0.1343  loss_box_reg: 0.2078  loss_mask: 0.2142  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.06769    time: 1.2865  last_time: 1.2463  data_time: 0.3097  last_data_time: 0.3329   lr: 0.0089911  max_mem: 16194M
[03/01 21:51:37 d2.utils.events]:  eta: 0:26:30  iter: 199  total_loss: 0.635  loss_cls: 0.1301  loss_box_reg: 0.2048  loss_mask: 0.1973  loss_rpn_cls: 0.0255  loss_rpn_loc: 0.07333    time: 1.2852  last_time: 1.1929  data_time: 0.3494  last_data_time: 0.3208   lr: 0.0099901  max_mem: 16461M
[03/01 21:52:02 d2.utils.events]:  eta: 0:26:07  iter: 219  total_loss: 0.6326  loss_cls: 0.1344  loss_box_reg: 0.203  loss_mask: 0.1954  loss_rpn_cls: 0.02405  loss_rpn_loc: 0.06901    time: 1.2826  last_time: 1.2082  data_time: 0.3282  last_data_time: 0.3045   lr: 0.010989  max_mem: 16461M
[03/01 21:52:27 d2.utils.events]:  eta: 0:25:43  iter: 239  total_loss: 0.5799  loss_cls: 0.1157  loss_box_reg: 0.1792  loss_mask: 0.1927  loss_rpn_cls: 0.02273  loss_rpn_loc: 0.07282    time: 1.2779  last_time: 1.2624  data_time: 0.3098  last_data_time: 0.3217   lr: 0.011988  max_mem: 16461M
[03/01 21:52:52 d2.utils.events]:  eta: 0:25:18  iter: 259  total_loss: 0.6155  loss_cls: 0.1258  loss_box_reg: 0.1985  loss_mask: 0.1948  loss_rpn_cls: 0.0235  loss_rpn_loc: 0.07589    time: 1.2744  last_time: 1.3642  data_time: 0.3098  last_data_time: 0.3749   lr: 0.012987  max_mem: 16524M
[03/01 21:53:17 d2.utils.events]:  eta: 0:24:57  iter: 279  total_loss: 0.6336  loss_cls: 0.1304  loss_box_reg: 0.2066  loss_mask: 0.2033  loss_rpn_cls: 0.02173  loss_rpn_loc: 0.06291    time: 1.2754  last_time: 1.2307  data_time: 0.3295  last_data_time: 0.2819   lr: 0.013986  max_mem: 16682M
[03/01 21:53:43 d2.utils.events]:  eta: 0:24:37  iter: 299  total_loss: 0.6288  loss_cls: 0.1288  loss_box_reg: 0.2078  loss_mask: 0.197  loss_rpn_cls: 0.02177  loss_rpn_loc: 0.07271    time: 1.2743  last_time: 1.1826  data_time: 0.3263  last_data_time: 0.2664   lr: 0.014985  max_mem: 16682M
[03/01 21:54:08 d2.utils.events]:  eta: 0:24:12  iter: 319  total_loss: 0.5973  loss_cls: 0.123  loss_box_reg: 0.2001  loss_mask: 0.1899  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.06546    time: 1.2739  last_time: 1.2116  data_time: 0.3429  last_data_time: 0.3047   lr: 0.015984  max_mem: 16682M
[03/01 21:54:33 d2.utils.events]:  eta: 0:23:48  iter: 339  total_loss: 0.59  loss_cls: 0.1211  loss_box_reg: 0.1961  loss_mask: 0.1889  loss_rpn_cls: 0.01962  loss_rpn_loc: 0.06949    time: 1.2720  last_time: 1.2166  data_time: 0.3103  last_data_time: 0.2929   lr: 0.016983  max_mem: 16682M
[03/01 21:54:58 d2.utils.events]:  eta: 0:23:25  iter: 359  total_loss: 0.5779  loss_cls: 0.1193  loss_box_reg: 0.1901  loss_mask: 0.1834  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.06789    time: 1.2716  last_time: 1.2107  data_time: 0.3320  last_data_time: 0.2916   lr: 0.017982  max_mem: 16682M
[03/01 21:55:23 d2.utils.events]:  eta: 0:23:01  iter: 379  total_loss: 0.5845  loss_cls: 0.1208  loss_box_reg: 0.1885  loss_mask: 0.1872  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.0622    time: 1.2701  last_time: 1.2852  data_time: 0.3161  last_data_time: 0.3181   lr: 0.018981  max_mem: 16682M
[03/01 21:55:48 d2.utils.events]:  eta: 0:22:38  iter: 399  total_loss: 0.5816  loss_cls: 0.1156  loss_box_reg: 0.201  loss_mask: 0.1698  loss_rpn_cls: 0.02001  loss_rpn_loc: 0.06891    time: 1.2697  last_time: 1.2897  data_time: 0.3180  last_data_time: 0.3386   lr: 0.01998  max_mem: 16682M
[03/01 21:56:13 d2.utils.events]:  eta: 0:22:14  iter: 419  total_loss: 0.58  loss_cls: 0.112  loss_box_reg: 0.1955  loss_mask: 0.1811  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.0621    time: 1.2689  last_time: 1.2626  data_time: 0.3298  last_data_time: 0.3291   lr: 0.020979  max_mem: 16682M
[03/01 21:56:39 d2.utils.events]:  eta: 0:21:50  iter: 439  total_loss: 0.5555  loss_cls: 0.1104  loss_box_reg: 0.1853  loss_mask: 0.1741  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.06665    time: 1.2688  last_time: 1.2002  data_time: 0.3329  last_data_time: 0.2965   lr: 0.021978  max_mem: 16682M
[03/01 21:57:04 d2.utils.events]:  eta: 0:21:26  iter: 459  total_loss: 0.5679  loss_cls: 0.1112  loss_box_reg: 0.1765  loss_mask: 0.1824  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.06608    time: 1.2686  last_time: 1.2066  data_time: 0.3363  last_data_time: 0.3007   lr: 0.022977  max_mem: 16682M
[03/01 21:57:29 d2.utils.events]:  eta: 0:21:02  iter: 479  total_loss: 0.5793  loss_cls: 0.1117  loss_box_reg: 0.1871  loss_mask: 0.1906  loss_rpn_cls: 0.01963  loss_rpn_loc: 0.06029    time: 1.2682  last_time: 1.2867  data_time: 0.3291  last_data_time: 0.3502   lr: 0.023976  max_mem: 16682M
[03/01 21:57:56 d2.utils.events]:  eta: 0:20:38  iter: 499  total_loss: 0.5823  loss_cls: 0.1158  loss_box_reg: 0.1949  loss_mask: 0.1821  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.06309    time: 1.2692  last_time: 1.2840  data_time: 0.3524  last_data_time: 0.3219   lr: 0.024975  max_mem: 16682M
[03/01 21:58:22 d2.utils.events]:  eta: 0:20:15  iter: 519  total_loss: 0.5495  loss_cls: 0.1032  loss_box_reg: 0.1803  loss_mask: 0.1784  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.07072    time: 1.2702  last_time: 1.3168  data_time: 0.3607  last_data_time: 0.3913   lr: 0.025974  max_mem: 16682M
[03/01 21:58:47 d2.utils.events]:  eta: 0:19:52  iter: 539  total_loss: 0.55  loss_cls: 0.1011  loss_box_reg: 0.1794  loss_mask: 0.1749  loss_rpn_cls: 0.01884  loss_rpn_loc: 0.06265    time: 1.2698  last_time: 1.2483  data_time: 0.3268  last_data_time: 0.3119   lr: 0.026973  max_mem: 16682M
[03/01 21:59:12 d2.utils.events]:  eta: 0:19:27  iter: 559  total_loss: 0.5319  loss_cls: 0.1088  loss_box_reg: 0.1798  loss_mask: 0.1752  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.05406    time: 1.2693  last_time: 1.2334  data_time: 0.3125  last_data_time: 0.3258   lr: 0.027972  max_mem: 16682M
[03/01 21:59:37 d2.utils.events]:  eta: 0:19:03  iter: 579  total_loss: 0.6024  loss_cls: 0.1161  loss_box_reg: 0.2066  loss_mask: 0.1806  loss_rpn_cls: 0.02166  loss_rpn_loc: 0.06058    time: 1.2689  last_time: 1.2465  data_time: 0.3153  last_data_time: 0.3061   lr: 0.028971  max_mem: 16682M
[03/01 22:00:03 d2.utils.events]:  eta: 0:18:39  iter: 599  total_loss: 0.5503  loss_cls: 0.1084  loss_box_reg: 0.1897  loss_mask: 0.1748  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.07052    time: 1.2689  last_time: 1.3055  data_time: 0.3242  last_data_time: 0.3071   lr: 0.02997  max_mem: 16682M
[03/01 22:00:28 d2.utils.events]:  eta: 0:18:15  iter: 619  total_loss: 0.5509  loss_cls: 0.1056  loss_box_reg: 0.2014  loss_mask: 0.1671  loss_rpn_cls: 0.0202  loss_rpn_loc: 0.06625    time: 1.2694  last_time: 1.2522  data_time: 0.3281  last_data_time: 0.2887   lr: 0.030969  max_mem: 16714M
[03/01 22:00:54 d2.utils.events]:  eta: 0:17:51  iter: 639  total_loss: 0.5582  loss_cls: 0.1127  loss_box_reg: 0.1973  loss_mask: 0.1763  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.06395    time: 1.2701  last_time: 1.3346  data_time: 0.3330  last_data_time: 0.3281   lr: 0.031968  max_mem: 16714M
[03/01 22:01:20 d2.utils.events]:  eta: 0:17:28  iter: 659  total_loss: 0.5424  loss_cls: 0.09471  loss_box_reg: 0.1846  loss_mask: 0.1665  loss_rpn_cls: 0.01713  loss_rpn_loc: 0.0644    time: 1.2706  last_time: 1.2194  data_time: 0.3385  last_data_time: 0.3008   lr: 0.032967  max_mem: 16714M
[03/01 22:01:45 d2.utils.events]:  eta: 0:17:03  iter: 679  total_loss: 0.5419  loss_cls: 0.09177  loss_box_reg: 0.1842  loss_mask: 0.1662  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.06986    time: 1.2707  last_time: 1.1942  data_time: 0.3407  last_data_time: 0.2884   lr: 0.033966  max_mem: 16714M
[03/01 22:02:11 d2.utils.events]:  eta: 0:16:39  iter: 699  total_loss: 0.5201  loss_cls: 0.1001  loss_box_reg: 0.1813  loss_mask: 0.1631  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.05858    time: 1.2711  last_time: 1.3209  data_time: 0.3267  last_data_time: 0.3390   lr: 0.034965  max_mem: 16714M
[03/01 22:02:37 d2.utils.events]:  eta: 0:16:15  iter: 719  total_loss: 0.5274  loss_cls: 0.09328  loss_box_reg: 0.1769  loss_mask: 0.164  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.06595    time: 1.2718  last_time: 1.3149  data_time: 0.3459  last_data_time: 0.3263   lr: 0.035964  max_mem: 16714M
[03/01 22:03:02 d2.utils.events]:  eta: 0:15:49  iter: 739  total_loss: 0.5004  loss_cls: 0.093  loss_box_reg: 0.1687  loss_mask: 0.1629  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.05628    time: 1.2710  last_time: 1.2831  data_time: 0.3114  last_data_time: 0.3089   lr: 0.036963  max_mem: 16714M
[03/01 22:03:28 d2.utils.events]:  eta: 0:15:24  iter: 759  total_loss: 0.5386  loss_cls: 0.1006  loss_box_reg: 0.1926  loss_mask: 0.1668  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.06223    time: 1.2714  last_time: 1.2338  data_time: 0.3276  last_data_time: 0.2976   lr: 0.037962  max_mem: 16714M
[03/01 22:03:54 d2.utils.events]:  eta: 0:15:00  iter: 779  total_loss: 0.532  loss_cls: 0.09898  loss_box_reg: 0.1708  loss_mask: 0.1626  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.06205    time: 1.2720  last_time: 1.5508  data_time: 0.3295  last_data_time: 0.5690   lr: 0.038961  max_mem: 16714M
[03/01 22:04:20 d2.utils.events]:  eta: 0:14:36  iter: 799  total_loss: 0.5413  loss_cls: 0.1025  loss_box_reg: 0.1876  loss_mask: 0.1684  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.0634    time: 1.2726  last_time: 1.2680  data_time: 0.3319  last_data_time: 0.3355   lr: 0.03996  max_mem: 16732M
[03/01 22:04:45 d2.utils.events]:  eta: 0:14:11  iter: 819  total_loss: 0.514  loss_cls: 0.09503  loss_box_reg: 0.1734  loss_mask: 0.1676  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.0569    time: 1.2727  last_time: 1.2316  data_time: 0.3206  last_data_time: 0.3342   lr: 0.040959  max_mem: 16732M
[03/01 22:05:11 d2.utils.events]:  eta: 0:13:46  iter: 839  total_loss: 0.5108  loss_cls: 0.09223  loss_box_reg: 0.1785  loss_mask: 0.1628  loss_rpn_cls: 0.01605  loss_rpn_loc: 0.06601    time: 1.2729  last_time: 1.2998  data_time: 0.3333  last_data_time: 0.3140   lr: 0.041958  max_mem: 16847M
[03/01 22:05:37 d2.utils.events]:  eta: 0:13:21  iter: 859  total_loss: 0.5087  loss_cls: 0.08993  loss_box_reg: 0.1822  loss_mask: 0.1581  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.06116    time: 1.2743  last_time: 1.2912  data_time: 0.3755  last_data_time: 0.3107   lr: 0.042957  max_mem: 16847M
[03/01 22:06:03 d2.utils.events]:  eta: 0:12:56  iter: 879  total_loss: 0.5171  loss_cls: 0.09734  loss_box_reg: 0.1823  loss_mask: 0.1576  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.06038    time: 1.2741  last_time: 1.3328  data_time: 0.3223  last_data_time: 0.3706   lr: 0.043956  max_mem: 16847M
[03/01 22:06:28 d2.utils.events]:  eta: 0:12:31  iter: 899  total_loss: 0.5348  loss_cls: 0.09902  loss_box_reg: 0.1788  loss_mask: 0.1636  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.06206    time: 1.2737  last_time: 1.2471  data_time: 0.3103  last_data_time: 0.3165   lr: 0.044955  max_mem: 16847M
[03/01 22:06:53 d2.utils.events]:  eta: 0:12:06  iter: 919  total_loss: 0.5224  loss_cls: 0.09565  loss_box_reg: 0.1739  loss_mask: 0.1728  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.0611    time: 1.2733  last_time: 1.2298  data_time: 0.3117  last_data_time: 0.3088   lr: 0.045954  max_mem: 16847M
[03/01 22:07:19 d2.utils.events]:  eta: 0:11:41  iter: 939  total_loss: 0.5406  loss_cls: 0.1051  loss_box_reg: 0.1927  loss_mask: 0.1657  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.06457    time: 1.2739  last_time: 1.2360  data_time: 0.3455  last_data_time: 0.3128   lr: 0.046953  max_mem: 16847M
[03/01 22:07:44 d2.utils.events]:  eta: 0:11:16  iter: 959  total_loss: 0.4784  loss_cls: 0.08639  loss_box_reg: 0.1606  loss_mask: 0.1609  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.05101    time: 1.2736  last_time: 1.2039  data_time: 0.3231  last_data_time: 0.2824   lr: 0.047952  max_mem: 16847M
[03/01 22:08:10 d2.utils.events]:  eta: 0:10:51  iter: 979  total_loss: 0.4891  loss_cls: 0.09068  loss_box_reg: 0.1759  loss_mask: 0.16  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.06124    time: 1.2737  last_time: 1.1985  data_time: 0.3241  last_data_time: 0.2558   lr: 0.048951  max_mem: 16847M
[03/01 22:08:37 d2.utils.events]:  eta: 0:10:27  iter: 999  total_loss: 0.5028  loss_cls: 0.08759  loss_box_reg: 0.1823  loss_mask: 0.1571  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.05658    time: 1.2742  last_time: 1.2594  data_time: 0.3286  last_data_time: 0.3125   lr: 0.04995  max_mem: 16847M
[03/01 22:09:03 d2.utils.events]:  eta: 0:10:02  iter: 1019  total_loss: 0.5339  loss_cls: 0.09959  loss_box_reg: 0.182  loss_mask: 0.16  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.0591    time: 1.2747  last_time: 1.3600  data_time: 0.3354  last_data_time: 0.3635   lr: 0.05  max_mem: 16847M
[03/01 22:09:28 d2.utils.events]:  eta: 0:09:38  iter: 1039  total_loss: 0.5025  loss_cls: 0.09447  loss_box_reg: 0.1702  loss_mask: 0.1572  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.06188    time: 1.2746  last_time: 1.3256  data_time: 0.3250  last_data_time: 0.3443   lr: 0.05  max_mem: 16847M
[03/01 22:09:54 d2.utils.events]:  eta: 0:09:13  iter: 1059  total_loss: 0.5227  loss_cls: 0.09636  loss_box_reg: 0.1787  loss_mask: 0.1594  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.0648    time: 1.2750  last_time: 1.3210  data_time: 0.3379  last_data_time: 0.3496   lr: 0.05  max_mem: 16847M
[03/01 22:10:19 d2.utils.events]:  eta: 0:08:48  iter: 1079  total_loss: 0.5148  loss_cls: 0.09512  loss_box_reg: 0.18  loss_mask: 0.1556  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.06125    time: 1.2749  last_time: 1.2860  data_time: 0.3223  last_data_time: 0.3242   lr: 0.05  max_mem: 16847M
[03/01 22:10:45 d2.utils.events]:  eta: 0:08:23  iter: 1099  total_loss: 0.5065  loss_cls: 0.09677  loss_box_reg: 0.1832  loss_mask: 0.1572  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.05681    time: 1.2751  last_time: 1.3514  data_time: 0.3158  last_data_time: 0.3727   lr: 0.05  max_mem: 16847M
[03/01 22:11:17 d2.utils.events]:  eta: 0:07:58  iter: 1119  total_loss: 0.4615  loss_cls: 0.08483  loss_box_reg: 0.1645  loss_mask: 0.1545  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.05392    time: 1.2812  last_time: 1.2933  data_time: 0.3849  last_data_time: 0.3389   lr: 0.05  max_mem: 16847M
[03/01 22:11:44 d2.utils.events]:  eta: 0:07:34  iter: 1139  total_loss: 0.5486  loss_cls: 0.09779  loss_box_reg: 0.1983  loss_mask: 0.155  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.07491    time: 1.2820  last_time: 1.2688  data_time: 0.3471  last_data_time: 0.3113   lr: 0.05  max_mem: 16878M
[03/01 22:12:11 d2.utils.events]:  eta: 0:07:09  iter: 1159  total_loss: 0.4925  loss_cls: 0.08841  loss_box_reg: 0.166  loss_mask: 0.1491  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.06708    time: 1.2829  last_time: 1.2172  data_time: 0.3703  last_data_time: 0.2824   lr: 0.05  max_mem: 16878M
[03/01 22:12:37 d2.utils.events]:  eta: 0:06:44  iter: 1179  total_loss: 0.5053  loss_cls: 0.08997  loss_box_reg: 0.1802  loss_mask: 0.1567  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.06224    time: 1.2834  last_time: 1.3133  data_time: 0.3493  last_data_time: 0.3307   lr: 0.05  max_mem: 16878M
[03/01 22:13:02 d2.utils.events]:  eta: 0:06:19  iter: 1199  total_loss: 0.488  loss_cls: 0.0869  loss_box_reg: 0.1737  loss_mask: 0.1579  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.05229    time: 1.2832  last_time: 1.3618  data_time: 0.3159  last_data_time: 0.3880   lr: 0.05  max_mem: 16878M
[03/01 22:13:28 d2.utils.events]:  eta: 0:05:54  iter: 1219  total_loss: 0.4763  loss_cls: 0.08453  loss_box_reg: 0.1658  loss_mask: 0.1466  loss_rpn_cls: 0.01345  loss_rpn_loc: 0.05806    time: 1.2835  last_time: 1.2727  data_time: 0.3299  last_data_time: 0.3470   lr: 0.05  max_mem: 16878M
[03/01 22:13:54 d2.utils.events]:  eta: 0:05:29  iter: 1239  total_loss: 0.4753  loss_cls: 0.08809  loss_box_reg: 0.1712  loss_mask: 0.1525  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.05368    time: 1.2836  last_time: 1.2391  data_time: 0.3290  last_data_time: 0.2945   lr: 0.05  max_mem: 16878M
[03/01 22:14:20 d2.utils.events]:  eta: 0:05:04  iter: 1259  total_loss: 0.4797  loss_cls: 0.08806  loss_box_reg: 0.1731  loss_mask: 0.148  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.05218    time: 1.2838  last_time: 1.2649  data_time: 0.3269  last_data_time: 0.3130   lr: 0.05  max_mem: 16878M
[03/01 22:14:46 d2.utils.events]:  eta: 0:04:39  iter: 1279  total_loss: 0.4811  loss_cls: 0.08372  loss_box_reg: 0.1648  loss_mask: 0.1513  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.056    time: 1.2838  last_time: 1.2743  data_time: 0.3210  last_data_time: 0.3015   lr: 0.05  max_mem: 16878M
[03/01 22:15:12 d2.utils.events]:  eta: 0:04:14  iter: 1299  total_loss: 0.4606  loss_cls: 0.08249  loss_box_reg: 0.1669  loss_mask: 0.1457  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.05401    time: 1.2842  last_time: 1.3278  data_time: 0.3328  last_data_time: 0.3086   lr: 0.05  max_mem: 17003M
[03/01 22:15:38 d2.utils.events]:  eta: 0:03:49  iter: 1319  total_loss: 0.4693  loss_cls: 0.08199  loss_box_reg: 0.1702  loss_mask: 0.1477  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.04927    time: 1.2844  last_time: 1.2776  data_time: 0.3253  last_data_time: 0.3075   lr: 0.05  max_mem: 17003M
[03/01 22:16:04 d2.utils.events]:  eta: 0:03:24  iter: 1339  total_loss: 0.4586  loss_cls: 0.08166  loss_box_reg: 0.1613  loss_mask: 0.1399  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.06208    time: 1.2847  last_time: 1.2765  data_time: 0.3279  last_data_time: 0.2970   lr: 0.05  max_mem: 17003M
[03/01 22:16:30 d2.utils.events]:  eta: 0:02:58  iter: 1359  total_loss: 0.4611  loss_cls: 0.08367  loss_box_reg: 0.1711  loss_mask: 0.1389  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.05508    time: 1.2850  last_time: 1.3793  data_time: 0.3267  last_data_time: 0.3489   lr: 0.05  max_mem: 17003M
[03/01 22:16:57 d2.utils.events]:  eta: 0:02:33  iter: 1379  total_loss: 0.4377  loss_cls: 0.07766  loss_box_reg: 0.1547  loss_mask: 0.1462  loss_rpn_cls: 0.008962  loss_rpn_loc: 0.04798    time: 1.2855  last_time: 1.2739  data_time: 0.3450  last_data_time: 0.3044   lr: 0.05  max_mem: 17003M
[03/01 22:17:22 d2.utils.events]:  eta: 0:02:07  iter: 1399  total_loss: 0.4487  loss_cls: 0.07893  loss_box_reg: 0.1568  loss_mask: 0.1405  loss_rpn_cls: 0.009364  loss_rpn_loc: 0.05798    time: 1.2856  last_time: 1.2960  data_time: 0.3132  last_data_time: 0.3250   lr: 0.05  max_mem: 17003M
[03/01 22:17:49 d2.utils.events]:  eta: 0:01:42  iter: 1419  total_loss: 0.4491  loss_cls: 0.07929  loss_box_reg: 0.1651  loss_mask: 0.1402  loss_rpn_cls: 0.009874  loss_rpn_loc: 0.05195    time: 1.2859  last_time: 1.3103  data_time: 0.3255  last_data_time: 0.3309   lr: 0.05  max_mem: 17003M
[03/01 22:18:15 d2.utils.events]:  eta: 0:01:16  iter: 1439  total_loss: 0.4488  loss_cls: 0.08275  loss_box_reg: 0.1598  loss_mask: 0.1438  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.04845    time: 1.2861  last_time: 1.2598  data_time: 0.3208  last_data_time: 0.2816   lr: 0.05  max_mem: 17003M
[03/01 22:18:40 d2.utils.events]:  eta: 0:00:51  iter: 1459  total_loss: 0.449  loss_cls: 0.07986  loss_box_reg: 0.161  loss_mask: 0.1446  loss_rpn_cls: 0.009855  loss_rpn_loc: 0.05141    time: 1.2862  last_time: 1.2610  data_time: 0.3186  last_data_time: 0.2564   lr: 0.05  max_mem: 17003M
[03/01 22:19:06 d2.utils.events]:  eta: 0:00:25  iter: 1479  total_loss: 0.4483  loss_cls: 0.07643  loss_box_reg: 0.1554  loss_mask: 0.1417  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.05794    time: 1.2859  last_time: 1.2463  data_time: 0.2989  last_data_time: 0.2810   lr: 0.05  max_mem: 17003M
[03/01 22:19:34 d2.utils.events]:  eta: 0:00:00  iter: 1499  total_loss: 0.46  loss_cls: 0.08567  loss_box_reg: 0.1663  loss_mask: 0.1503  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.0583    time: 1.2862  last_time: 1.2352  data_time: 0.3298  last_data_time: 0.2883   lr: 0.05  max_mem: 17003M
[03/01 22:19:34 d2.engine.hooks]: Overall training speed: 1498 iterations in 0:32:06 (1.2862 s / it)
[03/01 22:19:34 d2.engine.hooks]: Total training time: 0:32:18 (0:00:11 on hooks)
[03/01 22:19:36 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 8021         | pedestrian | 3347         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 2765         |            |              |
|   total    | 14133        |            |              |            |              |
[03/01 22:19:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/01 22:19:36 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 22:19:36 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/01 22:19:36 d2.data.common]: Serialized dataset takes 5.86 MiB
WARNING [03/01 22:19:36 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[03/01 22:19:43 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /ghome/group07/C5-W2/lr_0_05_bs_32_is_16/model_0001499.pth ...
[03/01 22:19:46 d2.evaluation.coco_evaluation]: Trying to convert 'KITTI-MOTS_val' to COCO format ...
[03/01 22:19:46 d2.data.datasets.coco]: Converting annotations of dataset 'KITTI-MOTS_val' to COCO format ...)
[03/01 22:19:48 d2.data.datasets.coco]: Converting dataset dicts into COCO format
[03/01 22:19:48 d2.data.datasets.coco]: Conversion finished, #images: 2919, #annotations: 14133
[03/01 22:19:48 d2.data.datasets.coco]: Caching COCO format annotations at '/ghome/group07/C5-W2/lr_0_05_bs_32_is_16/KITTI-MOTS_val_coco_format.json' ...
[03/01 22:19:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/01 22:19:51 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 22:19:51 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/01 22:19:51 d2.data.common]: Serialized dataset takes 5.86 MiB
[03/01 22:19:51 d2.evaluation.evaluator]: Start inference on 2919 batches
[03/01 22:19:53 d2.evaluation.evaluator]: Inference done 11/2919. Dataloading: 0.0019 s/iter. Inference: 0.0547 s/iter. Eval: 0.0021 s/iter. Total: 0.0587 s/iter. ETA=0:02:50
[03/01 22:19:58 d2.evaluation.evaluator]: Inference done 94/2919. Dataloading: 0.0032 s/iter. Inference: 0.0536 s/iter. Eval: 0.0034 s/iter. Total: 0.0602 s/iter. ETA=0:02:50
[03/01 22:20:03 d2.evaluation.evaluator]: Inference done 177/2919. Dataloading: 0.0030 s/iter. Inference: 0.0545 s/iter. Eval: 0.0028 s/iter. Total: 0.0603 s/iter. ETA=0:02:45
[03/01 22:20:08 d2.evaluation.evaluator]: Inference done 264/2919. Dataloading: 0.0029 s/iter. Inference: 0.0539 s/iter. Eval: 0.0025 s/iter. Total: 0.0595 s/iter. ETA=0:02:37
[03/01 22:20:13 d2.evaluation.evaluator]: Inference done 348/2919. Dataloading: 0.0029 s/iter. Inference: 0.0542 s/iter. Eval: 0.0024 s/iter. Total: 0.0596 s/iter. ETA=0:02:33
[03/01 22:20:18 d2.evaluation.evaluator]: Inference done 435/2919. Dataloading: 0.0029 s/iter. Inference: 0.0539 s/iter. Eval: 0.0023 s/iter. Total: 0.0592 s/iter. ETA=0:02:26
[03/01 22:20:23 d2.evaluation.evaluator]: Inference done 522/2919. Dataloading: 0.0028 s/iter. Inference: 0.0538 s/iter. Eval: 0.0023 s/iter. Total: 0.0589 s/iter. ETA=0:02:21
[03/01 22:20:28 d2.evaluation.evaluator]: Inference done 606/2919. Dataloading: 0.0028 s/iter. Inference: 0.0539 s/iter. Eval: 0.0023 s/iter. Total: 0.0591 s/iter. ETA=0:02:16
[03/01 22:20:33 d2.evaluation.evaluator]: Inference done 693/2919. Dataloading: 0.0028 s/iter. Inference: 0.0537 s/iter. Eval: 0.0023 s/iter. Total: 0.0589 s/iter. ETA=0:02:11
[03/01 22:20:38 d2.evaluation.evaluator]: Inference done 783/2919. Dataloading: 0.0028 s/iter. Inference: 0.0533 s/iter. Eval: 0.0024 s/iter. Total: 0.0586 s/iter. ETA=0:02:05
[03/01 22:20:43 d2.evaluation.evaluator]: Inference done 869/2919. Dataloading: 0.0028 s/iter. Inference: 0.0532 s/iter. Eval: 0.0025 s/iter. Total: 0.0586 s/iter. ETA=0:02:00
[03/01 22:20:48 d2.evaluation.evaluator]: Inference done 956/2919. Dataloading: 0.0028 s/iter. Inference: 0.0531 s/iter. Eval: 0.0025 s/iter. Total: 0.0585 s/iter. ETA=0:01:54
[03/01 22:20:53 d2.evaluation.evaluator]: Inference done 1043/2919. Dataloading: 0.0028 s/iter. Inference: 0.0530 s/iter. Eval: 0.0025 s/iter. Total: 0.0584 s/iter. ETA=0:01:49
[03/01 22:20:58 d2.evaluation.evaluator]: Inference done 1129/2919. Dataloading: 0.0028 s/iter. Inference: 0.0530 s/iter. Eval: 0.0026 s/iter. Total: 0.0585 s/iter. ETA=0:01:44
[03/01 22:21:03 d2.evaluation.evaluator]: Inference done 1217/2919. Dataloading: 0.0028 s/iter. Inference: 0.0529 s/iter. Eval: 0.0026 s/iter. Total: 0.0583 s/iter. ETA=0:01:39
[03/01 22:21:08 d2.evaluation.evaluator]: Inference done 1308/2919. Dataloading: 0.0028 s/iter. Inference: 0.0527 s/iter. Eval: 0.0026 s/iter. Total: 0.0581 s/iter. ETA=0:01:33
[03/01 22:21:13 d2.evaluation.evaluator]: Inference done 1396/2919. Dataloading: 0.0028 s/iter. Inference: 0.0526 s/iter. Eval: 0.0026 s/iter. Total: 0.0581 s/iter. ETA=0:01:28
[03/01 22:21:18 d2.evaluation.evaluator]: Inference done 1483/2919. Dataloading: 0.0028 s/iter. Inference: 0.0526 s/iter. Eval: 0.0026 s/iter. Total: 0.0580 s/iter. ETA=0:01:23
[03/01 22:21:23 d2.evaluation.evaluator]: Inference done 1564/2919. Dataloading: 0.0028 s/iter. Inference: 0.0529 s/iter. Eval: 0.0026 s/iter. Total: 0.0583 s/iter. ETA=0:01:18
[03/01 22:21:29 d2.evaluation.evaluator]: Inference done 1616/2919. Dataloading: 0.0028 s/iter. Inference: 0.0541 s/iter. Eval: 0.0027 s/iter. Total: 0.0596 s/iter. ETA=0:01:17
[03/01 22:21:34 d2.evaluation.evaluator]: Inference done 1697/2919. Dataloading: 0.0028 s/iter. Inference: 0.0542 s/iter. Eval: 0.0027 s/iter. Total: 0.0597 s/iter. ETA=0:01:12
[03/01 22:21:39 d2.evaluation.evaluator]: Inference done 1781/2919. Dataloading: 0.0028 s/iter. Inference: 0.0542 s/iter. Eval: 0.0027 s/iter. Total: 0.0597 s/iter. ETA=0:01:07
[03/01 22:21:44 d2.evaluation.evaluator]: Inference done 1862/2919. Dataloading: 0.0028 s/iter. Inference: 0.0542 s/iter. Eval: 0.0028 s/iter. Total: 0.0598 s/iter. ETA=0:01:03
[03/01 22:21:49 d2.evaluation.evaluator]: Inference done 1936/2919. Dataloading: 0.0028 s/iter. Inference: 0.0545 s/iter. Eval: 0.0028 s/iter. Total: 0.0602 s/iter. ETA=0:00:59
[03/01 22:21:54 d2.evaluation.evaluator]: Inference done 2020/2919. Dataloading: 0.0028 s/iter. Inference: 0.0544 s/iter. Eval: 0.0028 s/iter. Total: 0.0601 s/iter. ETA=0:00:54
[03/01 22:21:59 d2.evaluation.evaluator]: Inference done 2095/2919. Dataloading: 0.0028 s/iter. Inference: 0.0546 s/iter. Eval: 0.0030 s/iter. Total: 0.0604 s/iter. ETA=0:00:49
[03/01 22:22:04 d2.evaluation.evaluator]: Inference done 2176/2919. Dataloading: 0.0028 s/iter. Inference: 0.0546 s/iter. Eval: 0.0030 s/iter. Total: 0.0605 s/iter. ETA=0:00:44
[03/01 22:22:09 d2.evaluation.evaluator]: Inference done 2262/2919. Dataloading: 0.0028 s/iter. Inference: 0.0546 s/iter. Eval: 0.0030 s/iter. Total: 0.0604 s/iter. ETA=0:00:39
[03/01 22:22:14 d2.evaluation.evaluator]: Inference done 2334/2919. Dataloading: 0.0028 s/iter. Inference: 0.0548 s/iter. Eval: 0.0030 s/iter. Total: 0.0607 s/iter. ETA=0:00:35
[03/01 22:22:19 d2.evaluation.evaluator]: Inference done 2416/2919. Dataloading: 0.0028 s/iter. Inference: 0.0547 s/iter. Eval: 0.0031 s/iter. Total: 0.0607 s/iter. ETA=0:00:30
[03/01 22:22:24 d2.evaluation.evaluator]: Inference done 2491/2919. Dataloading: 0.0028 s/iter. Inference: 0.0548 s/iter. Eval: 0.0033 s/iter. Total: 0.0609 s/iter. ETA=0:00:26
[03/01 22:22:29 d2.evaluation.evaluator]: Inference done 2572/2919. Dataloading: 0.0028 s/iter. Inference: 0.0547 s/iter. Eval: 0.0034 s/iter. Total: 0.0609 s/iter. ETA=0:00:21
[03/01 22:22:34 d2.evaluation.evaluator]: Inference done 2651/2919. Dataloading: 0.0028 s/iter. Inference: 0.0548 s/iter. Eval: 0.0034 s/iter. Total: 0.0610 s/iter. ETA=0:00:16
[03/01 22:22:39 d2.evaluation.evaluator]: Inference done 2737/2919. Dataloading: 0.0028 s/iter. Inference: 0.0547 s/iter. Eval: 0.0033 s/iter. Total: 0.0610 s/iter. ETA=0:00:11
[03/01 22:22:44 d2.evaluation.evaluator]: Inference done 2823/2919. Dataloading: 0.0028 s/iter. Inference: 0.0546 s/iter. Eval: 0.0033 s/iter. Total: 0.0609 s/iter. ETA=0:00:05
[03/01 22:22:49 d2.evaluation.evaluator]: Inference done 2907/2919. Dataloading: 0.0028 s/iter. Inference: 0.0546 s/iter. Eval: 0.0033 s/iter. Total: 0.0609 s/iter. ETA=0:00:00
[03/01 22:22:50 d2.evaluation.evaluator]: Total inference time: 0:02:57.327548 (0.060854 s / iter per device, on 1 devices)
[03/01 22:22:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:02:39 (0.054585 s / iter per device, on 1 devices)
[03/01 22:22:50 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[03/01 22:22:50 d2.evaluation.coco_evaluation]: Saving results to /ghome/group07/C5-W2/lr_0_05_bs_32_is_16/coco_instances_results.json
[03/01 22:22:50 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[03/01 22:22:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[03/01 22:22:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 1.03 seconds.
[03/01 22:22:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[03/01 22:22:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.10 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.249
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.516
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
[03/01 22:22:51 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.725 | 55.785 | 43.898 | 24.871 | 45.211 | 51.553 |
[03/01 22:22:51 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 64.265 | pedestrian | 47.378 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 4.531  |            |        |
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
[03/01 22:22:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[03/01 22:22:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.96 seconds.
[03/01 22:22:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[03/01 22:22:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.09 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.367
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600
[03/01 22:22:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 34.320 | 52.871 | 36.722 | 19.522 | 40.708 | 54.321 |
[03/01 22:22:53 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 64.057 | pedestrian | 35.259 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 3.644  |            |        |
OrderedDict([('bbox', {'AP': 38.72465375239903, 'AP50': 55.78537101181127, 'AP75': 43.89784638197318, 'APs': 24.87144294027999, 'APm': 45.211243947940005, 'APl': 51.553272811813336, 'AP-background': nan, 'AP-car': 64.26456855198673, 'AP-pedestrian': 47.37811926642462, 'AP-': nan, 'AP-ignore': 4.531273438785739}), ('segm', {'AP': 34.320217716814824, 'AP50': 52.870592012938786, 'AP75': 36.72204753993079, 'APs': 19.522345486629277, 'APm': 40.7081222605622, 'APl': 54.320588480099005, 'AP-background': nan, 'AP-car': 64.05733683020641, 'AP-pedestrian': 35.25927220677766, 'AP-': nan, 'AP-ignore': 3.6440441134603994})])
