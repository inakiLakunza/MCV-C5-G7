Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (44, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (44,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (11, 256, 1, 1) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
roi_heads.mask_head.predictor.{bias, weight}
/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])
/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])
/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])
/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])
/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2024-02-29 20:55:40.161829: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-29 20:55:40.161956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-29 20:55:40.163547: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-29 20:55:40.174424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-29 20:55:46.653426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Traceback (most recent call last):
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/compat/__init__.py", line 42, in tf
    from tensorboard.compat import notf  # noqa: F401
ImportError: cannot import name 'notf' from 'tensorboard.compat' (/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/compat/__init__.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/engine/hooks.py", line 181, in after_step
    writer.write()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/utils/events.py", line 169, in write
    self._writer.add_scalar(k, v, iter)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/functools.py", line 981, in __get__
    val = self.func(instance)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/utils/events.py", line 160, in _writer
    from torch.utils.tensorboard import SummaryWriter
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py", line 12, in <module>
    from .writer import FileWriter, SummaryWriter  # noqa: F401
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py", line 18, in <module>
    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/torch/utils/tensorboard/_embedding.py", line 9, in <module>
    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, "join")
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/lazy.py", line 65, in __getattr__
    return getattr(load_once(self), attr_name)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/lazy.py", line 97, in wrapper
    cache[arg] = f(arg)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/lazy.py", line 50, in load_once
    module = load_fn()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/compat/__init__.py", line 45, in tf
    import tensorflow
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/__init__.py", line 48, in <module>
    from tensorflow._api.v2 import __internal__
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py", line 13, in <module>
    from tensorflow._api.v2.__internal__ import feature_column
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/feature_column/__init__.py", line 8, in <module>
    from tensorflow.python.feature_column.feature_column_v2 import DenseColumn # line: 1983
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/feature_column/feature_column_v2.py", line 137, in <module>
    from tensorflow.python.feature_column import feature_column as fc_old
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/feature_column/feature_column.py", line 143, in <module>
    from tensorflow.python.layers import base
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/layers/base.py", line 16, in <module>
    from tensorflow.python.keras.legacy_tf_layers import base
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/__init__.py", line 25, in <module>
    from tensorflow.python.keras import models
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/models.py", line 25, in <module>
    from tensorflow.python.keras.engine import training_v1
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/engine/training_v1.py", line 46, in <module>
    from tensorflow.python.keras.engine import training_arrays_v1
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py", line 37, in <module>
    from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/sparse/__init__.py", line 294, in <module>
    from ._base import *
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/sparse/_base.py", line 5, in <module>
    from scipy._lib._util import VisibleDeprecationWarning
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/_lib/_util.py", line 18, in <module>
    from scipy._lib._array_api import array_namespace
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/_lib/_array_api.py", line 15, in <module>
    from numpy.testing import assert_
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/testing/__init__.py", line 11, in <module>
    from ._private.utils import *
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/testing/_private/utils.py", line 1253, in <module>
    _SUPPORTS_SVE = check_support_sve()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/testing/_private/utils.py", line 1247, in check_support_sve
    output = subprocess.run(cmd, capture_output=True, text=True)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 505, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 1154, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 2059, in _communicate
    stdout = self._translate_newlines(stdout,
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 1031, in _translate_newlines
    data = data.decode(encoding, errors)
UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 62: ordinal not in range(128)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/compat/__init__.py", line 42, in tf
    from tensorboard.compat import notf  # noqa: F401
ImportError: cannot import name 'notf' from 'tensorboard.compat' (/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/compat/__init__.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/export/home/group07/C5-W2/task_e.py", line 123, in <module>
    trainer.train()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/engine/defaults.py", line 486, in train
    super().train(self.start_iter, self.max_iter)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 165, in train
    self.after_train()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/engine/train_loop.py", line 174, in after_train
    h.after_train()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/engine/hooks.py", line 187, in after_train
    writer.write()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/utils/events.py", line 169, in write
    self._writer.add_scalar(k, v, iter)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/functools.py", line 981, in __get__
    val = self.func(instance)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/detectron2/utils/events.py", line 160, in _writer
    from torch.utils.tensorboard import SummaryWriter
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py", line 12, in <module>
    from .writer import FileWriter, SummaryWriter  # noqa: F401
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py", line 18, in <module>
    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/torch/utils/tensorboard/_embedding.py", line 9, in <module>
    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, "join")
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/lazy.py", line 65, in __getattr__
    return getattr(load_once(self), attr_name)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/lazy.py", line 97, in wrapper
    cache[arg] = f(arg)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/lazy.py", line 50, in load_once
    module = load_fn()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorboard/compat/__init__.py", line 45, in tf
    import tensorflow
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/__init__.py", line 48, in <module>
    from tensorflow._api.v2 import __internal__
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py", line 13, in <module>
    from tensorflow._api.v2.__internal__ import feature_column
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/feature_column/__init__.py", line 8, in <module>
    from tensorflow.python.feature_column.feature_column_v2 import DenseColumn # line: 1983
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/feature_column/feature_column_v2.py", line 137, in <module>
    from tensorflow.python.feature_column import feature_column as fc_old
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/feature_column/feature_column.py", line 143, in <module>
    from tensorflow.python.layers import base
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/layers/base.py", line 16, in <module>
    from tensorflow.python.keras.legacy_tf_layers import base
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/__init__.py", line 25, in <module>
    from tensorflow.python.keras import models
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/models.py", line 25, in <module>
    from tensorflow.python.keras.engine import training_v1
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/engine/training_v1.py", line 46, in <module>
    from tensorflow.python.keras.engine import training_arrays_v1
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py", line 37, in <module>
    from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/sparse/__init__.py", line 294, in <module>
    from ._base import *
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/sparse/_base.py", line 5, in <module>
    from scipy._lib._util import VisibleDeprecationWarning
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/_lib/_util.py", line 18, in <module>
    from scipy._lib._array_api import array_namespace
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/scipy/_lib/_array_api.py", line 15, in <module>
    from numpy.testing import assert_
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/testing/__init__.py", line 11, in <module>
    from ._private.utils import *
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/testing/_private/utils.py", line 1253, in <module>
    _SUPPORTS_SVE = check_support_sve()
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/testing/_private/utils.py", line 1247, in check_support_sve
    output = subprocess.run(cmd, capture_output=True, text=True)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 505, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 1154, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 2059, in _communicate
    stdout = self._translate_newlines(stdout,
  File "/ghome/group07/anaconda3/envs/torch/lib/python3.10/subprocess.py", line 1031, in _translate_newlines
    data = data.decode(encoding, errors)
UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 62: ordinal not in range(128)
