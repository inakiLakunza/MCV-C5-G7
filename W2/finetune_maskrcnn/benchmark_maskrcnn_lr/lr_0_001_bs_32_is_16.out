1
The device we will be working on is: cuda
[03/01 21:49:04 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[03/01 21:49:08 d2.data.build]: Removed 0 images with no usable annotations. 5007 images left.
[03/01 21:49:08 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 18822        | pedestrian | 8065         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 4977         |            |              |
|   total    | 31864        |            |              |            |              |
[03/01 21:49:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[03/01 21:49:08 d2.data.build]: Using training sampler TrainingSampler
[03/01 21:49:08 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 21:49:08 d2.data.common]: Serializing 5007 elements to byte tensors and concatenating them all ...
[03/01 21:49:08 d2.data.common]: Serialized dataset takes 13.56 MiB
[03/01 21:49:08 d2.data.build]: Making batched data loader with batch_size=16
WARNING [03/01 21:49:08 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[03/01 21:49:08 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...
[03/01 21:49:08 d2.engine.train_loop]: Starting training from iteration 0
[03/01 21:49:42 d2.utils.events]:  eta: 0:29:42  iter: 19  total_loss: 3.793  loss_cls: 2.391  loss_box_reg: 0.4695  loss_mask: 0.6898  loss_rpn_cls: 0.166  loss_rpn_loc: 0.08894    time: 1.3101  last_time: 1.2193  data_time: 0.6017  last_data_time: 0.3295   lr: 1.9981e-05  max_mem: 15981M
[03/01 21:50:13 d2.utils.events]:  eta: 0:29:05  iter: 39  total_loss: 3.214  loss_cls: 1.925  loss_box_reg: 0.4385  loss_mask: 0.6642  loss_rpn_cls: 0.1538  loss_rpn_loc: 0.08988    time: 1.2815  last_time: 1.1400  data_time: 0.3612  last_data_time: 0.2935   lr: 3.9961e-05  max_mem: 15981M
[03/01 21:50:40 d2.utils.events]:  eta: 0:29:02  iter: 59  total_loss: 2.444  loss_cls: 1.069  loss_box_reg: 0.4782  loss_mask: 0.6125  loss_rpn_cls: 0.1361  loss_rpn_loc: 0.09161    time: 1.3036  last_time: 1.2370  data_time: 0.3965  last_data_time: 0.3098   lr: 5.9941e-05  max_mem: 15981M
[03/01 21:51:04 d2.utils.events]:  eta: 0:28:22  iter: 79  total_loss: 1.769  loss_cls: 0.5841  loss_box_reg: 0.4593  loss_mask: 0.563  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.07232    time: 1.2741  last_time: 1.1626  data_time: 0.3188  last_data_time: 0.3052   lr: 7.9921e-05  max_mem: 15981M
[03/01 21:51:29 d2.utils.events]:  eta: 0:27:58  iter: 99  total_loss: 1.615  loss_cls: 0.5059  loss_box_reg: 0.441  loss_mask: 0.5022  loss_rpn_cls: 0.08285  loss_rpn_loc: 0.07417    time: 1.2644  last_time: 1.7335  data_time: 0.3597  last_data_time: 0.8586   lr: 9.9901e-05  max_mem: 15981M
[03/01 21:51:53 d2.utils.events]:  eta: 0:27:33  iter: 119  total_loss: 1.455  loss_cls: 0.4179  loss_box_reg: 0.4187  loss_mask: 0.4574  loss_rpn_cls: 0.07837  loss_rpn_loc: 0.08246    time: 1.2556  last_time: 1.1830  data_time: 0.3320  last_data_time: 0.3399   lr: 0.00011988  max_mem: 15981M
[03/01 21:52:17 d2.utils.events]:  eta: 0:27:08  iter: 139  total_loss: 1.334  loss_cls: 0.3627  loss_box_reg: 0.43  loss_mask: 0.4179  loss_rpn_cls: 0.06514  loss_rpn_loc: 0.07724    time: 1.2462  last_time: 1.1669  data_time: 0.3131  last_data_time: 0.2998   lr: 0.00013986  max_mem: 15981M
[03/01 21:52:41 d2.utils.events]:  eta: 0:26:45  iter: 159  total_loss: 1.288  loss_cls: 0.3335  loss_box_reg: 0.4273  loss_mask: 0.3822  loss_rpn_cls: 0.05545  loss_rpn_loc: 0.07292    time: 1.2425  last_time: 1.2186  data_time: 0.3248  last_data_time: 0.3424   lr: 0.00015984  max_mem: 15981M
[03/01 21:53:06 d2.utils.events]:  eta: 0:26:24  iter: 179  total_loss: 1.199  loss_cls: 0.2984  loss_box_reg: 0.4035  loss_mask: 0.3509  loss_rpn_cls: 0.05425  loss_rpn_loc: 0.08099    time: 1.2413  last_time: 1.2731  data_time: 0.3319  last_data_time: 0.3617   lr: 0.00017982  max_mem: 16062M
[03/01 21:53:31 d2.utils.events]:  eta: 0:26:04  iter: 199  total_loss: 1.168  loss_cls: 0.2901  loss_box_reg: 0.3963  loss_mask: 0.344  loss_rpn_cls: 0.0495  loss_rpn_loc: 0.0742    time: 1.2425  last_time: 1.2030  data_time: 0.3449  last_data_time: 0.2888   lr: 0.0001998  max_mem: 16505M
[03/01 21:53:56 d2.utils.events]:  eta: 0:25:44  iter: 219  total_loss: 1.091  loss_cls: 0.2645  loss_box_reg: 0.3825  loss_mask: 0.3224  loss_rpn_cls: 0.04799  loss_rpn_loc: 0.07423    time: 1.2420  last_time: 1.2045  data_time: 0.3264  last_data_time: 0.2874   lr: 0.00021978  max_mem: 16505M
[03/01 21:54:20 d2.utils.events]:  eta: 0:25:20  iter: 239  total_loss: 0.9797  loss_cls: 0.2312  loss_box_reg: 0.3145  loss_mask: 0.2968  loss_rpn_cls: 0.04604  loss_rpn_loc: 0.07823    time: 1.2393  last_time: 1.2802  data_time: 0.3144  last_data_time: 0.3533   lr: 0.00023976  max_mem: 16505M
[03/01 21:54:44 d2.utils.events]:  eta: 0:24:55  iter: 259  total_loss: 0.926  loss_cls: 0.2114  loss_box_reg: 0.2819  loss_mask: 0.2849  loss_rpn_cls: 0.0466  loss_rpn_loc: 0.07339    time: 1.2375  last_time: 1.1887  data_time: 0.3319  last_data_time: 0.3020   lr: 0.00025974  max_mem: 16505M
[03/01 21:55:08 d2.utils.events]:  eta: 0:24:30  iter: 279  total_loss: 0.8785  loss_cls: 0.1994  loss_box_reg: 0.2715  loss_mask: 0.2817  loss_rpn_cls: 0.04173  loss_rpn_loc: 0.08053    time: 1.2352  last_time: 1.2940  data_time: 0.3200  last_data_time: 0.4146   lr: 0.00027972  max_mem: 16505M
[03/01 21:55:32 d2.utils.events]:  eta: 0:24:07  iter: 299  total_loss: 0.8673  loss_cls: 0.1982  loss_box_reg: 0.2703  loss_mask: 0.2858  loss_rpn_cls: 0.04682  loss_rpn_loc: 0.07921    time: 1.2338  last_time: 1.2942  data_time: 0.3244  last_data_time: 0.3663   lr: 0.0002997  max_mem: 16505M
[03/01 21:55:57 d2.utils.events]:  eta: 0:23:42  iter: 319  total_loss: 0.8571  loss_cls: 0.1875  loss_box_reg: 0.2597  loss_mask: 0.2758  loss_rpn_cls: 0.04297  loss_rpn_loc: 0.08278    time: 1.2333  last_time: 1.2015  data_time: 0.3359  last_data_time: 0.3093   lr: 0.00031968  max_mem: 16505M
[03/01 21:56:21 d2.utils.events]:  eta: 0:23:18  iter: 339  total_loss: 0.8073  loss_cls: 0.1771  loss_box_reg: 0.2402  loss_mask: 0.2709  loss_rpn_cls: 0.04074  loss_rpn_loc: 0.08359    time: 1.2324  last_time: 1.1335  data_time: 0.3229  last_data_time: 0.2917   lr: 0.00033966  max_mem: 16505M
[03/01 21:56:46 d2.utils.events]:  eta: 0:22:55  iter: 359  total_loss: 0.8131  loss_cls: 0.1675  loss_box_reg: 0.2392  loss_mask: 0.2636  loss_rpn_cls: 0.03984  loss_rpn_loc: 0.07908    time: 1.2314  last_time: 1.2349  data_time: 0.3322  last_data_time: 0.3179   lr: 0.00035964  max_mem: 16505M
[03/01 21:57:10 d2.utils.events]:  eta: 0:22:30  iter: 379  total_loss: 0.7958  loss_cls: 0.1641  loss_box_reg: 0.2268  loss_mask: 0.2637  loss_rpn_cls: 0.0379  loss_rpn_loc: 0.07637    time: 1.2303  last_time: 1.4271  data_time: 0.3280  last_data_time: 0.5218   lr: 0.00037962  max_mem: 16505M
[03/01 21:57:34 d2.utils.events]:  eta: 0:22:07  iter: 399  total_loss: 0.7678  loss_cls: 0.1639  loss_box_reg: 0.2303  loss_mask: 0.2594  loss_rpn_cls: 0.0366  loss_rpn_loc: 0.07496    time: 1.2296  last_time: 1.2478  data_time: 0.3228  last_data_time: 0.3060   lr: 0.0003996  max_mem: 16505M
[03/01 21:57:59 d2.utils.events]:  eta: 0:21:43  iter: 419  total_loss: 0.762  loss_cls: 0.1585  loss_box_reg: 0.2337  loss_mask: 0.2518  loss_rpn_cls: 0.0359  loss_rpn_loc: 0.07323    time: 1.2295  last_time: 1.2432  data_time: 0.3284  last_data_time: 0.3538   lr: 0.00041958  max_mem: 16505M
[03/01 21:58:23 d2.utils.events]:  eta: 0:21:18  iter: 439  total_loss: 0.7205  loss_cls: 0.1496  loss_box_reg: 0.2066  loss_mask: 0.2618  loss_rpn_cls: 0.03485  loss_rpn_loc: 0.06568    time: 1.2280  last_time: 1.1797  data_time: 0.3128  last_data_time: 0.2840   lr: 0.00043956  max_mem: 16505M
[03/01 21:58:47 d2.utils.events]:  eta: 0:20:54  iter: 459  total_loss: 0.7217  loss_cls: 0.1406  loss_box_reg: 0.2118  loss_mask: 0.2555  loss_rpn_cls: 0.03529  loss_rpn_loc: 0.07518    time: 1.2268  last_time: 1.2349  data_time: 0.3116  last_data_time: 0.3297   lr: 0.00045954  max_mem: 16505M
[03/01 21:59:11 d2.utils.events]:  eta: 0:20:30  iter: 479  total_loss: 0.7284  loss_cls: 0.1504  loss_box_reg: 0.2193  loss_mask: 0.2439  loss_rpn_cls: 0.03388  loss_rpn_loc: 0.06577    time: 1.2265  last_time: 1.2037  data_time: 0.3264  last_data_time: 0.2834   lr: 0.00047952  max_mem: 16505M
[03/01 21:59:36 d2.utils.events]:  eta: 0:20:06  iter: 499  total_loss: 0.708  loss_cls: 0.1489  loss_box_reg: 0.2143  loss_mask: 0.2504  loss_rpn_cls: 0.03027  loss_rpn_loc: 0.05893    time: 1.2260  last_time: 1.1559  data_time: 0.3254  last_data_time: 0.3140   lr: 0.0004995  max_mem: 16505M
[03/01 22:00:01 d2.utils.events]:  eta: 0:19:41  iter: 519  total_loss: 0.7323  loss_cls: 0.1459  loss_box_reg: 0.2107  loss_mask: 0.2472  loss_rpn_cls: 0.03948  loss_rpn_loc: 0.07702    time: 1.2261  last_time: 1.1548  data_time: 0.3345  last_data_time: 0.2756   lr: 0.00051948  max_mem: 16505M
[03/01 22:00:25 d2.utils.events]:  eta: 0:19:17  iter: 539  total_loss: 0.6853  loss_cls: 0.1373  loss_box_reg: 0.2039  loss_mask: 0.2457  loss_rpn_cls: 0.03404  loss_rpn_loc: 0.07934    time: 1.2258  last_time: 1.1549  data_time: 0.3266  last_data_time: 0.2911   lr: 0.00053946  max_mem: 16505M
[03/01 22:00:50 d2.utils.events]:  eta: 0:18:54  iter: 559  total_loss: 0.7156  loss_cls: 0.1487  loss_box_reg: 0.2109  loss_mask: 0.2541  loss_rpn_cls: 0.0339  loss_rpn_loc: 0.06491    time: 1.2256  last_time: 1.2040  data_time: 0.3273  last_data_time: 0.2841   lr: 0.00055944  max_mem: 16505M
[03/01 22:01:14 d2.utils.events]:  eta: 0:18:30  iter: 579  total_loss: 0.7081  loss_cls: 0.1429  loss_box_reg: 0.1978  loss_mask: 0.244  loss_rpn_cls: 0.03666  loss_rpn_loc: 0.0729    time: 1.2250  last_time: 1.1624  data_time: 0.3222  last_data_time: 0.3058   lr: 0.00057942  max_mem: 16505M
[03/01 22:01:38 d2.utils.events]:  eta: 0:18:05  iter: 599  total_loss: 0.6903  loss_cls: 0.1376  loss_box_reg: 0.1953  loss_mask: 0.2478  loss_rpn_cls: 0.03223  loss_rpn_loc: 0.06999    time: 1.2243  last_time: 1.5163  data_time: 0.3270  last_data_time: 0.6511   lr: 0.0005994  max_mem: 16505M
[03/01 22:02:02 d2.utils.events]:  eta: 0:17:41  iter: 619  total_loss: 0.6628  loss_cls: 0.1374  loss_box_reg: 0.1918  loss_mask: 0.2356  loss_rpn_cls: 0.02555  loss_rpn_loc: 0.06169    time: 1.2243  last_time: 1.2023  data_time: 0.3370  last_data_time: 0.3302   lr: 0.00061938  max_mem: 16505M
[03/01 22:02:26 d2.utils.events]:  eta: 0:17:16  iter: 639  total_loss: 0.6657  loss_cls: 0.1342  loss_box_reg: 0.1868  loss_mask: 0.2389  loss_rpn_cls: 0.03028  loss_rpn_loc: 0.06835    time: 1.2236  last_time: 1.2122  data_time: 0.3173  last_data_time: 0.3569   lr: 0.00063936  max_mem: 16505M
[03/01 22:02:50 d2.utils.events]:  eta: 0:16:52  iter: 659  total_loss: 0.6541  loss_cls: 0.1328  loss_box_reg: 0.1905  loss_mask: 0.2359  loss_rpn_cls: 0.02732  loss_rpn_loc: 0.06841    time: 1.2229  last_time: 1.2087  data_time: 0.3166  last_data_time: 0.3118   lr: 0.00065934  max_mem: 16505M
[03/01 22:03:15 d2.utils.events]:  eta: 0:16:28  iter: 679  total_loss: 0.6468  loss_cls: 0.1321  loss_box_reg: 0.1938  loss_mask: 0.2316  loss_rpn_cls: 0.03058  loss_rpn_loc: 0.06938    time: 1.2225  last_time: 1.1811  data_time: 0.3174  last_data_time: 0.2989   lr: 0.00067932  max_mem: 16505M
[03/01 22:03:39 d2.utils.events]:  eta: 0:16:04  iter: 699  total_loss: 0.6798  loss_cls: 0.1369  loss_box_reg: 0.1933  loss_mask: 0.2343  loss_rpn_cls: 0.03019  loss_rpn_loc: 0.06954    time: 1.2224  last_time: 1.1544  data_time: 0.3320  last_data_time: 0.2968   lr: 0.0006993  max_mem: 16505M
[03/01 22:04:03 d2.utils.events]:  eta: 0:15:40  iter: 719  total_loss: 0.6712  loss_cls: 0.1335  loss_box_reg: 0.1954  loss_mask: 0.236  loss_rpn_cls: 0.02653  loss_rpn_loc: 0.07595    time: 1.2217  last_time: 1.1820  data_time: 0.3100  last_data_time: 0.2996   lr: 0.00071928  max_mem: 16505M
[03/01 22:04:27 d2.utils.events]:  eta: 0:15:16  iter: 739  total_loss: 0.6456  loss_cls: 0.1353  loss_box_reg: 0.1859  loss_mask: 0.2338  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.06302    time: 1.2214  last_time: 1.1657  data_time: 0.3280  last_data_time: 0.3220   lr: 0.00073926  max_mem: 16505M
[03/01 22:04:51 d2.utils.events]:  eta: 0:14:52  iter: 759  total_loss: 0.6494  loss_cls: 0.1287  loss_box_reg: 0.1935  loss_mask: 0.231  loss_rpn_cls: 0.02805  loss_rpn_loc: 0.06317    time: 1.2209  last_time: 1.1476  data_time: 0.3182  last_data_time: 0.2933   lr: 0.00075924  max_mem: 16505M
[03/01 22:05:16 d2.utils.events]:  eta: 0:14:28  iter: 779  total_loss: 0.6729  loss_cls: 0.1311  loss_box_reg: 0.1934  loss_mask: 0.2271  loss_rpn_cls: 0.02844  loss_rpn_loc: 0.07407    time: 1.2212  last_time: 1.2478  data_time: 0.3295  last_data_time: 0.3660   lr: 0.00077922  max_mem: 16505M
[03/01 22:05:41 d2.utils.events]:  eta: 0:14:04  iter: 799  total_loss: 0.6996  loss_cls: 0.1389  loss_box_reg: 0.2033  loss_mask: 0.2409  loss_rpn_cls: 0.03195  loss_rpn_loc: 0.07122    time: 1.2214  last_time: 1.2433  data_time: 0.3212  last_data_time: 0.3470   lr: 0.0007992  max_mem: 16505M
[03/01 22:06:05 d2.utils.events]:  eta: 0:13:40  iter: 819  total_loss: 0.6635  loss_cls: 0.142  loss_box_reg: 0.1957  loss_mask: 0.2279  loss_rpn_cls: 0.02926  loss_rpn_loc: 0.06997    time: 1.2215  last_time: 1.2279  data_time: 0.3333  last_data_time: 0.3272   lr: 0.00081918  max_mem: 16505M
[03/01 22:06:30 d2.utils.events]:  eta: 0:13:16  iter: 839  total_loss: 0.6829  loss_cls: 0.1337  loss_box_reg: 0.2058  loss_mask: 0.2286  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.07216    time: 1.2220  last_time: 1.2552  data_time: 0.3399  last_data_time: 0.3689   lr: 0.00083916  max_mem: 16505M
[03/01 22:06:54 d2.utils.events]:  eta: 0:12:52  iter: 859  total_loss: 0.6323  loss_cls: 0.1309  loss_box_reg: 0.1935  loss_mask: 0.2189  loss_rpn_cls: 0.02554  loss_rpn_loc: 0.06991    time: 1.2218  last_time: 1.2008  data_time: 0.3226  last_data_time: 0.3291   lr: 0.00085914  max_mem: 16505M
[03/01 22:07:18 d2.utils.events]:  eta: 0:12:28  iter: 879  total_loss: 0.6089  loss_cls: 0.1221  loss_box_reg: 0.1809  loss_mask: 0.2267  loss_rpn_cls: 0.02474  loss_rpn_loc: 0.05563    time: 1.2212  last_time: 1.2111  data_time: 0.3132  last_data_time: 0.3220   lr: 0.00087912  max_mem: 16505M
[03/01 22:07:43 d2.utils.events]:  eta: 0:12:04  iter: 899  total_loss: 0.6483  loss_cls: 0.1307  loss_box_reg: 0.1966  loss_mask: 0.229  loss_rpn_cls: 0.02707  loss_rpn_loc: 0.06404    time: 1.2213  last_time: 1.2225  data_time: 0.3309  last_data_time: 0.3118   lr: 0.0008991  max_mem: 16505M
[03/01 22:08:07 d2.utils.events]:  eta: 0:11:40  iter: 919  total_loss: 0.6581  loss_cls: 0.1298  loss_box_reg: 0.2004  loss_mask: 0.2314  loss_rpn_cls: 0.02715  loss_rpn_loc: 0.06489    time: 1.2212  last_time: 1.1221  data_time: 0.3189  last_data_time: 0.2516   lr: 0.00091908  max_mem: 16505M
[03/01 22:08:31 d2.utils.events]:  eta: 0:11:15  iter: 939  total_loss: 0.621  loss_cls: 0.1203  loss_box_reg: 0.1853  loss_mask: 0.2184  loss_rpn_cls: 0.02383  loss_rpn_loc: 0.0736    time: 1.2207  last_time: 1.2668  data_time: 0.3112  last_data_time: 0.3260   lr: 0.00093906  max_mem: 16505M
[03/01 22:08:55 d2.utils.events]:  eta: 0:10:51  iter: 959  total_loss: 0.6363  loss_cls: 0.1247  loss_box_reg: 0.1886  loss_mask: 0.2224  loss_rpn_cls: 0.02807  loss_rpn_loc: 0.06826    time: 1.2204  last_time: 1.2777  data_time: 0.3177  last_data_time: 0.3444   lr: 0.00095904  max_mem: 16505M
[03/01 22:09:20 d2.utils.events]:  eta: 0:10:27  iter: 979  total_loss: 0.6099  loss_cls: 0.1217  loss_box_reg: 0.186  loss_mask: 0.2215  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.06646    time: 1.2203  last_time: 1.1422  data_time: 0.3183  last_data_time: 0.2773   lr: 0.00097902  max_mem: 16505M
[03/01 22:09:45 d2.utils.events]:  eta: 0:10:03  iter: 999  total_loss: 0.6222  loss_cls: 0.1285  loss_box_reg: 0.1967  loss_mask: 0.2204  loss_rpn_cls: 0.02212  loss_rpn_loc: 0.06097    time: 1.2204  last_time: 1.1746  data_time: 0.3377  last_data_time: 0.3069   lr: 0.000999  max_mem: 16505M
[03/01 22:10:10 d2.utils.events]:  eta: 0:09:39  iter: 1019  total_loss: 0.6746  loss_cls: 0.1311  loss_box_reg: 0.2037  loss_mask: 0.2182  loss_rpn_cls: 0.02682  loss_rpn_loc: 0.08107    time: 1.2211  last_time: 1.3194  data_time: 0.3459  last_data_time: 0.3595   lr: 0.001  max_mem: 16505M
[03/01 22:10:34 d2.utils.events]:  eta: 0:09:15  iter: 1039  total_loss: 0.6187  loss_cls: 0.1231  loss_box_reg: 0.1902  loss_mask: 0.2089  loss_rpn_cls: 0.02487  loss_rpn_loc: 0.07037    time: 1.2208  last_time: 1.1575  data_time: 0.3234  last_data_time: 0.3037   lr: 0.001  max_mem: 16505M
[03/01 22:10:59 d2.utils.events]:  eta: 0:08:51  iter: 1059  total_loss: 0.6559  loss_cls: 0.1367  loss_box_reg: 0.1932  loss_mask: 0.2124  loss_rpn_cls: 0.0237  loss_rpn_loc: 0.07161    time: 1.2209  last_time: 1.2296  data_time: 0.3275  last_data_time: 0.3342   lr: 0.001  max_mem: 16505M
[03/01 22:11:23 d2.utils.events]:  eta: 0:08:27  iter: 1079  total_loss: 0.6177  loss_cls: 0.1228  loss_box_reg: 0.1771  loss_mask: 0.2215  loss_rpn_cls: 0.02333  loss_rpn_loc: 0.05892    time: 1.2203  last_time: 1.1910  data_time: 0.3071  last_data_time: 0.3203   lr: 0.001  max_mem: 16505M
[03/01 22:11:47 d2.utils.events]:  eta: 0:08:03  iter: 1099  total_loss: 0.6279  loss_cls: 0.1266  loss_box_reg: 0.1954  loss_mask: 0.2177  loss_rpn_cls: 0.02221  loss_rpn_loc: 0.06081    time: 1.2204  last_time: 1.2725  data_time: 0.3175  last_data_time: 0.3449   lr: 0.001  max_mem: 16505M
[03/01 22:12:18 d2.utils.events]:  eta: 0:07:39  iter: 1119  total_loss: 0.6234  loss_cls: 0.1237  loss_box_reg: 0.1894  loss_mask: 0.2173  loss_rpn_cls: 0.02302  loss_rpn_loc: 0.05613    time: 1.2258  last_time: 1.2521  data_time: 0.3694  last_data_time: 0.3172   lr: 0.001  max_mem: 16505M
[03/01 22:12:42 d2.utils.events]:  eta: 0:07:15  iter: 1139  total_loss: 0.6301  loss_cls: 0.1289  loss_box_reg: 0.2019  loss_mask: 0.2186  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.05707    time: 1.2257  last_time: 1.2058  data_time: 0.3260  last_data_time: 0.3520   lr: 0.001  max_mem: 16505M
[03/01 22:13:07 d2.utils.events]:  eta: 0:06:51  iter: 1159  total_loss: 0.616  loss_cls: 0.1263  loss_box_reg: 0.1976  loss_mask: 0.2134  loss_rpn_cls: 0.02158  loss_rpn_loc: 0.0646    time: 1.2258  last_time: 1.2190  data_time: 0.3262  last_data_time: 0.3002   lr: 0.001  max_mem: 16505M
[03/01 22:13:31 d2.utils.events]:  eta: 0:06:27  iter: 1179  total_loss: 0.6195  loss_cls: 0.1232  loss_box_reg: 0.1905  loss_mask: 0.2071  loss_rpn_cls: 0.02385  loss_rpn_loc: 0.06594    time: 1.2258  last_time: 1.2466  data_time: 0.3235  last_data_time: 0.3133   lr: 0.001  max_mem: 16505M
[03/01 22:13:56 d2.utils.events]:  eta: 0:06:02  iter: 1199  total_loss: 0.6181  loss_cls: 0.1268  loss_box_reg: 0.1853  loss_mask: 0.2079  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.06551    time: 1.2259  last_time: 1.2624  data_time: 0.3316  last_data_time: 0.3346   lr: 0.001  max_mem: 16505M
[03/01 22:14:20 d2.utils.events]:  eta: 0:05:38  iter: 1219  total_loss: 0.5781  loss_cls: 0.1165  loss_box_reg: 0.1661  loss_mask: 0.2024  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.06506    time: 1.2259  last_time: 1.2353  data_time: 0.3186  last_data_time: 0.3455   lr: 0.001  max_mem: 16505M
[03/01 22:14:45 d2.utils.events]:  eta: 0:05:15  iter: 1239  total_loss: 0.6269  loss_cls: 0.1217  loss_box_reg: 0.1837  loss_mask: 0.2097  loss_rpn_cls: 0.025  loss_rpn_loc: 0.06865    time: 1.2264  last_time: 1.2618  data_time: 0.3356  last_data_time: 0.3555   lr: 0.001  max_mem: 16505M
[03/01 22:15:10 d2.utils.events]:  eta: 0:04:50  iter: 1259  total_loss: 0.6103  loss_cls: 0.1203  loss_box_reg: 0.1875  loss_mask: 0.2054  loss_rpn_cls: 0.02393  loss_rpn_loc: 0.06115    time: 1.2262  last_time: 1.2986  data_time: 0.3085  last_data_time: 0.3641   lr: 0.001  max_mem: 16505M
[03/01 22:15:34 d2.utils.events]:  eta: 0:04:26  iter: 1279  total_loss: 0.5918  loss_cls: 0.1199  loss_box_reg: 0.1906  loss_mask: 0.2042  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.05798    time: 1.2262  last_time: 1.3389  data_time: 0.3249  last_data_time: 0.4065   lr: 0.001  max_mem: 16505M
[03/01 22:15:58 d2.utils.events]:  eta: 0:04:02  iter: 1299  total_loss: 0.5827  loss_cls: 0.1154  loss_box_reg: 0.1761  loss_mask: 0.2031  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.06192    time: 1.2259  last_time: 1.2377  data_time: 0.3180  last_data_time: 0.3031   lr: 0.001  max_mem: 16505M
[03/01 22:16:23 d2.utils.events]:  eta: 0:03:38  iter: 1319  total_loss: 0.5884  loss_cls: 0.1143  loss_box_reg: 0.1869  loss_mask: 0.2093  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.06498    time: 1.2260  last_time: 1.2210  data_time: 0.3273  last_data_time: 0.3049   lr: 0.001  max_mem: 16505M
[03/01 22:16:48 d2.utils.events]:  eta: 0:03:14  iter: 1339  total_loss: 0.5878  loss_cls: 0.116  loss_box_reg: 0.1865  loss_mask: 0.202  loss_rpn_cls: 0.0199  loss_rpn_loc: 0.05913    time: 1.2260  last_time: 1.2594  data_time: 0.3272  last_data_time: 0.3375   lr: 0.001  max_mem: 16505M
[03/01 22:17:13 d2.utils.events]:  eta: 0:02:49  iter: 1359  total_loss: 0.6287  loss_cls: 0.1198  loss_box_reg: 0.2003  loss_mask: 0.2107  loss_rpn_cls: 0.01983  loss_rpn_loc: 0.06009    time: 1.2265  last_time: 1.2574  data_time: 0.3343  last_data_time: 0.2888   lr: 0.001  max_mem: 16505M
[03/01 22:17:37 d2.utils.events]:  eta: 0:02:25  iter: 1379  total_loss: 0.5949  loss_cls: 0.1211  loss_box_reg: 0.1872  loss_mask: 0.2076  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.06604    time: 1.2263  last_time: 1.2150  data_time: 0.3194  last_data_time: 0.3280   lr: 0.001  max_mem: 16505M
[03/01 22:18:02 d2.utils.events]:  eta: 0:02:01  iter: 1399  total_loss: 0.5778  loss_cls: 0.1136  loss_box_reg: 0.1784  loss_mask: 0.1966  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.05964    time: 1.2265  last_time: 1.2381  data_time: 0.3284  last_data_time: 0.3697   lr: 0.001  max_mem: 16505M
[03/01 22:18:27 d2.utils.events]:  eta: 0:01:37  iter: 1419  total_loss: 0.6108  loss_cls: 0.1202  loss_box_reg: 0.1916  loss_mask: 0.2005  loss_rpn_cls: 0.02001  loss_rpn_loc: 0.06987    time: 1.2268  last_time: 1.2343  data_time: 0.3360  last_data_time: 0.3127   lr: 0.001  max_mem: 16505M
[03/01 22:18:52 d2.utils.events]:  eta: 0:01:12  iter: 1439  total_loss: 0.6081  loss_cls: 0.1242  loss_box_reg: 0.1982  loss_mask: 0.1984  loss_rpn_cls: 0.02034  loss_rpn_loc: 0.06439    time: 1.2274  last_time: 1.1791  data_time: 0.3486  last_data_time: 0.2900   lr: 0.001  max_mem: 16505M
[03/01 22:19:16 d2.utils.events]:  eta: 0:00:48  iter: 1459  total_loss: 0.5598  loss_cls: 0.1109  loss_box_reg: 0.1696  loss_mask: 0.1935  loss_rpn_cls: 0.01979  loss_rpn_loc: 0.06386    time: 1.2270  last_time: 1.1646  data_time: 0.3129  last_data_time: 0.2735   lr: 0.001  max_mem: 16505M
[03/01 22:19:41 d2.utils.events]:  eta: 0:00:24  iter: 1479  total_loss: 0.5972  loss_cls: 0.1179  loss_box_reg: 0.1823  loss_mask: 0.2019  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.06523    time: 1.2269  last_time: 1.1550  data_time: 0.3144  last_data_time: 0.2929   lr: 0.001  max_mem: 16505M
[03/01 22:20:07 d2.utils.events]:  eta: 0:00:00  iter: 1499  total_loss: 0.6194  loss_cls: 0.1253  loss_box_reg: 0.1878  loss_mask: 0.2107  loss_rpn_cls: 0.02331  loss_rpn_loc: 0.06874    time: 1.2271  last_time: 1.2183  data_time: 0.3366  last_data_time: 0.2837   lr: 0.001  max_mem: 16505M
[03/01 22:20:07 d2.engine.hooks]: Overall training speed: 1498 iterations in 0:30:38 (1.2271 s / it)
[03/01 22:20:07 d2.engine.hooks]: Total training time: 0:30:49 (0:00:11 on hooks)
[03/01 22:20:10 d2.data.build]: Distribution of instances among all 11 categories:
|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
| background | 0            |    car     | 8021         | pedestrian | 3347         |
|            | 0            |            | 0            |            | 0            |
|            | 0            |            | 0            |            | 0            |
|            | 0            |   ignore   | 2765         |            |              |
|   total    | 14133        |            |              |            |              |
[03/01 22:20:10 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/01 22:20:10 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 22:20:10 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/01 22:20:10 d2.data.common]: Serialized dataset takes 5.86 MiB
WARNING [03/01 22:20:10 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[03/01 22:20:11 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /ghome/group07/C5-W2/lr_0_001_bs_32_is_16/model_0001499.pth ...
[03/01 22:20:12 d2.evaluation.coco_evaluation]: Trying to convert 'KITTI-MOTS_val' to COCO format ...
[03/01 22:20:12 d2.data.datasets.coco]: Converting annotations of dataset 'KITTI-MOTS_val' to COCO format ...)
[03/01 22:20:18 d2.data.datasets.coco]: Converting dataset dicts into COCO format
[03/01 22:20:18 d2.data.datasets.coco]: Conversion finished, #images: 2919, #annotations: 14133
[03/01 22:20:18 d2.data.datasets.coco]: Caching COCO format annotations at '/ghome/group07/C5-W2/lr_0_001_bs_32_is_16/KITTI-MOTS_val_coco_format.json' ...
[03/01 22:20:21 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[03/01 22:20:21 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/01 22:20:21 d2.data.common]: Serializing 2919 elements to byte tensors and concatenating them all ...
[03/01 22:20:21 d2.data.common]: Serialized dataset takes 5.86 MiB
[03/01 22:20:21 d2.evaluation.evaluator]: Start inference on 2919 batches
[03/01 22:20:30 d2.evaluation.evaluator]: Inference done 11/2919. Dataloading: 0.0046 s/iter. Inference: 0.0729 s/iter. Eval: 0.0084 s/iter. Total: 0.0860 s/iter. ETA=0:04:09
[03/01 22:20:35 d2.evaluation.evaluator]: Inference done 76/2919. Dataloading: 0.0049 s/iter. Inference: 0.0696 s/iter. Eval: 0.0038 s/iter. Total: 0.0783 s/iter. ETA=0:03:42
[03/01 22:20:40 d2.evaluation.evaluator]: Inference done 156/2919. Dataloading: 0.0044 s/iter. Inference: 0.0606 s/iter. Eval: 0.0050 s/iter. Total: 0.0701 s/iter. ETA=0:03:13
[03/01 22:20:45 d2.evaluation.evaluator]: Inference done 250/2919. Dataloading: 0.0038 s/iter. Inference: 0.0560 s/iter. Eval: 0.0040 s/iter. Total: 0.0638 s/iter. ETA=0:02:50
[03/01 22:20:50 d2.evaluation.evaluator]: Inference done 337/2919. Dataloading: 0.0035 s/iter. Inference: 0.0551 s/iter. Eval: 0.0035 s/iter. Total: 0.0621 s/iter. ETA=0:02:40
[03/01 22:20:55 d2.evaluation.evaluator]: Inference done 431/2919. Dataloading: 0.0034 s/iter. Inference: 0.0537 s/iter. Eval: 0.0031 s/iter. Total: 0.0603 s/iter. ETA=0:02:29
[03/01 22:21:00 d2.evaluation.evaluator]: Inference done 527/2919. Dataloading: 0.0033 s/iter. Inference: 0.0526 s/iter. Eval: 0.0029 s/iter. Total: 0.0588 s/iter. ETA=0:02:20
[03/01 22:21:05 d2.evaluation.evaluator]: Inference done 618/2919. Dataloading: 0.0032 s/iter. Inference: 0.0521 s/iter. Eval: 0.0029 s/iter. Total: 0.0583 s/iter. ETA=0:02:14
[03/01 22:21:10 d2.evaluation.evaluator]: Inference done 709/2919. Dataloading: 0.0032 s/iter. Inference: 0.0517 s/iter. Eval: 0.0029 s/iter. Total: 0.0579 s/iter. ETA=0:02:07
[03/01 22:21:15 d2.evaluation.evaluator]: Inference done 796/2919. Dataloading: 0.0032 s/iter. Inference: 0.0518 s/iter. Eval: 0.0029 s/iter. Total: 0.0579 s/iter. ETA=0:02:02
[03/01 22:21:20 d2.evaluation.evaluator]: Inference done 882/2919. Dataloading: 0.0031 s/iter. Inference: 0.0519 s/iter. Eval: 0.0029 s/iter. Total: 0.0580 s/iter. ETA=0:01:58
[03/01 22:21:25 d2.evaluation.evaluator]: Inference done 966/2919. Dataloading: 0.0031 s/iter. Inference: 0.0520 s/iter. Eval: 0.0029 s/iter. Total: 0.0581 s/iter. ETA=0:01:53
[03/01 22:21:30 d2.evaluation.evaluator]: Inference done 1055/2919. Dataloading: 0.0031 s/iter. Inference: 0.0520 s/iter. Eval: 0.0029 s/iter. Total: 0.0580 s/iter. ETA=0:01:48
[03/01 22:21:35 d2.evaluation.evaluator]: Inference done 1149/2919. Dataloading: 0.0031 s/iter. Inference: 0.0516 s/iter. Eval: 0.0029 s/iter. Total: 0.0576 s/iter. ETA=0:01:41
[03/01 22:21:40 d2.evaluation.evaluator]: Inference done 1236/2919. Dataloading: 0.0030 s/iter. Inference: 0.0516 s/iter. Eval: 0.0029 s/iter. Total: 0.0576 s/iter. ETA=0:01:36
[03/01 22:21:45 d2.evaluation.evaluator]: Inference done 1330/2919. Dataloading: 0.0030 s/iter. Inference: 0.0513 s/iter. Eval: 0.0029 s/iter. Total: 0.0573 s/iter. ETA=0:01:31
[03/01 22:21:50 d2.evaluation.evaluator]: Inference done 1423/2919. Dataloading: 0.0030 s/iter. Inference: 0.0511 s/iter. Eval: 0.0030 s/iter. Total: 0.0571 s/iter. ETA=0:01:25
[03/01 22:21:55 d2.evaluation.evaluator]: Inference done 1512/2919. Dataloading: 0.0030 s/iter. Inference: 0.0510 s/iter. Eval: 0.0031 s/iter. Total: 0.0571 s/iter. ETA=0:01:20
[03/01 22:22:00 d2.evaluation.evaluator]: Inference done 1600/2919. Dataloading: 0.0030 s/iter. Inference: 0.0510 s/iter. Eval: 0.0031 s/iter. Total: 0.0571 s/iter. ETA=0:01:15
[03/01 22:22:05 d2.evaluation.evaluator]: Inference done 1672/2919. Dataloading: 0.0030 s/iter. Inference: 0.0516 s/iter. Eval: 0.0031 s/iter. Total: 0.0576 s/iter. ETA=0:01:11
[03/01 22:22:10 d2.evaluation.evaluator]: Inference done 1759/2919. Dataloading: 0.0030 s/iter. Inference: 0.0516 s/iter. Eval: 0.0031 s/iter. Total: 0.0577 s/iter. ETA=0:01:06
[03/01 22:22:15 d2.evaluation.evaluator]: Inference done 1846/2919. Dataloading: 0.0030 s/iter. Inference: 0.0515 s/iter. Eval: 0.0031 s/iter. Total: 0.0577 s/iter. ETA=0:01:01
[03/01 22:22:20 d2.evaluation.evaluator]: Inference done 1927/2919. Dataloading: 0.0029 s/iter. Inference: 0.0516 s/iter. Eval: 0.0033 s/iter. Total: 0.0578 s/iter. ETA=0:00:57
[03/01 22:22:27 d2.evaluation.evaluator]: Inference done 1950/2919. Dataloading: 0.0029 s/iter. Inference: 0.0545 s/iter. Eval: 0.0033 s/iter. Total: 0.0608 s/iter. ETA=0:00:58
[03/01 22:22:32 d2.evaluation.evaluator]: Inference done 2036/2919. Dataloading: 0.0029 s/iter. Inference: 0.0544 s/iter. Eval: 0.0033 s/iter. Total: 0.0607 s/iter. ETA=0:00:53
[03/01 22:22:37 d2.evaluation.evaluator]: Inference done 2121/2919. Dataloading: 0.0029 s/iter. Inference: 0.0542 s/iter. Eval: 0.0034 s/iter. Total: 0.0606 s/iter. ETA=0:00:48
[03/01 22:22:42 d2.evaluation.evaluator]: Inference done 2207/2919. Dataloading: 0.0029 s/iter. Inference: 0.0542 s/iter. Eval: 0.0034 s/iter. Total: 0.0606 s/iter. ETA=0:00:43
[03/01 22:22:47 d2.evaluation.evaluator]: Inference done 2290/2919. Dataloading: 0.0029 s/iter. Inference: 0.0541 s/iter. Eval: 0.0035 s/iter. Total: 0.0606 s/iter. ETA=0:00:38
[03/01 22:22:52 d2.evaluation.evaluator]: Inference done 2370/2919. Dataloading: 0.0029 s/iter. Inference: 0.0541 s/iter. Eval: 0.0035 s/iter. Total: 0.0606 s/iter. ETA=0:00:33
[03/01 22:22:58 d2.evaluation.evaluator]: Inference done 2446/2919. Dataloading: 0.0029 s/iter. Inference: 0.0542 s/iter. Eval: 0.0037 s/iter. Total: 0.0608 s/iter. ETA=0:00:28
[03/01 22:23:03 d2.evaluation.evaluator]: Inference done 2513/2919. Dataloading: 0.0029 s/iter. Inference: 0.0544 s/iter. Eval: 0.0038 s/iter. Total: 0.0612 s/iter. ETA=0:00:24
[03/01 22:23:08 d2.evaluation.evaluator]: Inference done 2587/2919. Dataloading: 0.0029 s/iter. Inference: 0.0545 s/iter. Eval: 0.0039 s/iter. Total: 0.0614 s/iter. ETA=0:00:20
[03/01 22:23:13 d2.evaluation.evaluator]: Inference done 2657/2919. Dataloading: 0.0029 s/iter. Inference: 0.0548 s/iter. Eval: 0.0039 s/iter. Total: 0.0617 s/iter. ETA=0:00:16
[03/01 22:23:18 d2.evaluation.evaluator]: Inference done 2738/2919. Dataloading: 0.0029 s/iter. Inference: 0.0548 s/iter. Eval: 0.0039 s/iter. Total: 0.0617 s/iter. ETA=0:00:11
[03/01 22:23:23 d2.evaluation.evaluator]: Inference done 2818/2919. Dataloading: 0.0029 s/iter. Inference: 0.0549 s/iter. Eval: 0.0039 s/iter. Total: 0.0617 s/iter. ETA=0:00:06
[03/01 22:23:28 d2.evaluation.evaluator]: Inference done 2888/2919. Dataloading: 0.0029 s/iter. Inference: 0.0551 s/iter. Eval: 0.0039 s/iter. Total: 0.0620 s/iter. ETA=0:00:01
[03/01 22:23:30 d2.evaluation.evaluator]: Total inference time: 0:03:00.567765 (0.061966 s / iter per device, on 1 devices)
[03/01 22:23:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:02:40 (0.055103 s / iter per device, on 1 devices)
[03/01 22:23:30 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[03/01 22:23:30 d2.evaluation.coco_evaluation]: Saving results to /ghome/group07/C5-W2/lr_0_001_bs_32_is_16/coco_instances_results.json
[03/01 22:23:30 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[03/01 22:23:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[03/01 22:23:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.78 seconds.
[03/01 22:23:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[03/01 22:23:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.08 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.274
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
[03/01 22:23:31 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.629 | 57.370 | 48.282 | 27.420 | 48.639 | 54.483 |
[03/01 22:23:31 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 68.695 | pedestrian | 53.055 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 3.136  |            |        |
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
[03/01 22:23:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[03/01 22:23:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.91 seconds.
[03/01 22:23:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[03/01 22:23:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.08 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.560
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.282
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605
[03/01 22:23:32 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.221 | 55.987 | 42.018 | 21.915 | 43.657 | 55.828 |
[03/01 22:23:32 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| background | nan  | car        | 67.646 | pedestrian | 41.052 |
|            | nan  |            | nan    |            | nan    |
|            | nan  |            | nan    |            | nan    |
|            | nan  | ignore     | 2.964  |            |        |
OrderedDict([('bbox', {'AP': 41.62871112613832, 'AP50': 57.37047111725687, 'AP75': 48.2822794267474, 'APs': 27.420034548234934, 'APm': 48.6385054593002, 'APl': 54.48260403985942, 'AP-background': nan, 'AP-car': 68.69493591836428, 'AP-pedestrian': 53.05493355544269, 'AP-': nan, 'AP-ignore': 3.136263904608014}), ('segm', {'AP': 37.220611613082575, 'AP50': 55.986856587071074, 'AP75': 42.017693349386384, 'APs': 21.914500206121414, 'APm': 43.65738638435876, 'APl': 55.82800163701035, 'AP-background': nan, 'AP-car': 67.64639434684725, 'AP-pedestrian': 41.05165696641189, 'AP-': nan, 'AP-ignore': 2.9637835259885916})])
